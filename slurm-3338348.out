2024-03-28 18:12:27.232 | DEBUG    | api.config:<module>:296 - SETTINGS: {
    "host": "0.0.0.0",
    "port": 10086,
    "api_prefix": "/v1",
    "engine": "default",
    "model_name": "internlm2",
    "model_path": "/mnt/petrelfs/zhangdi1/chemllm-lnk/LLaMA-Factory-dev/CHEMLLM_1_5",
    "adapter_model_path": null,
    "resize_embeddings": false,
    "dtype": "half",
    "device": "cuda",
    "device_map": "auto",
    "gpus": null,
    "num_gpus": 1,
    "only_embedding": false,
    "embedding_name": "moka-ai/m3e-base",
    "embedding_size": -1,
    "embedding_device": "cuda",
    "quantize": 16,
    "load_in_8bit": false,
    "load_in_4bit": false,
    "using_ptuning_v2": false,
    "pre_seq_len": 128,
    "context_length": 4096,
    "chat_template": null,
    "rope_scaling": null,
    "flash_attn": false,
    "trust_remote_code": false,
    "tokenize_mode": "auto",
    "tensor_parallel_size": 1,
    "gpu_memory_utilization": 0.9,
    "max_num_batched_tokens": -1,
    "max_num_seqs": 256,
    "quantization_method": null,
    "enforce_eager": false,
    "max_context_len_to_capture": 8192,
    "max_loras": 1,
    "max_lora_rank": 32,
    "lora_extra_vocab_size": 256,
    "lora_dtype": "auto",
    "max_cpu_loras": -1,
    "lora_modules": "",
    "use_streamer_v2": false,
    "api_keys": null,
    "activate_inference": true,
    "interrupt_requests": true,
    "n_gpu_layers": 0,
    "main_gpu": 0,
    "tensor_split": null,
    "n_batch": 512,
    "n_threads": 128,
    "n_threads_batch": 128,
    "rope_scaling_type": -1,
    "rope_freq_base": 0.0,
    "rope_freq_scale": 0.0,
    "tgi_endpoint": null,
    "tei_endpoint": null,
    "max_concurrent_requests": 256,
    "max_client_batch_size": 32
}
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:08<00:59,  8.47s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:15<00:45,  7.59s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:22<00:36,  7.25s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:29<00:28,  7.06s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:35<00:21,  7.01s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:42<00:13,  6.93s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:49<00:06,  6.88s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:55<00:00,  6.74s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:55<00:00,  7.00s/it]
2024-03-28 18:13:46.465 | INFO     | api.models:create_generate_model:61 - Using default engine
INFO:     Started server process [231253]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:10086 (Press CTRL+C to quit)
slurmstepd: error: *** JOB 3338348 ON SH-IDC1-10-140-24-111 CANCELLED AT 2024-03-28T18:14:03 ***
