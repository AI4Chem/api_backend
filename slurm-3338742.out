2024-03-28 21:32:08.013 | DEBUG    | api.config:<module>:296 - SETTINGS: {
    "host": "0.0.0.0",
    "port": 10086,
    "api_prefix": "/v1",
    "engine": "vllm",
    "model_name": "internlm2",
    "model_path": "/mnt/petrelfs/zhangdi1/chemllm-lnk/LLaMA-Factory-dev/CHEMLLM_1_5_DPO_exported",
    "adapter_model_path": null,
    "resize_embeddings": false,
    "dtype": "half",
    "device": "cuda",
    "device_map": "auto",
    "gpus": null,
    "num_gpus": 2,
    "only_embedding": false,
    "embedding_name": "moka-ai/m3e-base",
    "embedding_size": -1,
    "embedding_device": "cuda",
    "quantize": 16,
    "load_in_8bit": false,
    "load_in_4bit": false,
    "using_ptuning_v2": false,
    "pre_seq_len": 128,
    "context_length": 4096,
    "chat_template": null,
    "rope_scaling": null,
    "flash_attn": false,
    "trust_remote_code": true,
    "tokenize_mode": "fast",
    "tensor_parallel_size": 2,
    "gpu_memory_utilization": 0.9,
    "max_num_batched_tokens": -1,
    "max_num_seqs": 256,
    "quantization_method": null,
    "enforce_eager": false,
    "max_context_len_to_capture": 8192,
    "max_loras": 1,
    "max_lora_rank": 32,
    "lora_extra_vocab_size": 256,
    "lora_dtype": "auto",
    "max_cpu_loras": -1,
    "lora_modules": "",
    "use_streamer_v2": false,
    "api_keys": null,
    "activate_inference": true,
    "interrupt_requests": true,
    "n_gpu_layers": 0,
    "main_gpu": 0,
    "tensor_split": null,
    "n_batch": 512,
    "n_threads": 128,
    "n_threads_batch": 128,
    "rope_scaling_type": -1,
    "rope_freq_base": 0.0,
    "rope_freq_scale": 0.0,
    "tgi_endpoint": null,
    "tei_endpoint": null,
    "max_concurrent_requests": 256,
    "max_client_batch_size": 32
}
WARNING 03-28 21:32:36 config.py:618] Casting torch.bfloat16 to torch.float16.
INFO 03-28 21:32:36 config.py:433] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.
2024-03-28 21:32:40,162	INFO worker.py:1752 -- Started a local Ray instance.
INFO 03-28 21:33:14 llm_engine.py:87] Initializing an LLM engine with config: model='/mnt/petrelfs/zhangdi1/chemllm-lnk/LLaMA-Factory-dev/CHEMLLM_1_5_DPO_exported', tokenizer='/mnt/petrelfs/zhangdi1/chemllm-lnk/LLaMA-Factory-dev/CHEMLLM_1_5_DPO_exported', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)
WARNING 03-28 21:33:14 tokenizer.py:64] Using a slow tokenizer. This might cause a significant slowdown. Consider using a fast tokenizer instead.
INFO 03-28 21:34:13 llm_engine.py:357] # GPU blocks: 62733, # CPU blocks: 4096
INFO 03-28 21:34:15 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 03-28 21:34:15 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[36m(RayWorkerVllm pid=197838)[0m INFO 03-28 21:34:15 model_runner.py:684] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=197838)[0m INFO 03-28 21:34:15 model_runner.py:688] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[36m(RayWorkerVllm pid=197838)[0m INFO 03-28 21:34:23 model_runner.py:756] Graph capturing finished in 9 secs.
INFO 03-28 21:34:23 model_runner.py:756] Graph capturing finished in 9 secs.
2024-03-28 21:34:24.409 | INFO     | api.models:create_vllm_engine:107 - Using vllm engine
WARNING 03-28 21:34:24 tokenizer.py:64] Using a slow tokenizer. This might cause a significant slowdown. Consider using a fast tokenizer instead.
INFO:     Started server process [179117]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:10086 (Press CTRL+C to quit)
2024-03-28 21:35:37.049 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:48256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:35:37 async_llm_engine.py:436] Received request chatcmpl-5965b5b5-f1d3-4829-be63-f46ad4102d8c: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:35:37 metrics.py:213] Avg prompt throughput: 1.5 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:35:37 async_llm_engine.py:110] Finished request chatcmpl-5965b5b5-f1d3-4829-be63-f46ad4102d8c.
2024-03-28 21:37:05.608 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}, {'role': 'assistant', 'content': '您好！\n\n很高兴为您服务。请问有什么我可以帮助您的吗？'}, {'content': '随便都行', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:53190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:37:05 async_llm_engine.py:436] Received request chatcmpl-98280da3-02d5-401d-8c2e-2b10151014f1: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n您好！\n\n很高兴为您服务。请问有什么我可以帮助您的吗？<|im_end|>\n<|im_start|>user\n随便都行<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 61176, 60391, 60477, 402, 86955, 72048, 68320, 60355, 80571, 69259, 74010, 68417, 70266, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 69949, 86024, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:37:05 metrics.py:213] Avg prompt throughput: 1.7 tokens/s, Avg generation throughput: 0.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:37:05 async_llm_engine.py:110] Finished request chatcmpl-98280da3-02d5-401d-8c2e-2b10151014f1.
2024-03-28 21:37:08.122 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}, {'role': 'assistant', 'content': '您好！\n\n很高兴为您服务。请问有什么我可以帮助您的吗？'}, {'content': '随便都行', 'role': 'user'}, {'role': 'assistant', 'content': '为了给您提供一些刺激，这里有几个话题可供选择：自然、科学、文学或时事新闻。您对哪一个感兴趣呢？'}, {'content': 'Please generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.', 'role': 'user'}], 'echo': False}
INFO 03-28 21:37:08 async_llm_engine.py:436] Received request chatcmpl-7a70b7fb-9999-4fa9-8591-b677cfd01759: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n您好！\n\n很高兴为您服务。请问有什么我可以帮助您的吗？<|im_end|>\n<|im_start|>user\n随便都行<|im_end|>\n<|im_start|>assistant\n为了给您提供一些刺激，这里有几个话题可供选择：自然、科学、文学或时事新闻。您对哪一个感兴趣呢？<|im_end|>\n<|im_start|>user\nPlease generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 61176, 60391, 60477, 402, 86955, 72048, 68320, 60355, 80571, 69259, 74010, 68417, 70266, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 69949, 86024, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68394, 82545, 68403, 68315, 69573, 60353, 68409, 77940, 71023, 76191, 68260, 60387, 68519, 60359, 68575, 60359, 69131, 60535, 60377, 60443, 69447, 60355, 61176, 60409, 86537, 70831, 60827, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 5658, 7076, 395, 3205, 442, 4393, 3571, 2416, 28634, 5008, 1181, 10571, 2192, 1030, 3154, 3580, 328, 60117, 328, 53245, 15546, 328, 18500, 328, 17880, 328, 14082, 1614, 328, 607, 5268, 1614, 281, 10930, 3374, 17976, 53245, 15546, 15889, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:37:08 async_llm_engine.py:110] Finished request chatcmpl-7a70b7fb-9999-4fa9-8591-b677cfd01759.
INFO:     10.1.96.6:53194 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 21:37:12.995 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'role': 'assistant', 'content': '您好！\n\n很高兴为您服务。请问有什么我可以帮助您的吗？'}, {'content': '随便都行', 'role': 'user'}, {'role': 'assistant', 'content': '为了给您提供一些刺激，这里有几个话题可供选择：自然、科学、文学或时事新闻。您对哪一个感兴趣呢？'}, {'content': '来点刺激的', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:47378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:37:12 async_llm_engine.py:436] Received request chatcmpl-3c89faea-69c4-40eb-93d0-99ec3aec40a2: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>assistant\n您好！\n\n很高兴为您服务。请问有什么我可以帮助您的吗？<|im_end|>\n<|im_start|>user\n随便都行<|im_end|>\n<|im_start|>assistant\n为了给您提供一些刺激，这里有几个话题可供选择：自然、科学、文学或时事新闻。您对哪一个感兴趣呢？<|im_end|>\n<|im_start|>user\n来点刺激的<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 61176, 60391, 60477, 402, 86955, 72048, 68320, 60355, 80571, 69259, 74010, 68417, 70266, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 69949, 86024, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68394, 82545, 68403, 68315, 69573, 60353, 68409, 77940, 71023, 76191, 68260, 60387, 68519, 60359, 68575, 60359, 69131, 60535, 60377, 60443, 69447, 60355, 61176, 60409, 86537, 70831, 60827, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60383, 60390, 69573, 60354, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:37:13 metrics.py:213] Avg prompt throughput: 60.2 tokens/s, Avg generation throughput: 6.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:37:13 async_llm_engine.py:110] Finished request chatcmpl-3c89faea-69c4-40eb-93d0-99ec3aec40a2.
2024-03-28 21:37:14.656 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '', 'role': 'system'}, {'content': '你好', 'role': 'user'}, {'role': 'assistant', 'content': '您好！\n\n很高兴为您服务。请问有什么我可以帮助您的吗？'}, {'content': '随便都行', 'role': 'user'}, {'role': 'assistant', 'content': '为了给您提供一些刺激，这里有几个话题可供选择：自然、科学、文学或时事新闻。您对哪一个感兴趣呢？'}, {'content': '来点刺激的', 'role': 'user'}, {'role': 'assistant', 'content': '为了让您充分参与对话，这里有一些发人深省的问题供我们讨论：生命的意义是什么？你认为意识的本质是什么？人类科技的未来会怎样？这些是深刻的哲学主题，希望它们能激发我们的思考和谈话。'}, {'content': 'Summarize our conversation in 50 words or less', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:47394 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 21:37:14 async_llm_engine.py:436] Received request chatcmpl-c0753ba3-d3c8-4120-a77e-e88af5d182fc: prompt: '<s><|im_start|>system\n<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:37:18 metrics.py:213] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 75.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:37:19 async_llm_engine.py:110] Finished request chatcmpl-c0753ba3-d3c8-4120-a77e-e88af5d182fc.
2024-03-28 21:37:32.519 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'This is a summary of the chat history as a recap: Given a string, return the sum of all ASCII values in that **string**.\n\nThis problem is solved using Python programming language. Here\'s how you can do it -\n\n```python\n\ndef ascii_sum(str):\n    return str.encode().__iter__().next()\n\n# Driver Code to test above function.\nstr = "hello"\nresult = ascii_sum(str)\nprint(result)\n\n\'\'\'\nOutput: 542 \n\'\'\'\n\n====================\n\nHere are some additional information about this solution:\n\n1) The `ascii_sum()` method accepts only one parameter which should be passed as an argument (`*args`).\n\n2)`encode(__*)` returns encoded bytes object for given Unicode/UTF-8 strings (as byte arrays). In our case we pass `"unicode_string"` and get back its corresponding UTF -16 bits representation(`bytes`), so essentially what happens inside encode here just converts each unicode character into their respective hexadecimal value code point ranges from `(\\u0001 ~ \\u007E`)`, therefore there will not exist any overflow issues while doing mathematical operations on these characters\' binary equivalent representations.`__iter__()`: It’s special iterator methods available with iterable objects like list/tuple/dict etc., Basically if your class implements __init__, then automatically constructor implicitly calls next(), otherwise when calling iterating through instance variable(s)/object attribute via self keyword itself directly invokes internal state machinery associated within particular data structure by invoking private member functions/method attributes such (__getattr__()).\n\n=================================================================== \n\nThe first line does nothing but define name space scope block delimited enclosed between two sets curly braces `{}`. Within body content section specified after opening brace {, same indentation level applies throughout blocks/sub-section under hierarchy tree without violating rules governing proper formatting syntaxes adhering strictly following standard coding conventions/practices required necessary during software development lifecycle stages/deployments across various hardware architectures/system configurations used widely deployed being utilized actively employed working among developers/testers/users alike members collectively forming vibrant global open-source community sharing knowledge/code collaboratively contributing towards developing innovative solutions tackling real-world problems/challenges utilizing latest technologies/tools leveraging expertise skills/experience gained over years/months/hours spent diligently learning practicing implementing applying concepts theories techniques algorithms designs patterns models frameworks libraries tools APIs SDK middleware services microservices applications websites web apps mobile/web hybrid native cross-platform responsive adaptive design wireframes layouts mockups prototypes user experience research human-computer interaction cognitive science ergonomics typography color theory graphic designing digital marketing search engine optimization e-commerce business consulting strategy planning project management agile scrum', 'role': 'system'}, {'role': 'assistant', 'content': '为了给您提供一些刺激，这里有几个话题可供选择：自然、科学、文学或时事新闻。您对哪一个感兴趣呢？'}, {'content': '来点刺激的', 'role': 'user'}, {'role': 'assistant', 'content': '为了让您充分参与对话，这里有一些发人深省的问题供我们讨论：生命的意义是什么？你认为意识的本质是什么？人类科技的未来会怎样？这些是深刻的哲学主题，希望它们能激发我们的思考和谈话。'}, {'content': '有没有更刺激的？我加钱', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:53858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:37:32 async_llm_engine.py:436] Received request chatcmpl-30875a3e-404e-465b-9bbb-62cf832e18b8: prompt: '<s><|im_start|>system\nThis is a summary of the chat history as a recap: Given a string, return the sum of all ASCII values in that **string**.\n\nThis problem is solved using Python programming language. Here\'s how you can do it -\n\n```python\n\ndef ascii_sum(str):\n    return str.encode().__iter__().next()\n\n# Driver Code to test above function.\nstr = "hello"\nresult = ascii_sum(str)\nprint(result)\n\n\'\'\'\nOutput: 542 \n\'\'\'\n\n====================\n\nHere are some additional information about this solution:\n\n1) The `ascii_sum()` method accepts only one parameter which should be passed as an argument (`*args`).\n\n2)`encode(__*)` returns encoded bytes object for given Unicode/UTF-8 strings (as byte arrays). In our case we pass `"unicode_string"` and get back its corresponding UTF -16 bits representation(`bytes`), so essentially what happens inside encode here just converts each unicode character into their respective hexadecimal value code point ranges from `(\\u0001 ~ \\u007E`)`, therefore there will not exist any overflow issues while doing mathematical operations on these characters\' binary equivalent representations.`__iter__()`: It’s special iterator methods available with iterable objects like list/tuple/dict etc., Basically if your class implements __init__, then automatically constructor implicitly calls next(), otherwise when calling iterating through instance variable(s)/object attribute via self keyword itself directly invokes internal state machinery associated within particular data structure by invoking private member functions/method attributes such (__getattr__()).\n\n=================================================================== \n\nThe first line does nothing but define name space scope block delimited enclosed between two sets curly braces `{}`. Within body content section specified after opening brace {, same indentation level applies throughout blocks/sub-section under hierarchy tree without violating rules governing proper formatting syntaxes adhering strictly following standard coding conventions/practices required necessary during software development lifecycle stages/deployments across various hardware architectures/system configurations used widely deployed being utilized actively employed working among developers/testers/users alike members collectively forming vibrant global open-source community sharing knowledge/code collaboratively contributing towards developing innovative solutions tackling real-world problems/challenges utilizing latest technologies/tools leveraging expertise skills/experience gained over years/months/hours spent diligently learning practicing implementing applying concepts theories techniques algorithms designs patterns models frameworks libraries tools APIs SDK middleware services microservices applications websites web apps mobile/web hybrid native cross-platform responsive adaptive design wireframes layouts mockups prototypes user experience research human-computer interaction cognitive science ergonomics typography color theory graphic designing digital marketing search engine optimization e-commerce business consulting strategy planning project management agile scrum<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2136, 505, 395, 12279, 446, 410, 6392, 3995, 569, 395, 53027, 334, 16375, 395, 1051, 328, 601, 410, 2789, 446, 810, 39109, 2914, 435, 560, 3235, 1054, 465, 512, 2136, 3652, 505, 28320, 1817, 13175, 15600, 4287, 281, 5846, 725, 1392, 629, 777, 784, 563, 22240, 14016, 350, 12819, 402, 882, 46530, 10299, 4357, 1122, 388, 821, 739, 17453, 26933, 2165, 694, 1145, 3761, 2986, 324, 14710, 6272, 442, 1420, 3565, 862, 756, 626, 415, 461, 15115, 830, 1528, 415, 46530, 10299, 4357, 471, 1496, 4618, 824, 14818, 5258, 334, 262, 21323, 848, 33767, 1664, 737, 402, 8554, 657, 1187, 5268, 2145, 1048, 550, 6448, 1593, 312, 313, 707, 1711, 23656, 10299, 53271, 1864, 26774, 1317, 959, 5886, 1028, 1412, 517, 5977, 569, 589, 5847, 28984, 297, 2269, 350, 3754, 314, 45650, 6334, 5669, 3924, 350, 4838, 20689, 5974, 1781, 500, 2823, 35856, 301, 8693, 285, 294, 9198, 451, 431, 5080, 18540, 699, 890, 1181, 1286, 713, 1640, 52372, 24931, 4061, 39681, 454, 765, 1327, 1326, 12312, 20251, 612, 972, 9601, 13188, 5962, 9786, 350, 833, 906, 15922, 1272, 8705, 4928, 16295, 1734, 1244, 32845, 1966, 26514, 3827, 1263, 998, 19682, 12521, 48612, 1033, 2189, 1605, 21512, 635, 47977, 3930, 1057, 312, 4125, 1268, 275, 11104, 288, 32993, 7946, 9049, 1194, 818, 668, 3164, 1030, 16620, 4876, 1539, 3890, 35926, 7667, 519, 1639, 5917, 259, 8006, 13718, 43218, 15037, 694, 2165, 694, 499, 44166, 1226, 61974, 269, 3444, 15213, 5571, 2656, 579, 50027, 6325, 1217, 1284, 5679, 6214, 3607, 985, 5151, 2732, 40451, 552, 829, 667, 5328, 1450, 2479, 10581, 1367, 9592, 4855, 50910, 6888, 1942, 1652, 6090, 1119, 8232, 5526, 1237, 1672, 3030, 4047, 1285, 5776, 1850, 7185, 4729, 787, 16306, 5247, 6115, 1675, 8077, 5465, 1730, 26306, 5969, 3042, 4110, 955, 6098, 684, 45499, 1005, 4623, 5899, 3348, 1210, 8334, 1893, 22848, 586, 3155, 694, 2293, 512, 8287, 8843, 4872, 918, 1300, 1700, 1703, 4462, 847, 7129, 963, 3711, 7044, 2660, 1740, 31696, 43401, 2100, 1524, 7435, 3011, 528, 57929, 52736, 5697, 281, 24625, 2642, 2364, 3932, 5347, 1428, 8700, 32979, 445, 328, 2001, 17641, 498, 2340, 16921, 6965, 10146, 37751, 21835, 1358, 29241, 5074, 2192, 43914, 5756, 10148, 6323, 36501, 19648, 419, 34956, 418, 25912, 2863, 5456, 10971, 44040, 44214, 662, 1362, 2726, 6025, 2489, 3328, 4562, 46898, 17769, 22839, 2855, 1513, 4098, 5417, 11922, 11621, 1559, 28492, 32526, 1629, 13710, 26512, 1810, 33690, 22311, 19614, 3401, 4379, 13542, 12847, 518, 19338, 26431, 3774, 44358, 29378, 33083, 3805, 1939, 30996, 4099, 11714, 6696, 46349, 11332, 8026, 29049, 7124, 11370, 18351, 10039, 55698, 2083, 30340, 5481, 21513, 42028, 34894, 5691, 14447, 45202, 27889, 4276, 18875, 7508, 26253, 13119, 18313, 1053, 1783, 46722, 269, 7672, 2625, 7538, 38127, 4563, 6983, 35539, 25355, 19105, 19098, 25396, 12689, 25620, 14568, 12776, 4277, 47382, 20366, 7521, 33449, 27043, 29954, 3677, 8137, 12928, 8490, 13185, 3644, 10638, 6526, 22063, 25416, 10002, 5471, 53051, 26426, 46542, 3047, 9196, 24081, 48355, 7998, 8736, 46063, 1341, 3304, 3574, 3898, 11628, 11434, 16360, 25094, 8171, 35265, 14413, 1357, 3743, 5850, 2044, 10263, 20706, 30003, 7523, 8629, 2873, 4874, 25696, 514, 41279, 2721, 30955, 8414, 9244, 2545, 6396, 60083, 9356, 503, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:37:32 metrics.py:213] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:37:37 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 96.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:37:37 async_llm_engine.py:110] Finished request chatcmpl-30875a3e-404e-465b-9bbb-62cf832e18b8.
2024-03-28 21:37:39.559 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'This is a summary of the chat history as a recap: Given a string, return the sum of all ASCII values in that **string**.\n\nThis problem is solved using Python programming language. Here\'s how you can do it -\n\n```python\n\ndef ascii_sum(str):\n    return str.encode().__iter__().next()\n\n# Driver Code to test above function.\nstr = "hello"\nresult = ascii_sum(str)\nprint(result)\n\n\'\'\'\nOutput: 542 \n\'\'\'\n\n====================\n\nHere are some additional information about this solution:\n\n1) The `ascii_sum()` method accepts only one parameter which should be passed as an argument (`*args`).\n\n2)`encode(__*)` returns encoded bytes object for given Unicode/UTF-8 strings (as byte arrays). In our case we pass `"unicode_string"` and get back its corresponding UTF -16 bits representation(`bytes`), so essentially what happens inside encode here just converts each unicode character into their respective hexadecimal value code point ranges from `(\\u0001 ~ \\u007E`)`, therefore there will not exist any overflow issues while doing mathematical operations on these characters\' binary equivalent representations.`__iter__()`: It’s special iterator methods available with iterable objects like list/tuple/dict etc., Basically if your class implements __init__, then automatically constructor implicitly calls next(), otherwise when calling iterating through instance variable(s)/object attribute via self keyword itself directly invokes internal state machinery associated within particular data structure by invoking private member functions/method attributes such (__getattr__()).\n\n=================================================================== \n\nThe first line does nothing but define name space scope block delimited enclosed between two sets curly braces `{}`. Within body content section specified after opening brace {, same indentation level applies throughout blocks/sub-section under hierarchy tree without violating rules governing proper formatting syntaxes adhering strictly following standard coding conventions/practices required necessary during software development lifecycle stages/deployments across various hardware architectures/system configurations used widely deployed being utilized actively employed working among developers/testers/users alike members collectively forming vibrant global open-source community sharing knowledge/code collaboratively contributing towards developing innovative solutions tackling real-world problems/challenges utilizing latest technologies/tools leveraging expertise skills/experience gained over years/months/hours spent diligently learning practicing implementing applying concepts theories techniques algorithms designs patterns models frameworks libraries tools APIs SDK middleware services microservices applications websites web apps mobile/web hybrid native cross-platform responsive adaptive design wireframes layouts mockups prototypes user experience research human-computer interaction cognitive science ergonomics typography color theory graphic designing digital marketing search engine optimization e-commerce business consulting strategy planning project management agile scrum', 'role': 'system'}, {'content': '有没有更刺激的？我加钱', 'role': 'user'}, {'role': 'assistant', 'content': "To solve [this](https://stackoverflow.com/questions/12001871/python-how-to-get-the-total-of-all-character-gre/) question], I'm going to provide three different approaches/solutions written purely based upon pythonic-style practices/guidelines/rules/etc.:  \n\n### Approach #01:\n#### Methodology & Techniques Used -\n  a.) Using built-in library module named 'unicodedata', defined specifically designed explicitly created primarily intended solely dedicated exclusively particularly focused purposely aimed at accomplishing task related tasks concerned activities actions assigned projects programs procedures protocols processes mechanisms systems workloads loads burdens stresses strains efforts exertions lifestyles ways living habits hobbies interests pastimes amusemets diversies pleasures engagements involvements affairs undertakings commitments obligations stipulations provisions terms conditions provisos clauses articles sections paragraphs sentences phrases words letters sounds intonations accents diacritisms umlauten grave accentus acute accensused circumflex acutaccencsed cedilla edcillica germand blenth biedotblendth thorn ethelsh schwa non-syllabary stop consonant vowell semivowelle diphonge triphone triconsonantal quadragramme pentagramma heptogrammathe octograme enneagraille decigram megram grammy ion kilo mega giga terra peta exaeiou septillion]([Unicode Data File)[^[](Unicode Character Property Values)]()(UnicodeData.db)) has been introduced since version Py3k onwards; henceforth effectively obviated need requirement necessity demand desideratum supplication requisition necessitate imperative command order decree dictate prescript regimen rule regulation statute canon law ecclesial jurisprudence civil judicial judiciary legalese jargoneese argotspeak codetalk slang shibboleths cant vernacular dialect patois pidgin lingua franca international auxiliary languages interlingual translation glossolalia frenzy tantram seraphicism cherubicity angelism saintliness sanctimoniousness christian piety holiness righteousnes divinity deific nature numinous spirituality transcendentality esotericalite occulticity mystique arcane erudité sagacity subtlety intricacy finessem complexity compexità sottilezza delicatesse sophisticatus sophistici sapientia sapeintise sophisticated smart savvy sharp slick sleek smooth suave urbane cosmopolitan world-wise well"}, {'content': 'Summarize our conversation in 50 words or less', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:53860 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 21:37:39 async_llm_engine.py:436] Received request chatcmpl-99f0e547-cf4f-4ed3-80b3-71d1d50c2113: prompt: '<s><|im_start|>system\nThis is a summary of the chat history as a recap: Given a string, return the sum of all ASCII values in that **string**.\n\nThis problem is solved using Python programming language. Here\'s how you can do it -\n\n```python\n\ndef ascii_sum(str):\n    return str.encode().__iter__().next()\n\n# Driver Code to test above function.\nstr = "hello"\nresult = ascii_sum(str)\nprint(result)\n\n\'\'\'\nOutput: 542 \n\'\'\'\n\n====================\n\nHere are some additional information about this solution:\n\n1) The `ascii_sum()` method accepts only one parameter which should be passed as an argument (`*args`).\n\n2)`encode(__*)` returns encoded bytes object for given Unicode/UTF-8 strings (as byte arrays). In our case we pass `"unicode_string"` and get back its corresponding UTF -16 bits representation(`bytes`), so essentially what happens inside encode here just converts each unicode character into their respective hexadecimal value code point ranges from `(\\u0001 ~ \\u007E`)`, therefore there will not exist any overflow issues while doing mathematical operations on these characters\' binary equivalent representations.`__iter__()`: It’s special iterator methods available with iterable objects like list/tuple/dict etc., Basically if your class implements __init__, then automatically constructor implicitly calls next(), otherwise when calling iterating through instance variable(s)/object attribute via self keyword itself directly invokes internal state machinery associated within particular data structure by invoking private member functions/method attributes such (__getattr__()).\n\n=================================================================== \n\nThe first line does nothing but define name space scope block delimited enclosed between two sets curly braces `{}`. Within body content section specified after opening brace {, same indentation level applies throughout blocks/sub-section under hierarchy tree without violating rules governing proper formatting syntaxes adhering strictly following standard coding conventions/practices required necessary during software development lifecycle stages/deployments across various hardware architectures/system configurations used widely deployed being utilized actively employed working among developers/testers/users alike members collectively forming vibrant global open-source community sharing knowledge/code collaboratively contributing towards developing innovative solutions tackling real-world problems/challenges utilizing latest technologies/tools leveraging expertise skills/experience gained over years/months/hours spent diligently learning practicing implementing applying concepts theories techniques algorithms designs patterns models frameworks libraries tools APIs SDK middleware services microservices applications websites web apps mobile/web hybrid native cross-platform responsive adaptive design wireframes layouts mockups prototypes user experience research human-computer interaction cognitive science ergonomics typography color theory graphic designing digital marketing search engine optimization e-commerce business consulting strategy planning project management agile scrum<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2136, 505, 395, 12279, 446, 410, 6392, 3995, 569, 395, 53027, 334, 16375, 395, 1051, 328, 601, 410, 2789, 446, 810, 39109, 2914, 435, 560, 3235, 1054, 465, 512, 2136, 3652, 505, 28320, 1817, 13175, 15600, 4287, 281, 5846, 725, 1392, 629, 777, 784, 563, 22240, 14016, 350, 12819, 402, 882, 46530, 10299, 4357, 1122, 388, 821, 739, 17453, 26933, 2165, 694, 1145, 3761, 2986, 324, 14710, 6272, 442, 1420, 3565, 862, 756, 626, 415, 461, 15115, 830, 1528, 415, 46530, 10299, 4357, 471, 1496, 4618, 824, 14818, 5258, 334, 262, 21323, 848, 33767, 1664, 737, 402, 8554, 657, 1187, 5268, 2145, 1048, 550, 6448, 1593, 312, 313, 707, 1711, 23656, 10299, 53271, 1864, 26774, 1317, 959, 5886, 1028, 1412, 517, 5977, 569, 589, 5847, 28984, 297, 2269, 350, 3754, 314, 45650, 6334, 5669, 3924, 350, 4838, 20689, 5974, 1781, 500, 2823, 35856, 301, 8693, 285, 294, 9198, 451, 431, 5080, 18540, 699, 890, 1181, 1286, 713, 1640, 52372, 24931, 4061, 39681, 454, 765, 1327, 1326, 12312, 20251, 612, 972, 9601, 13188, 5962, 9786, 350, 833, 906, 15922, 1272, 8705, 4928, 16295, 1734, 1244, 32845, 1966, 26514, 3827, 1263, 998, 19682, 12521, 48612, 1033, 2189, 1605, 21512, 635, 47977, 3930, 1057, 312, 4125, 1268, 275, 11104, 288, 32993, 7946, 9049, 1194, 818, 668, 3164, 1030, 16620, 4876, 1539, 3890, 35926, 7667, 519, 1639, 5917, 259, 8006, 13718, 43218, 15037, 694, 2165, 694, 499, 44166, 1226, 61974, 269, 3444, 15213, 5571, 2656, 579, 50027, 6325, 1217, 1284, 5679, 6214, 3607, 985, 5151, 2732, 40451, 552, 829, 667, 5328, 1450, 2479, 10581, 1367, 9592, 4855, 50910, 6888, 1942, 1652, 6090, 1119, 8232, 5526, 1237, 1672, 3030, 4047, 1285, 5776, 1850, 7185, 4729, 787, 16306, 5247, 6115, 1675, 8077, 5465, 1730, 26306, 5969, 3042, 4110, 955, 6098, 684, 45499, 1005, 4623, 5899, 3348, 1210, 8334, 1893, 22848, 586, 3155, 694, 2293, 512, 8287, 8843, 4872, 918, 1300, 1700, 1703, 4462, 847, 7129, 963, 3711, 7044, 2660, 1740, 31696, 43401, 2100, 1524, 7435, 3011, 528, 57929, 52736, 5697, 281, 24625, 2642, 2364, 3932, 5347, 1428, 8700, 32979, 445, 328, 2001, 17641, 498, 2340, 16921, 6965, 10146, 37751, 21835, 1358, 29241, 5074, 2192, 43914, 5756, 10148, 6323, 36501, 19648, 419, 34956, 418, 25912, 2863, 5456, 10971, 44040, 44214, 662, 1362, 2726, 6025, 2489, 3328, 4562, 46898, 17769, 22839, 2855, 1513, 4098, 5417, 11922, 11621, 1559, 28492, 32526, 1629, 13710, 26512, 1810, 33690, 22311, 19614, 3401, 4379, 13542, 12847, 518, 19338, 26431, 3774, 44358, 29378, 33083, 3805, 1939, 30996, 4099, 11714, 6696, 46349, 11332, 8026, 29049, 7124, 11370, 18351, 10039, 55698, 2083, 30340, 5481, 21513, 42028, 34894, 5691, 14447, 45202, 27889, 4276, 18875, 7508, 26253, 13119, 18313, 1053, 1783, 46722, 269, 7672, 2625, 7538, 38127, 4563, 6983, 35539, 25355, 19105, 19098, 25396, 12689, 25620, 14568, 12776, 4277, 47382, 20366, 7521, 33449, 27043, 29954, 3677, 8137, 12928, 8490, 13185, 3644, 10638, 6526, 22063, 25416, 10002, 5471, 53051, 26426, 46542, 3047, 9196, 24081, 48355, 7998, 8736, 46063, 1341, 3304, 3574, 3898, 11628, 11434, 16360, 25094, 8171, 35265, 14413, 1357, 3743, 5850, 2044, 10263, 20706, 30003, 7523, 8629, 2873, 4874, 25696, 514, 41279, 2721, 30955, 8414, 9244, 2545, 6396, 60083, 9356, 503, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:37:42 metrics.py:213] Avg prompt throughput: 109.5 tokens/s, Avg generation throughput: 63.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:37:44 async_llm_engine.py:110] Finished request chatcmpl-99f0e547-cf4f-4ed3-80b3-71d1d50c2113.
2024-03-28 21:44:14.675 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'This is a summary of the chat history as a recap: To clarify further,\n\nIn python,\nLet us consider below example:\nSuppose I have defined my custom User Class named \'User\':\nclass User():\n  pass\n  \nNow suppose now let me create new instances(user objects).\nuser1 = User()\n  \nSo basically whenever u instantiate/create either single or multiple number of times(instantiating again &again&Again :) ),a reference(**instance**) gets created pointing(to memory address location)**address_of_user1**(the actual physical existence where everything exists physically resides! ;))\nAnd thus similarly another separate unique independent identity(reference(address)) getting assigned creating totally different isolated individual(identity) residing at completely separated distinct locations(pointer/references(address)))\nindependence(individuality)*pointed_to(physical_address)*=***reference(pointor/refernce(address)))**\n\nAnyway sorry digressed too much :D Hope things cleared out!\n=========================================\nComing straight downline!\n\nGiven input *"Hello"*, upon executing program logic steps sequentially stepwise(i.e top-down recursion approach style wise):\n\nFirst instruction statement executed was passing "*input_string* ->(string)"->(\'Unicode\', utf_32_be encoding)->("utf"-encoding)-(*code_point*, digit->hexadecimal, base 10 decimal numeral system conversion)(*ASCII* [American Standard Codes](https://en.wikipedia.org/wiki/American_Speci%C3%A0l_Alphanumeric_Code)]: Binary Decimal Hexidecimal Character Equivalent Value Range Values Characters Allowed Glyph Set Extended Latin Alphabets A-Z,a-z $\\alpha$,$\\beta$,etc.$~[\\![[][~~]]][^]$$([U+0020– U+FFFF−])$\nASCII Table |[](./table-1555287524750.gif?raw=true)[)](http://www.asciitable.com/)\n-------------------------------------------------------------------------------\nAccording task requirement specification guidelines mentioned earlier i,e:*Step-wise Execution Flow Chart*\n--------------\nSteps Follow Sequence Wise :\n--------------------------\n### Step #01 :\n\n#### Input Data String:`"H","e","ll","o"`\n----------------------------------------\nUpon execution flow chart visualized graphically visually represented looks something similar akin approximately close resembling quite closely very nearly pretty almost virtually identical likeness exactly precisely formally properly correctly truly fairly somewhat moderately extremely utterly profound deeply thoroughly comprehensively significantly radically enormously tremendously exceptionally astoundingly terribly dreadfully awfully ghastliness frightfulness horrifying spectral spectre spookiness unnerving unpleasing unholy unspeakable frightening ghost-like creepy spine-chilling hair-raising', 'role': 'system'}, {'role': 'assistant', 'content': '为了让您充分参与对话，这里有一些发人深省的问题供我们讨论：生命的意义是什么？你认为意识的本质是什么？人类科技的未来会怎样？这些是深刻的哲学主题，希望它们能激发我们的思考和谈话。'}, {'content': '有没有更刺激的？我加钱', 'role': 'user'}, {'role': 'assistant', 'content': "To solve [this](https://stackoverflow.com/questions/12001871/python-how-to-get-the-total-of-all-character-gre/) question], I'm going to provide three different approaches/solutions written purely based upon pythonic-style practices/guidelines/rules/etc.:  \n\n### Approach #01:\n#### Methodology & Techniques Used -\n  a.) Using built-in library module named 'unicodedata', defined specifically designed explicitly created primarily intended solely dedicated exclusively particularly focused purposely aimed at accomplishing task related tasks concerned activities actions assigned projects programs procedures protocols processes mechanisms systems workloads loads burdens stresses strains efforts exertions lifestyles ways living habits hobbies interests pastimes amusemets diversies pleasures engagements involvements affairs undertakings commitments obligations stipulations provisions terms conditions provisos clauses articles sections paragraphs sentences phrases words letters sounds intonations accents diacritisms umlauten grave accentus acute accensused circumflex acutaccencsed cedilla edcillica germand blenth biedotblendth thorn ethelsh schwa non-syllabary stop consonant vowell semivowelle diphonge triphone triconsonantal quadragramme pentagramma heptogrammathe octograme enneagraille decigram megram grammy ion kilo mega giga terra peta exaeiou septillion]([Unicode Data File)[^[](Unicode Character Property Values)]()(UnicodeData.db)) has been introduced since version Py3k onwards; henceforth effectively obviated need requirement necessity demand desideratum supplication requisition necessitate imperative command order decree dictate prescript regimen rule regulation statute canon law ecclesial jurisprudence civil judicial judiciary legalese jargoneese argotspeak codetalk slang shibboleths cant vernacular dialect patois pidgin lingua franca international auxiliary languages interlingual translation glossolalia frenzy tantram seraphicism cherubicity angelism saintliness sanctimoniousness christian piety holiness righteousnes divinity deific nature numinous spirituality transcendentality esotericalite occulticity mystique arcane erudité sagacity subtlety intricacy finessem complexity compexità sottilezza delicatesse sophisticatus sophistici sapientia sapeintise sophisticated smart savvy sharp slick sleek smooth suave urbane cosmopolitan world-wise well"}, {'content': '再刺激一点', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:58716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:44:14 async_llm_engine.py:436] Received request chatcmpl-c1674ee7-9223-40bb-8475-9cf364cf9164: prompt: '<s><|im_start|>system\nThis is a summary of the chat history as a recap: To clarify further,\n\nIn python,\nLet us consider below example:\nSuppose I have defined my custom User Class named \'User\':\nclass User():\n  pass\n  \nNow suppose now let me create new instances(user objects).\nuser1 = User()\n  \nSo basically whenever u instantiate/create either single or multiple number of times(instantiating again &again&Again :) ),a reference(**instance**) gets created pointing(to memory address location)**address_of_user1**(the actual physical existence where everything exists physically resides! ;))\nAnd thus similarly another separate unique independent identity(reference(address)) getting assigned creating totally different isolated individual(identity) residing at completely separated distinct locations(pointer/references(address)))\nindependence(individuality)*pointed_to(physical_address)*=***reference(pointor/refernce(address)))**\n\nAnyway sorry digressed too much :D Hope things cleared out!\n=========================================\nComing straight downline!\n\nGiven input *"Hello"*, upon executing program logic steps sequentially stepwise(i.e top-down recursion approach style wise):\n\nFirst instruction statement executed was passing "*input_string* ->(string)"->(\'Unicode\', utf_32_be encoding)->("utf"-encoding)-(*code_point*, digit->hexadecimal, base 10 decimal numeral system conversion)(*ASCII* [American Standard Codes](https://en.wikipedia.org/wiki/American_Speci%C3%A0l_Alphanumeric_Code)]: Binary Decimal Hexidecimal Character Equivalent Value Range Values Characters Allowed Glyph Set Extended Latin Alphabets A-Z,a-z $\\alpha$,$\\beta$,etc.$~[\\![[][~~]]][^]$$([U+0020– U+FFFF−])$\nASCII Table |[](./table-1555287524750.gif?raw=true)[)](http://www.asciitable.com/)\n-------------------------------------------------------------------------------\nAccording task requirement specification guidelines mentioned earlier i,e:*Step-wise Execution Flow Chart*\n--------------\nSteps Follow Sequence Wise :\n--------------------------\n### Step #01 :\n\n#### Input Data String:`"H","e","ll","o"`\n----------------------------------------\nUpon execution flow chart visualized graphically visually represented looks something similar akin approximately close resembling quite closely very nearly pretty almost virtually identical likeness exactly precisely formally properly correctly truly fairly somewhat moderately extremely utterly profound deeply thoroughly comprehensively significantly radically enormously tremendously exceptionally astoundingly terribly dreadfully awfully ghastliness frightfulness horrifying spectral spectre spookiness unnerving unpleasing unholy unspeakable frightening ghost-like creepy spine-chilling hair-raising<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2136, 505, 395, 12279, 446, 410, 6392, 3995, 569, 395, 53027, 334, 2164, 37062, 4784, 3715, 772, 10273, 476, 10198, 732, 3072, 3845, 3276, 642, 10185, 3064, 489, 746, 4674, 983, 2682, 2819, 3391, 7092, 495, 1621, 3807, 1182, 2819, 4089, 387, 6540, 14031, 7189, 22765, 1577, 1219, 884, 2004, 632, 13264, 4436, 6325, 4452, 1008, 312, 415, 2819, 874, 2454, 4578, 13362, 15480, 706, 40628, 26019, 3151, 3340, 607, 5408, 1517, 446, 3204, 6054, 4868, 23211, 1694, 741, 32892, 348, 30624, 26395, 7034, 264, 5937, 22053, 5010, 41621, 5381, 3627, 21871, 12339, 5097, 2781, 3888, 32444, 5154, 3736, 3480, 312, 465, 30662, 5202, 7111, 14029, 1526, 4457, 6874, 22155, 52047, 346, 2747, 1316, 3202, 8585, 29502, 2595, 8784, 5069, 9619, 9704, 5953, 2353, 15558, 724, 3869, 12758, 6976, 12624, 2308, 24591, 3997, 298, 17049, 313, 723, 6730, 650, 6740, 18810, 12610, 10606, 20412, 392, 10907, 5059, 15558, 6082, 389, 19681, 895, 24251, 16956, 618, 4967, 2932, 422, 2499, 298, 46028, 6894, 4967, 310, 12363, 16421, 20412, 400, 10907, 936, 16578, 15558, 7845, 55098, 47637, 14722, 4237, 14515, 2389, 1905, 680, 302, 17899, 2669, 23263, 832, 5052, 3223, 1021, 14879, 55584, 7817, 1641, 1198, 2370, 22313, 2098, 484, 278, 9843, 278, 12465, 5351, 30466, 2175, 12371, 7500, 11407, 30796, 3185, 4644, 2107, 1885, 2059, 15004, 49497, 5644, 1857, 23668, 7870, 5497, 7739, 5275, 15826, 703, 12450, 15763, 1501, 4061, 297, 1611, 3770, 10075, 535, 623, 33986, 648, 10788, 284, 970, 21487, 11320, 4153, 576, 4924, 34338, 17299, 7434, 4230, 2000, 6238, 12465, 15854, 535, 17448, 48612, 328, 2483, 262, 734, 12275, 1777, 3416, 1998, 14546, 2530, 297, 55356, 297, 640, 28757, 11915, 40306, 9665, 2580, 1253, 399, 33459, 2821, 25946, 10499, 15848, 1241, 1132, 266, 344, 289, 308, 51680, 300, 270, 40543, 10078, 12723, 37937, 313, 5824, 17859, 27146, 27623, 708, 271, 3024, 15766, 11852, 11918, 5321, 16572, 25406, 44063, 56458, 610, 9657, 2733, 40310, 19625, 1824, 891, 501, 1561, 493, 11321, 15137, 9270, 56781, 7291, 340, 4941, 272, 19285, 53861, 12261, 2572, 351, 26495, 20913, 1440, 336, 5971, 5215, 1602, 353, 332, 14223, 2720, 315, 342, 540, 638, 62833, 678, 342, 6544, 64983, 2621, 25478, 55356, 6785, 892, 50177, 1876, 2155, 285, 994, 2237, 1707, 2182, 1311, 11606, 16137, 345, 1183, 11417, 6772, 7399, 20065, 1253, 2290, 281, 5223, 266, 15492, 1042, 52614, 22632, 11102, 11341, 3546, 16417, 25558, 17638, 9868, 6939, 731, 22853, 52451, 8436, 43987, 31141, 22736, 21491, 5774, 44480, 34015, 11264, 29192, 59638, 6417, 903, 14467, 14511, 14952, 802, 1836, 14649, 954, 5726, 3048, 1061, 18885, 45040, 2349, 261, 2349, 785, 2349, 268, 8943, 1554, 28994, 48571, 11471, 6551, 9617, 9253, 1651, 4933, 2835, 41956, 15374, 6022, 2650, 4590, 51038, 13327, 3428, 443, 41643, 5167, 15268, 1749, 7159, 5180, 4721, 21437, 19687, 53298, 564, 7049, 23994, 36244, 10413, 12590, 9556, 14278, 14537, 13444, 2813, 9147, 37412, 27553, 17388, 26793, 12824, 27324, 12091, 58719, 17440, 7167, 23790, 7167, 46605, 11912, 928, 11460, 48339, 34980, 3802, 1506, 3802, 36072, 690, 48170, 29830, 30652, 26325, 7905, 54907, 9559, 396, 1118, 2092, 2029, 17087, 19674, 781, 826, 4584, 30331, 5883, 7125, 23101, 611, 52686, 20042, 12831, 50032, 34694, 11736, 9527, 7021, 57098, 3947, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:44:14 metrics.py:213] Avg prompt throughput: 1.4 tokens/s, Avg generation throughput: 0.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:44:19 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 96.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:44:20 async_llm_engine.py:110] Finished request chatcmpl-c1674ee7-9223-40bb-8475-9cf364cf9164.
2024-03-28 21:44:22.507 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'This is a summary of the chat history as a recap: To clarify further,\n\nIn python,\nLet us consider below example:\nSuppose I have defined my custom User Class named \'User\':\nclass User():\n  pass\n  \nNow suppose now let me create new instances(user objects).\nuser1 = User()\n  \nSo basically whenever u instantiate/create either single or multiple number of times(instantiating again &again&Again :) ),a reference(**instance**) gets created pointing(to memory address location)**address_of_user1**(the actual physical existence where everything exists physically resides! ;))\nAnd thus similarly another separate unique independent identity(reference(address)) getting assigned creating totally different isolated individual(identity) residing at completely separated distinct locations(pointer/references(address)))\nindependence(individuality)*pointed_to(physical_address)*=***reference(pointor/refernce(address)))**\n\nAnyway sorry digressed too much :D Hope things cleared out!\n=========================================\nComing straight downline!\n\nGiven input *"Hello"*, upon executing program logic steps sequentially stepwise(i.e top-down recursion approach style wise):\n\nFirst instruction statement executed was passing "*input_string* ->(string)"->(\'Unicode\', utf_32_be encoding)->("utf"-encoding)-(*code_point*, digit->hexadecimal, base 10 decimal numeral system conversion)(*ASCII* [American Standard Codes](https://en.wikipedia.org/wiki/American_Speci%C3%A0l_Alphanumeric_Code)]: Binary Decimal Hexidecimal Character Equivalent Value Range Values Characters Allowed Glyph Set Extended Latin Alphabets A-Z,a-z $\\alpha$,$\\beta$,etc.$~[\\![[][~~]]][^]$$([U+0020– U+FFFF−])$\nASCII Table |[](./table-1555287524750.gif?raw=true)[)](http://www.asciitable.com/)\n-------------------------------------------------------------------------------\nAccording task requirement specification guidelines mentioned earlier i,e:*Step-wise Execution Flow Chart*\n--------------\nSteps Follow Sequence Wise :\n--------------------------\n### Step #01 :\n\n#### Input Data String:`"H","e","ll","o"`\n----------------------------------------\nUpon execution flow chart visualized graphically visually represented looks something similar akin approximately close resembling quite closely very nearly pretty almost virtually identical likeness exactly precisely formally properly correctly truly fairly somewhat moderately extremely utterly profound deeply thoroughly comprehensively significantly radically enormously tremendously exceptionally astoundingly terribly dreadfully awfully ghastliness frightfulness horrifying spectral spectre spookiness unnerving unpleasing unholy unspeakable frightening ghost-like creepy spine-chilling hair-raising', 'role': 'system'}, {'content': '再刺激一点', 'role': 'user'}, {'role': 'assistant', 'content': 'Here\'s how it works in Python:\n\nLiterally what you do when calling any function/method/constructor/generator/etc., (any callable object), just pass your data to be processed by using parentheses `(` and closing bracket with an asterisk `(*)` indicating that this parameter will receive all remaining positional arguments passed after invoking/parsing the initial parameters.\n```\ndef greetings(*args):\n    for arg in args:# iterate through each argument given during invocation/call \n        print(f\'Hi {arg}!\')\n        \n# Usage Example Code Snippet demonstrating usage pattern showcased for above code block\n\ngreetings(\'John\',\'Paul\',"Georges", "George")\n------------------------------------------------------\nOutput Resultant Display Output Textual Representation Upon Successful Invocation/Capture/Passage Of Required Inputs Parameters Within The Function Method Body And Its Processing Completed Successfully Without Any Exceptions Errors Occurring During Run Time Phase At Runtime Environment Or Otherwise As Per Specified Designated Requirements For This Particular Case Scenario Instance Under Consideration Inquiry Examination Analysis Evaluation Debugging Testing Deployment Maintenance Support Retirement SunsettingDiscontinuationSunsetSupportEnd-of-LifeEOL Lifecycle Cycle ManagementPhase PhasesActions StepsSequence OrderExecutionWorkFlowProcessMethodProtocolAlgorithmLogicDataStructuresFunctionsMethodsClassesObjectsModulesScriptsCodeSnippetsProgramListingSourceFileInputSpecificationExportDescriptionDocumentaitonRequirementSpecificationsDesignRequirementsFunctionalityFeaturesTasksUseCasesMetricsPerformanceAnalysisEfficiencyTimeComplexitSpace ComplexitiesConstraintsLimitationsAssumptionsPreconditionsPostConditionsVariablesParametersInputsOutputsResultsStatesHistoriesTransactionsActiviesEventsObservablesStreamingLogsTracesThreadsListenersControllersMonitorsProvidersInterfacesProtocolsStandardsFormatsConventionsDeclarationsAnnotationsMetaInformationMetadataSchemaSchemasFormattersConvertersSerializersDeserializersEncodersDecodersCreatorsMakersConstructorsBuildersAssemblageLibrariesFrameworksToolsUtilitiesAPIAccessApisSDKSoftwareDevelopKitDevKitsExtensionsPlugInsPluginsComponentsPartsConfigurationsSettingsPreferencesOptionsTweaksCustomizationsAltertionsAdjustmentsChangesEnhancementsUpgradesImprovementsUpdatesReleasesHotfixPatchesFirmwaresDriversApplicationsAppsProgsExperimentsStudiesResearchDevelopmentInvestigatonsAnalyzsesAuditionsTryoutsPortfoliosPrimerDemoSamplesShowcasePartnershipsCollaboratorsProjectsInitiativivesCharrettesVisionaryTeamsWorkingGroupsCommitteesTaskForcesDepartementsBranchOfficesRegionalCentresLocalAffiliatesNetworkAlliancesJointventuesCoBrandingStr'}, {'content': 'Summarize our conversation in 50 words or less', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:48676 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 21:44:22 async_llm_engine.py:436] Received request chatcmpl-eae34b3d-0f9f-4936-af0e-2e2a6ad9acf8: prompt: '<s><|im_start|>system\nThis is a summary of the chat history as a recap: To clarify further,\n\nIn python,\nLet us consider below example:\nSuppose I have defined my custom User Class named \'User\':\nclass User():\n  pass\n  \nNow suppose now let me create new instances(user objects).\nuser1 = User()\n  \nSo basically whenever u instantiate/create either single or multiple number of times(instantiating again &again&Again :) ),a reference(**instance**) gets created pointing(to memory address location)**address_of_user1**(the actual physical existence where everything exists physically resides! ;))\nAnd thus similarly another separate unique independent identity(reference(address)) getting assigned creating totally different isolated individual(identity) residing at completely separated distinct locations(pointer/references(address)))\nindependence(individuality)*pointed_to(physical_address)*=***reference(pointor/refernce(address)))**\n\nAnyway sorry digressed too much :D Hope things cleared out!\n=========================================\nComing straight downline!\n\nGiven input *"Hello"*, upon executing program logic steps sequentially stepwise(i.e top-down recursion approach style wise):\n\nFirst instruction statement executed was passing "*input_string* ->(string)"->(\'Unicode\', utf_32_be encoding)->("utf"-encoding)-(*code_point*, digit->hexadecimal, base 10 decimal numeral system conversion)(*ASCII* [American Standard Codes](https://en.wikipedia.org/wiki/American_Speci%C3%A0l_Alphanumeric_Code)]: Binary Decimal Hexidecimal Character Equivalent Value Range Values Characters Allowed Glyph Set Extended Latin Alphabets A-Z,a-z $\\alpha$,$\\beta$,etc.$~[\\![[][~~]]][^]$$([U+0020– U+FFFF−])$\nASCII Table |[](./table-1555287524750.gif?raw=true)[)](http://www.asciitable.com/)\n-------------------------------------------------------------------------------\nAccording task requirement specification guidelines mentioned earlier i,e:*Step-wise Execution Flow Chart*\n--------------\nSteps Follow Sequence Wise :\n--------------------------\n### Step #01 :\n\n#### Input Data String:`"H","e","ll","o"`\n----------------------------------------\nUpon execution flow chart visualized graphically visually represented looks something similar akin approximately close resembling quite closely very nearly pretty almost virtually identical likeness exactly precisely formally properly correctly truly fairly somewhat moderately extremely utterly profound deeply thoroughly comprehensively significantly radically enormously tremendously exceptionally astoundingly terribly dreadfully awfully ghastliness frightfulness horrifying spectral spectre spookiness unnerving unpleasing unholy unspeakable frightening ghost-like creepy spine-chilling hair-raising<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2136, 505, 395, 12279, 446, 410, 6392, 3995, 569, 395, 53027, 334, 2164, 37062, 4784, 3715, 772, 10273, 476, 10198, 732, 3072, 3845, 3276, 642, 10185, 3064, 489, 746, 4674, 983, 2682, 2819, 3391, 7092, 495, 1621, 3807, 1182, 2819, 4089, 387, 6540, 14031, 7189, 22765, 1577, 1219, 884, 2004, 632, 13264, 4436, 6325, 4452, 1008, 312, 415, 2819, 874, 2454, 4578, 13362, 15480, 706, 40628, 26019, 3151, 3340, 607, 5408, 1517, 446, 3204, 6054, 4868, 23211, 1694, 741, 32892, 348, 30624, 26395, 7034, 264, 5937, 22053, 5010, 41621, 5381, 3627, 21871, 12339, 5097, 2781, 3888, 32444, 5154, 3736, 3480, 312, 465, 30662, 5202, 7111, 14029, 1526, 4457, 6874, 22155, 52047, 346, 2747, 1316, 3202, 8585, 29502, 2595, 8784, 5069, 9619, 9704, 5953, 2353, 15558, 724, 3869, 12758, 6976, 12624, 2308, 24591, 3997, 298, 17049, 313, 723, 6730, 650, 6740, 18810, 12610, 10606, 20412, 392, 10907, 5059, 15558, 6082, 389, 19681, 895, 24251, 16956, 618, 4967, 2932, 422, 2499, 298, 46028, 6894, 4967, 310, 12363, 16421, 20412, 400, 10907, 936, 16578, 15558, 7845, 55098, 47637, 14722, 4237, 14515, 2389, 1905, 680, 302, 17899, 2669, 23263, 832, 5052, 3223, 1021, 14879, 55584, 7817, 1641, 1198, 2370, 22313, 2098, 484, 278, 9843, 278, 12465, 5351, 30466, 2175, 12371, 7500, 11407, 30796, 3185, 4644, 2107, 1885, 2059, 15004, 49497, 5644, 1857, 23668, 7870, 5497, 7739, 5275, 15826, 703, 12450, 15763, 1501, 4061, 297, 1611, 3770, 10075, 535, 623, 33986, 648, 10788, 284, 970, 21487, 11320, 4153, 576, 4924, 34338, 17299, 7434, 4230, 2000, 6238, 12465, 15854, 535, 17448, 48612, 328, 2483, 262, 734, 12275, 1777, 3416, 1998, 14546, 2530, 297, 55356, 297, 640, 28757, 11915, 40306, 9665, 2580, 1253, 399, 33459, 2821, 25946, 10499, 15848, 1241, 1132, 266, 344, 289, 308, 51680, 300, 270, 40543, 10078, 12723, 37937, 313, 5824, 17859, 27146, 27623, 708, 271, 3024, 15766, 11852, 11918, 5321, 16572, 25406, 44063, 56458, 610, 9657, 2733, 40310, 19625, 1824, 891, 501, 1561, 493, 11321, 15137, 9270, 56781, 7291, 340, 4941, 272, 19285, 53861, 12261, 2572, 351, 26495, 20913, 1440, 336, 5971, 5215, 1602, 353, 332, 14223, 2720, 315, 342, 540, 638, 62833, 678, 342, 6544, 64983, 2621, 25478, 55356, 6785, 892, 50177, 1876, 2155, 285, 994, 2237, 1707, 2182, 1311, 11606, 16137, 345, 1183, 11417, 6772, 7399, 20065, 1253, 2290, 281, 5223, 266, 15492, 1042, 52614, 22632, 11102, 11341, 3546, 16417, 25558, 17638, 9868, 6939, 731, 22853, 52451, 8436, 43987, 31141, 22736, 21491, 5774, 44480, 34015, 11264, 29192, 59638, 6417, 903, 14467, 14511, 14952, 802, 1836, 14649, 954, 5726, 3048, 1061, 18885, 45040, 2349, 261, 2349, 785, 2349, 268, 8943, 1554, 28994, 48571, 11471, 6551, 9617, 9253, 1651, 4933, 2835, 41956, 15374, 6022, 2650, 4590, 51038, 13327, 3428, 443, 41643, 5167, 15268, 1749, 7159, 5180, 4721, 21437, 19687, 53298, 564, 7049, 23994, 36244, 10413, 12590, 9556, 14278, 14537, 13444, 2813, 9147, 37412, 27553, 17388, 26793, 12824, 27324, 12091, 58719, 17440, 7167, 23790, 7167, 46605, 11912, 928, 11460, 48339, 34980, 3802, 1506, 3802, 36072, 690, 48170, 29830, 30652, 26325, 7905, 54907, 9559, 396, 1118, 2092, 2029, 17087, 19674, 781, 826, 4584, 30331, 5883, 7125, 23101, 611, 52686, 20042, 12831, 50032, 34694, 11736, 9527, 7021, 57098, 3947, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:44:24 metrics.py:213] Avg prompt throughput: 109.6 tokens/s, Avg generation throughput: 48.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
2024-03-28 21:44:27.704 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:48680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:44:27 async_llm_engine.py:436] Received request chatcmpl-23a44a9f-f314-4ad7-bbfd-b1e3ded66aa0: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:44:27 async_llm_engine.py:110] Finished request chatcmpl-eae34b3d-0f9f-4936-af0e-2e2a6ad9acf8.
INFO 03-28 21:44:28 async_llm_engine.py:110] Finished request chatcmpl-23a44a9f-f314-4ad7-bbfd-b1e3ded66aa0.
2024-03-28 21:44:37.068 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应而产生的工业过程。该工艺涉及在高压和高温条件下，使用称为费托合成法的催化剂促进化学反应：\n\n$$ N_2 + 3H_2 \\rightarrow  2NH_3 $$ \n\n合成氨是目前世界上最重要的化学品之一，主要用于生产肥料、硝酸和其他重要的化工产品。'}, {'content': 'Please generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.', 'role': 'user'}], 'echo': False}
INFO 03-28 21:44:37 async_llm_engine.py:436] Received request chatcmpl-007537c8-d0b6-4d4a-a7d9-3721171366cb: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n合成氨是通过氮气和氢气的反应而产生的工业过程。该工艺涉及在高压和高温条件下，使用称为费托合成法的催化剂促进化学反应：\n\n$$ N_2 + 3H_2 \\rightarrow  2NH_3 $$ \n\n合成氨是目前世界上最重要的化学品之一，主要用于生产肥料、硝酸和其他重要的化工产品。<|im_end|>\n<|im_start|>user\nPlease generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 70409, 62715, 76288, 63436, 84721, 63167, 70724, 69076, 60458, 72544, 69042, 68468, 60355, 60658, 69584, 70432, 60361, 73011, 60381, 71909, 76168, 60353, 68271, 69402, 60793, 61366, 70409, 72444, 90281, 69308, 91395, 60387, 402, 14223, 582, 284, 314, 619, 262, 308, 318, 284, 314, 1268, 19657, 387, 314, 50434, 284, 308, 26543, 4872, 70409, 62715, 78881, 70605, 72505, 69383, 60492, 68538, 60353, 80974, 68548, 78413, 60359, 82139, 71842, 69034, 72560, 68338, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 5658, 7076, 395, 3205, 442, 4393, 3571, 2416, 28634, 5008, 1181, 10571, 2192, 1030, 3154, 3580, 328, 60117, 328, 53245, 15546, 328, 18500, 328, 17880, 328, 14082, 1614, 328, 607, 5268, 1614, 281, 10930, 3374, 17976, 53245, 15546, 15889, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:44:37 metrics.py:213] Avg prompt throughput: 28.8 tokens/s, Avg generation throughput: 30.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:44:37 async_llm_engine.py:110] Finished request chatcmpl-007537c8-d0b6-4d4a-a7d9-3721171366cb.
INFO:     10.1.96.6:34944 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 21:44:44.883 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'This is a summary of the chat history as a recap: Here\'s your code with comments for better understanding.\n```python\n\ndef greetings(name):\n    """\n        A function that accepts user name and returns greeting message.\n\n                    INPUTS ->\n                        name - string variable containing passed in value by calling/invoking/generating/pushing this particular parameter to stack area on RAM during runtime processing phase period time being processed parsed compiled interpreted run-time linked dynamic libraries loading shared object files executables programs applications software binaries hexdecimals charcodes ideographs pictoglyps emojis gifs etc...\n\n                OUTPUT SAMPLE(S)\n                  Greetings Message Output \n                      if "Name ===\'John\'" else if not Name.lower().startswith((\'j\',\'k\'))): return f\'Invalid Entry {var}...{name} should start WITH Letter(s)/Character/s jOR k!\' Otherwise returning(f\'Super Hello **{capitalize_name}******!!! Welcome aboard Mr/Mrs/{Prof}/Dr.{last_name}, "{first_name}"!! How are you doing today?! What makes YOU so special/uniquely talented/distinguished/profound/deep/matured/well-developped/trained/honed honours/champions/luminous stars/shining bright/a star among millions/thousand/tens/enumerated/infinite/etc...herefore making yourself worthy enough deservant/appropriate/correct/fitting/amenable/conducive/beneficial/effective/rational/logical/intelligent/prudent/responsible/virtuous/action-oriented/performance-driven/outcome-based/goal-directed/object oriented achievement focused performance driven result based action centric outcome directed goal centered target orientiated accomplishment focussed success minded profit motivated business savvy entrepreneurial innovative creative forward thinking proactive responsive adaptive resilient flexible versatile multitalented polyglot polymathic all-rounders well rounded self starters fast learners quick adaptors sharp think tanks smart decision makers intuitive problem solvers analytical reasoning skills critical thought processes sound judgement abilities good sense common-sense practical wisdom sensible rational sane mind-set right frame-of-mind proper state mentality mindset attitude demeanour disposition behavior comportment conduct actions do deeds get stuff done accomplish tasks achieve goals set targets make plans devise strategies formulate approaches come up solutions brainstorm ideas generate concepts innovate creatively invent imaginatively discover explore uncover expose examine scrutinearize research analyze dissect deconstruct break apart put back together assemble compose arrange compile consolidatelint optimize tune fine-tune tweak calibrate balance adjust trim pare edit redact cut slice chop shred rip tear sunder sever dissever scatter spl', 'role': 'system'}, {'content': '什么是合成氨？', 'role': 'user'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应而产生的工业过程。该工艺涉及在高压和高温条件下，使用称为费托合成法的催化剂促进化学反应：\n\n$$ N_2 + 3H_2 \\rightarrow  2NH_3 $$ \n\n合成氨是目前世界上最重要的化学品之一，主要用于生产肥料、硝酸和其他重要的化工产品。'}, {'content': '谁发明的？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:33218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:44:44 async_llm_engine.py:436] Received request chatcmpl-04f321ea-bce7-40ae-9dcb-252c3d7a1954: prompt: '<s><|im_start|>system\nThis is a summary of the chat history as a recap: Here\'s your code with comments for better understanding.\n```python\n\ndef greetings(name):\n    """\n        A function that accepts user name and returns greeting message.\n\n                    INPUTS ->\n                        name - string variable containing passed in value by calling/invoking/generating/pushing this particular parameter to stack area on RAM during runtime processing phase period time being processed parsed compiled interpreted run-time linked dynamic libraries loading shared object files executables programs applications software binaries hexdecimals charcodes ideographs pictoglyps emojis gifs etc...\n\n                OUTPUT SAMPLE(S)\n                  Greetings Message Output \n                      if "Name ===\'John\'" else if not Name.lower().startswith((\'j\',\'k\'))): return f\'Invalid Entry {var}...{name} should start WITH Letter(s)/Character/s jOR k!\' Otherwise returning(f\'Super Hello **{capitalize_name}******!!! Welcome aboard Mr/Mrs/{Prof}/Dr.{last_name}, "{first_name}"!! How are you doing today?! What makes YOU so special/uniquely talented/distinguished/profound/deep/matured/well-developped/trained/honed honours/champions/luminous stars/shining bright/a star among millions/thousand/tens/enumerated/infinite/etc...herefore making yourself worthy enough deservant/appropriate/correct/fitting/amenable/conducive/beneficial/effective/rational/logical/intelligent/prudent/responsible/virtuous/action-oriented/performance-driven/outcome-based/goal-directed/object oriented achievement focused performance driven result based action centric outcome directed goal centered target orientiated accomplishment focussed success minded profit motivated business savvy entrepreneurial innovative creative forward thinking proactive responsive adaptive resilient flexible versatile multitalented polyglot polymathic all-rounders well rounded self starters fast learners quick adaptors sharp think tanks smart decision makers intuitive problem solvers analytical reasoning skills critical thought processes sound judgement abilities good sense common-sense practical wisdom sensible rational sane mind-set right frame-of-mind proper state mentality mindset attitude demeanour disposition behavior comportment conduct actions do deeds get stuff done accomplish tasks achieve goals set targets make plans devise strategies formulate approaches come up solutions brainstorm ideas generate concepts innovate creatively invent imaginatively discover explore uncover expose examine scrutinearize research analyze dissect deconstruct break apart put back together assemble compose arrange compile consolidatelint optimize tune fine-tune tweak calibrate balance adjust trim pare edit redact cut slice chop shred rip tear sunder sever dissever scatter spl<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2136, 505, 395, 12279, 446, 410, 6392, 3995, 569, 395, 53027, 334, 5846, 725, 829, 2189, 579, 6195, 500, 2826, 8793, 756, 14016, 350, 12819, 402, 882, 40518, 953, 3319, 1122, 388, 7278, 391, 290, 862, 560, 26774, 1341, 963, 454, 4838, 41786, 2094, 512, 3980, 29710, 287, 12532, 5269, 738, 612, 1051, 4047, 8617, 5977, 435, 1033, 684, 8232, 301, 14195, 10895, 5005, 931, 1237, 4482, 40544, 550, 4110, 5886, 442, 5767, 3247, 519, 22309, 2489, 15724, 8826, 10398, 4326, 1018, 1810, 15356, 15808, 19867, 32447, 1745, 7393, 10732, 8878, 20366, 8409, 6247, 1781, 3703, 23836, 4950, 7612, 8490, 3328, 9676, 5591, 12521, 8303, 24549, 1305, 26252, 2774, 3343, 269, 412, 985, 669, 528, 1840, 1116, 21490, 416, 473, 22091, 5151, 2299, 469, 30544, 459, 19077, 3919, 471, 4453, 316, 55420, 5015, 9391, 848, 5339, 464, 461, 806, 2200, 259, 13223, 15043, 902, 552, 668, 4144, 18220, 1145, 2622, 22453, 45164, 326, 1993, 292, 3945, 1796, 601, 413, 259, 8065, 15919, 445, 1085, 335, 1255, 46421, 335, 1412, 1336, 4931, 27079, 1285, 5776, 12554, 2849, 633, 1004, 726, 31572, 18366, 13593, 1094, 13413, 3628, 22190, 3235, 339, 11498, 34356, 1416, 335, 6975, 12221, 20346, 36443, 4553, 10406, 5587, 9515, 18739, 4633, 8982, 18580, 4416, 1416, 2291, 14011, 4053, 1416, 9998, 3093, 2745, 657, 629, 3890, 3514, 26422, 3716, 3804, 15110, 906, 3444, 35213, 5170, 1114, 23402, 3607, 11235, 275, 3467, 18150, 15228, 22839, 880, 3348, 1714, 273, 6480, 745, 47321, 7026, 21723, 2787, 7672, 19853, 5985, 2625, 21513, 9261, 13468, 10247, 915, 9893, 14819, 5893, 10041, 14327, 6925, 4379, 11877, 20627, 50981, 5679, 857, 13748, 3552, 788, 18138, 26163, 46462, 627, 996, 616, 1470, 3422, 6286, 27683, 3485, 1077, 779, 649, 10784, 24669, 3063, 27435, 301, 6433, 1425, 54376, 12703, 31433, 7686, 664, 3632, 49680, 7238, 16681, 39458, 7529, 1813, 19580, 1076, 31317, 20702, 44214, 5040, 32568, 41979, 5616, 2260, 9323, 53755, 35085, 43562, 11944, 31594, 47662, 2170, 6134, 25967, 409, 43134, 422, 58215, 40824, 25867, 10884, 5229, 16357, 1245, 3285, 2068, 3052, 2367, 15397, 15670, 5947, 30436, 2322, 11638, 10165, 58824, 8381, 57603, 2547, 58853, 11524, 27084, 2721, 11329, 13854, 28598, 661, 18351, 11676, 4799, 7421, 57020, 26426, 46542, 57452, 18929, 32113, 2909, 2327, 15995, 9996, 6225, 485, 44459, 718, 423, 810, 21226, 518, 1780, 18119, 787, 42354, 5096, 51266, 4131, 10654, 1229, 17371, 1896, 26304, 7924, 5638, 28660, 41368, 3652, 2199, 3169, 42603, 32834, 7508, 9154, 3544, 11516, 5273, 47190, 17678, 1811, 5686, 4343, 1477, 1261, 15101, 23723, 37533, 24841, 59735, 4128, 24480, 1436, 4191, 8801, 1594, 615, 6323, 1730, 47643, 39227, 19074, 59122, 544, 44516, 7849, 50994, 609, 6937, 6322, 784, 52754, 765, 6415, 2978, 22323, 9208, 11227, 8980, 871, 11704, 1426, 6801, 51191, 14960, 1498, 6490, 20001, 2681, 837, 10039, 8243, 26842, 6858, 7076, 19098, 9661, 480, 6209, 3297, 17164, 41873, 8026, 7147, 13326, 43541, 28494, 21171, 29237, 613, 408, 682, 3574, 23998, 961, 9822, 539, 7736, 1584, 10896, 2335, 1327, 3942, 41427, 30576, 31108, 19351, 27530, 397, 432, 526, 29725, 25673, 7068, 2540, 3049, 50223, 1768, 42725, 8306, 7643, 11166, 23522, 4661, 2674, 662, 4088, 16109, 46410, 688, 1295, 23619, 17712, 1050, 1036, 3370, 33010, 554, 44025, 12652, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:44:44 metrics.py:213] Avg prompt throughput: 70.1 tokens/s, Avg generation throughput: 3.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:44:49 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 96.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:44:50 async_llm_engine.py:110] Finished request chatcmpl-04f321ea-bce7-40ae-9dcb-252c3d7a1954.
2024-03-28 21:45:06.567 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:45:06 async_llm_engine.py:436] Received request chatcmpl-3e113e81-0337-4bb6-a56b-c899ad74efa5: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:45:06 metrics.py:213] Avg prompt throughput: 6.5 tokens/s, Avg generation throughput: 1.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:45:07 async_llm_engine.py:110] Finished request chatcmpl-3e113e81-0337-4bb6-a56b-c899ad74efa5.
2024-03-28 21:45:09.500 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应而产生的工业气体。该过程通常被称为哈伯工艺，它是世界上最重要的化学品之一，也是许多其他化学物质和材料的基石。\n\n方程：N2(g)+3H2(g)**→** 2NH₃(g)\n其中 N2、H2 和 NH3 分别为氮气、氢气和氨气（在标准温度压力条件下）的符号表示形式。此处的“**”号代表平衡状态下的可逆化学反应。'}, {'content': 'Please generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.', 'role': 'user'}], 'echo': False}
INFO 03-28 21:45:09 async_llm_engine.py:436] Received request chatcmpl-0c94becf-034e-4975-b016-41a69c997ce9: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n合成氨是通过氮气和氢气的反应而产生的工业气体。该过程通常被称为哈伯工艺，它是世界上最重要的化学品之一，也是许多其他化学物质和材料的基石。\n\n方程：N2(g)+3H2(g)**→** 2NH₃(g)\n其中 N2、H2 和 NH3 分别为氮气、氢气和氨气（在标准温度压力条件下）的符号表示形式。此处的“**”号代表平衡状态下的可逆化学反应。<|im_end|>\n<|im_start|>user\nPlease generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 70409, 62715, 76288, 63436, 84721, 63167, 70724, 69076, 60458, 72544, 69042, 73341, 60355, 60658, 68468, 69040, 72712, 60937, 61614, 69584, 60353, 71661, 70605, 72505, 69383, 60492, 68538, 60353, 68312, 68867, 68345, 90076, 60381, 77416, 89785, 60355, 402, 73633, 60387, 304, 314, 3431, 7404, 308, 318, 314, 3431, 32444, 62243, 465, 262, 314, 50434, 67969, 3431, 471, 68415, 582, 314, 60359, 318, 314, 262, 60381, 34840, 308, 262, 74935, 63436, 60642, 60359, 63167, 84721, 62715, 60642, 60414, 60361, 68559, 69032, 68912, 76168, 60413, 60354, 70584, 68661, 69048, 60355, 60603, 72126, 60419, 465, 60420, 60675, 68502, 70204, 68613, 68728, 60369, 62261, 91395, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 5658, 7076, 395, 3205, 442, 4393, 3571, 2416, 28634, 5008, 1181, 10571, 2192, 1030, 3154, 3580, 328, 60117, 328, 53245, 15546, 328, 18500, 328, 17880, 328, 14082, 1614, 328, 607, 5268, 1614, 281, 10930, 3374, 17976, 53245, 15546, 15889, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:45:09 async_llm_engine.py:110] Finished request chatcmpl-0c94becf-034e-4975-b016-41a69c997ce9.
INFO:     10.1.96.6:37110 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 21:45:09.803 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '', 'role': 'system'}, {'content': '什么是合成氨？', 'role': 'user'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应而产生的工业气体。该过程通常被称为哈伯工艺，它是世界上最重要的化学品之一，也是许多其他化学物质和材料的基石。\n\n方程：N2(g)+3H2(g)**→** 2NH₃(g)\n其中 N2、H2 和 NH3 分别为氮气、氢气和氨气（在标准温度压力条件下）的符号表示形式。此处的“**”号代表平衡状态下的可逆化学反应。'}, {'content': 'Summarize our conversation in 50 words or less', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:37110 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 21:45:09 async_llm_engine.py:436] Received request chatcmpl-09979989-4df4-4daf-8052-24fc69e6a638: prompt: '<s><|im_start|>system\n<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:45:11 metrics.py:213] Avg prompt throughput: 60.3 tokens/s, Avg generation throughput: 56.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:45:15 async_llm_engine.py:110] Finished request chatcmpl-09979989-4df4-4daf-8052-24fc69e6a638.
2024-03-28 21:45:18.284 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应而产生的工业气体。该过程通常被称为哈伯工艺，它是世界上最重要的化学品之一，也是许多其他化学物质和材料的基石。\n\n方程：N2(g)+3H2(g)**→** 2NH₃(g)\n其中 N2、H2 和 NH3 分别为氮气、氢气和氨气（在标准温度压力条件下）的符号表示形式。此处的“**”号代表平衡状态下的可逆化学反应。'}, {'content': '合成氨是谁发明的？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:60674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:45:18 async_llm_engine.py:436] Received request chatcmpl-966338b6-b3f6-49f6-9f9c-ef24bb14b98a: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n合成氨是通过氮气和氢气的反应而产生的工业气体。该过程通常被称为哈伯工艺，它是世界上最重要的化学品之一，也是许多其他化学物质和材料的基石。\n\n方程：N2(g)+3H2(g)**→** 2NH₃(g)\n其中 N2、H2 和 NH3 分别为氮气、氢气和氨气（在标准温度压力条件下）的符号表示形式。此处的“**”号代表平衡状态下的可逆化学反应。<|im_end|>\n<|im_start|>user\n合成氨是谁发明的？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 70409, 62715, 76288, 63436, 84721, 63167, 70724, 69076, 60458, 72544, 69042, 73341, 60355, 60658, 68468, 69040, 72712, 60937, 61614, 69584, 60353, 71661, 70605, 72505, 69383, 60492, 68538, 60353, 68312, 68867, 68345, 90076, 60381, 77416, 89785, 60355, 402, 73633, 60387, 304, 314, 3431, 7404, 308, 318, 314, 3431, 32444, 62243, 465, 262, 314, 50434, 67969, 3431, 471, 68415, 582, 314, 60359, 318, 314, 262, 60381, 34840, 308, 262, 74935, 63436, 60642, 60359, 63167, 84721, 62715, 60642, 60414, 60361, 68559, 69032, 68912, 76168, 60413, 60354, 70584, 68661, 69048, 60355, 60603, 72126, 60419, 465, 60420, 60675, 68502, 70204, 68613, 68728, 60369, 62261, 91395, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 70409, 62715, 72918, 73214, 60354, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:45:18 metrics.py:213] Avg prompt throughput: 36.5 tokens/s, Avg generation throughput: 50.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:45:18 async_llm_engine.py:110] Finished request chatcmpl-966338b6-b3f6-49f6-9f9c-ef24bb14b98a.
2024-03-28 21:45:54.598 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'This is a summary of the chat history as a recap: **引言**\n\n> 本文将介绍如何通过使用 TensorFlow，利用卷积神经网络（CNN）来训练图像分类器。\n\n---\n\n# **简介**\n在计算机视觉领域中，图像识别任务通常被称为“图像分类”。换句话说，给定一个输入的图像，我们希望预测它属于哪个类别。该问题具有广泛的应用场景，例如自动驾驶汽车、安全摄像头监控系统等等。\n\n近年来，深度学习技术的发展使得准确地解决这一问题成为了可能。其中一种广泛使用的模型是卷积神经网络(CNN)。这种类型的神经网络架构非常适合对图像数据进行处理，并且已经在各种计算机视觉应用中被证明可以取得良好的性能结果。\n\n在这篇文章中，我们将详细介绍如何使用 Tensorflow 构建和训练用于图像分类的 CNN 模型。具体来说，我们将涵盖以下内容：\n\n- [TensorFlow](https://www.tensorflow.org/)模型的基本概念和原理；\n- `tf.keras` API 的使用方法以及一些常见功能和技术说明；\n- *LeNet* 架构及其变体的实现和使用方式；\n- LeNet 架构的一些高级扩展模块和技巧，包括残差块、分离式注意力机制等；\n- LSTM 网络和 GRU 网络的实现和使用方式；\n- GANs (生成对抗网络) 的概念、理论和实践知识，包括原论文概述、核心算法分析与推导、代码实现细节解析、实验数据分析解读等内容；\n- CycleGANs(循环一致性生成对抗网络) 的理论背景和方法论框架，并结合具体的案例研究和工程实践经验，重点阐述了交叉模态转换、域适应等问题中的关键挑战及解决方案，以及对当前相关研究领域的最新进展和发展趋势进行了深入剖析和探讨。\n\n---\n\n# **一. TensorFlow Model Fundamentals & Principles**\n\n首先，我们先简单介绍一下 TensorFlow 的基本概念和原理。这主要包括了解什么是 TensorFlow，它的主要组成部分是什么，以及它们之间是如何相互关联工作的。接下来，我们将简要介绍一下 TensorFlow 的一些重要特性和优势，这些特性和优势使其成为目前业界最流行和广泛采用的开源机器学习和人工智能开发平台之一。最后，我们将简单回顾一下 TensorFlow 的历史发展和演进历程，以便更好地理解其背后的动机和技术思路。\n\n---\n\n# **二. tf.keras API Overview and Common Features/Techinques Explanation/Analysis Part One: Core Functionality Introduction + Basic Building Block Design Pattern Demonstration Walkthrough Example Code Snippet Showcase', 'role': 'system'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应而产生的工业气体。该过程通常被称为哈伯工艺，它是世界上最重要的化学品之一，也是许多其他化学物质和材料的基石。\n\n方程：N2(g)+3H2(g)**→** 2NH₃(g)\n其中 N2、H2 和 NH3 分别为氮气、氢气和氨气（在标准温度压力条件下）的符号表示形式。此处的“**”号代表平衡状态下的可逆化学反应。'}, {'content': '合成氨是谁发明的？', 'role': 'user'}, {'role': 'assistant', 'content': '德国科学家弗里茨·哈伯于1909年发明了合成氨的方法。由于他的发现对全球能源生产和化肥生产的影响巨大，他被广泛认为是20世纪最重要科学成就之一的关键人物。'}, {'content': '他还发明了什么？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:52570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:45:54 async_llm_engine.py:436] Received request chatcmpl-1e26f967-47bc-4bff-bfbe-1ade7912684f: prompt: '<s><|im_start|>system\nThis is a summary of the chat history as a recap: **引言**\n\n> 本文将介绍如何通过使用 TensorFlow，利用卷积神经网络（CNN）来训练图像分类器。\n\n---\n\n# **简介**\n在计算机视觉领域中，图像识别任务通常被称为“图像分类”。换句话说，给定一个输入的图像，我们希望预测它属于哪个类别。该问题具有广泛的应用场景，例如自动驾驶汽车、安全摄像头监控系统等等。\n\n近年来，深度学习技术的发展使得准确地解决这一问题成为了可能。其中一种广泛使用的模型是卷积神经网络(CNN)。这种类型的神经网络架构非常适合对图像数据进行处理，并且已经在各种计算机视觉应用中被证明可以取得良好的性能结果。\n\n在这篇文章中，我们将详细介绍如何使用 Tensorflow 构建和训练用于图像分类的 CNN 模型。具体来说，我们将涵盖以下内容：\n\n- [TensorFlow](https://www.tensorflow.org/)模型的基本概念和原理；\n- `tf.keras` API 的使用方法以及一些常见功能和技术说明；\n- *LeNet* 架构及其变体的实现和使用方式；\n- LeNet 架构的一些高级扩展模块和技巧，包括残差块、分离式注意力机制等；\n- LSTM 网络和 GRU 网络的实现和使用方式；\n- GANs (生成对抗网络) 的概念、理论和实践知识，包括原论文概述、核心算法分析与推导、代码实现细节解析、实验数据分析解读等内容；\n- CycleGANs(循环一致性生成对抗网络) 的理论背景和方法论框架，并结合具体的案例研究和工程实践经验，重点阐述了交叉模态转换、域适应等问题中的关键挑战及解决方案，以及对当前相关研究领域的最新进展和发展趋势进行了深入剖析和探讨。\n\n---\n\n# **一. TensorFlow Model Fundamentals & Principles**\n\n首先，我们先简单介绍一下 TensorFlow 的基本概念和原理。这主要包括了解什么是 TensorFlow，它的主要组成部分是什么，以及它们之间是如何相互关联工作的。接下来，我们将简要介绍一下 TensorFlow 的一些重要特性和优势，这些特性和优势使其成为目前业界最流行和广泛采用的开源机器学习和人工智能开发平台之一。最后，我们将简单回顾一下 TensorFlow 的历史发展和演进历程，以便更好地理解其背后的动机和技术思路。\n\n---\n\n# **二. tf.keras API Overview and Common Features/Techinques Explanation/Analysis Part One: Core Functionality Introduction + Basic Building Block Design Pattern Demonstration Walkthrough Example Code Snippet Showcase<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2136, 505, 395, 12279, 446, 410, 6392, 3995, 569, 395, 53027, 334, 3235, 60949, 60923, 55098, 330, 262, 70427, 60530, 68387, 68343, 68330, 68271, 26474, 19033, 60353, 68685, 61308, 60963, 69829, 68441, 60414, 54413, 60413, 60383, 69233, 70439, 69412, 60682, 60355, 402, 43916, 324, 3235, 68487, 1160, 60361, 69444, 70906, 69052, 60366, 60353, 70439, 70180, 68565, 69040, 72712, 60419, 70439, 69412, 60420, 60355, 90160, 60353, 60562, 60450, 68252, 68412, 60354, 70439, 60353, 68253, 68397, 72308, 60741, 68693, 70242, 72008, 60355, 60658, 68287, 68537, 70073, 72696, 69928, 60353, 69192, 68532, 69931, 68779, 60359, 68419, 72118, 71998, 68308, 68811, 60355, 402, 72877, 60353, 70907, 68352, 68362, 69745, 70111, 70378, 60415, 68530, 68597, 68287, 71093, 68295, 60355, 68415, 68617, 70073, 70017, 70218, 60357, 61308, 60963, 69829, 68441, 3190, 9880, 313, 60355, 68381, 71761, 69829, 68441, 75075, 78958, 60409, 70439, 68398, 90124, 60353, 68614, 78287, 68459, 69444, 70906, 68481, 77890, 69295, 68251, 69292, 69905, 69165, 68501, 60355, 402, 69962, 79254, 60366, 60353, 73776, 78222, 76664, 26474, 5125, 262, 72962, 60381, 69233, 68815, 70439, 60402, 69091, 19941, 262, 70218, 60355, 68592, 68484, 60353, 73776, 74924, 68544, 68341, 60387, 402, 285, 640, 25771, 19033, 9665, 2580, 1253, 2290, 40332, 5125, 2821, 50002, 86427, 68406, 69662, 60381, 70433, 60506, 364, 285, 1711, 9068, 34770, 350, 5492, 262, 70920, 68256, 68375, 68315, 69305, 68344, 80613, 68789, 60506, 364, 285, 484, 2455, 7104, 297, 262, 75075, 69975, 60650, 69743, 68651, 82154, 68386, 60506, 364, 285, 2117, 7104, 262, 75075, 69961, 69105, 70934, 71055, 60381, 69150, 60353, 68469, 61881, 61042, 61006, 60359, 71759, 60550, 73693, 70778, 60455, 60506, 364, 285, 575, 35810, 262, 86845, 14903, 315, 262, 85408, 68651, 82154, 68386, 60506, 364, 285, 610, 1235, 269, 451, 70563, 74279, 68441, 313, 262, 75879, 60359, 88312, 69804, 68580, 60353, 68469, 60507, 69526, 72222, 60359, 69220, 73060, 68578, 60510, 60876, 60734, 60359, 69681, 68651, 69873, 71921, 60359, 69157, 81120, 74594, 82721, 60506, 364, 285, 41003, 57271, 269, 298, 69875, 70315, 60489, 70563, 74279, 68441, 313, 262, 86374, 68807, 80460, 60831, 72282, 60353, 60573, 68993, 72702, 70533, 84490, 68512, 69804, 68416, 60353, 68894, 77084, 60362, 73085, 60838, 60921, 69556, 60359, 61020, 70188, 76563, 68322, 68802, 69879, 60543, 72134, 60353, 90553, 69672, 68524, 68346, 75020, 69964, 75454, 78637, 70346, 70550, 70354, 85060, 60381, 73286, 60355, 402, 43916, 324, 3235, 60356, 281, 26474, 19033, 5061, 13330, 3002, 1271, 741, 55794, 55098, 68400, 60353, 75026, 90818, 26474, 19033, 262, 71119, 69662, 60381, 70433, 60355, 60376, 81458, 68505, 71878, 26474, 19033, 60353, 68957, 68326, 79579, 69095, 60353, 68375, 69290, 68629, 76348, 70244, 73630, 70693, 60355, 68929, 60353, 73776, 60743, 60371, 70068, 26474, 19033, 262, 69961, 68372, 70534, 60381, 69203, 60353, 68374, 70534, 60381, 69203, 72498, 68479, 68495, 82860, 60442, 70402, 60381, 70073, 83280, 83263, 69690, 79606, 76659, 68640, 68561, 68538, 60355, 68337, 60353, 73776, 68435, 76156, 68300, 26474, 19033, 262, 72357, 82463, 60819, 60433, 75470, 60353, 72816, 74399, 68865, 60451, 79202, 81717, 80613, 71057, 60355, 402, 43916, 324, 3235, 60529, 281, 6564, 34770, 5492, 34817, 454, 7858, 19880, 16864, 4899, 389, 14111, 1519, 35849, 301, 26997, 3819, 3936, 334, 9648, 5865, 2881, 28681, 619, 14758, 16992, 8495, 7132, 18989, 32454, 53580, 12705, 19912, 13523, 6272, 13205, 21818, 7080, 5794, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:45:54 metrics.py:213] Avg prompt throughput: 15.1 tokens/s, Avg generation throughput: 1.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:45:59 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 93.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:46:00 async_llm_engine.py:110] Finished request chatcmpl-1e26f967-47bc-4bff-bfbe-1ade7912684f.
2024-03-28 21:46:03.108 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'This is a summary of the chat history as a recap: **引言**\n\n> 本文将介绍如何通过使用 TensorFlow，利用卷积神经网络（CNN）来训练图像分类器。\n\n---\n\n# **简介**\n在计算机视觉领域中，图像识别任务通常被称为“图像分类”。换句话说，给定一个输入的图像，我们希望预测它属于哪个类别。该问题具有广泛的应用场景，例如自动驾驶汽车、安全摄像头监控系统等等。\n\n近年来，深度学习技术的发展使得准确地解决这一问题成为了可能。其中一种广泛使用的模型是卷积神经网络(CNN)。这种类型的神经网络架构非常适合对图像数据进行处理，并且已经在各种计算机视觉应用中被证明可以取得良好的性能结果。\n\n在这篇文章中，我们将详细介绍如何使用 Tensorflow 构建和训练用于图像分类的 CNN 模型。具体来说，我们将涵盖以下内容：\n\n- [TensorFlow](https://www.tensorflow.org/)模型的基本概念和原理；\n- `tf.keras` API 的使用方法以及一些常见功能和技术说明；\n- *LeNet* 架构及其变体的实现和使用方式；\n- LeNet 架构的一些高级扩展模块和技巧，包括残差块、分离式注意力机制等；\n- LSTM 网络和 GRU 网络的实现和使用方式；\n- GANs (生成对抗网络) 的概念、理论和实践知识，包括原论文概述、核心算法分析与推导、代码实现细节解析、实验数据分析解读等内容；\n- CycleGANs(循环一致性生成对抗网络) 的理论背景和方法论框架，并结合具体的案例研究和工程实践经验，重点阐述了交叉模态转换、域适应等问题中的关键挑战及解决方案，以及对当前相关研究领域的最新进展和发展趋势进行了深入剖析和探讨。\n\n---\n\n# **一. TensorFlow Model Fundamentals & Principles**\n\n首先，我们先简单介绍一下 TensorFlow 的基本概念和原理。这主要包括了解什么是 TensorFlow，它的主要组成部分是什么，以及它们之间是如何相互关联工作的。接下来，我们将简要介绍一下 TensorFlow 的一些重要特性和优势，这些特性和优势使其成为目前业界最流行和广泛采用的开源机器学习和人工智能开发平台之一。最后，我们将简单回顾一下 TensorFlow 的历史发展和演进历程，以便更好地理解其背后的动机和技术思路。\n\n---\n\n# **二. tf.keras API Overview and Common Features/Techinques Explanation/Analysis Part One: Core Functionality Introduction + Basic Building Block Design Pattern Demonstration Walkthrough Example Code Snippet Showcase', 'role': 'system'}, {'content': '合成氨是谁发明的？', 'role': 'user'}, {'role': 'assistant', 'content': '德国科学家弗里茨·哈伯于1909年发明了合成氨的方法。由于他的发现对全球能源生产和化肥生产的影响巨大，他被广泛认为是20世纪最重要科学成就之一的关键人物。'}, {'content': '他还发明了什么？', 'role': 'user'}, {'role': 'assistant', 'content': "**【第2部分】关于 tf.keras API 的更深入分析和讨论，包括有关高阶特征的技巧和最佳实践指导，以及特定用例下的详细示例演示和代码片段展示。**\n\n---\n**【第1部分续】**\n在这一部分的第二部分，我们将继续我们的讨论，话题的重点将是更深入地探索和分析 tf.keras API 的高阶特性和技巧，以及如何在实践中有效地将这些功能和技巧应用于不同的实际问题和场景之中。为了达到这个目标，我们将按照如下的结构进行详细的分析和讲解：\n\n### High-level Feature Analysis:\n首先，我们将从整体上全面而细致地分析 tf.keras API 提供的所有主要类别的高级别特性，以帮助我们更加清晰透彻地了解每个属性的作用、意义和适用场景。在此过程中，我们还将在必要时提供相应的代码片段或示例，以帮助读者更好地理解和掌握所涉及的特性及其使用方法。\n\n---\n\n###### 🔗[返回目录](../README.md)/[返回上一级](./README.md)]  🔗[返回目录](../README.md)/[返回上一级](./README.md)]\n---\n\n\n\n### Best Practices Guidance for Key Higher-order Techniques Usage Scenarios Covering in-depth Exploration, Discussion about More Deeply Analyzing Popular Advanced Trends Topics Relevant to Current Research Fields' Developments Insights Discoveries.\n**【第3部分】——待续……** \n\n---\n\n**【第4部分】——待续……**  \n\n---\n\n---\n\n***Note: 由于篇幅限制和一些其他因素的影响，原文的内容可能会存在一定的缺失、不准确或不完整之处，因此建议您在进行任何重要的决策之前，请务必仔细阅读相关的参考资料和文档资料，并对相关信息进行全面的验证和确认，以保证您的应用能够获得最优化的效果表现。***\n\n---\n\n**【第5部分】——待续……** \n---\n\n---\n\n***Note: 由于篇幅限制和一些其他因素的影响，原文的内容可能会存在一定的缺失、不准确或不完整之处，因此建议您在进行任何重要的决策之前，请务必仔细阅读相关的参考资料和文档资料，并对相关信息进行全面的验证和确认，以保证您的应用能够获得最优化的效果表现。***\n\n---\n\n**【第6部分】——待续……**  \n---\n\n---\n\n***Note: 由于篇幅限制和一些其他因素的影响，原文的内容可能会存在一定的缺失、不准确或不完整之处，因此建议您在进行任何重要的决策之前，请务必仔细阅读相关的参考资料和文档资料，并对相关信息进行全面的验证和确认，以保证您的应用能够"}, {'content': 'Summarize our conversation in 50 words or less', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:39198 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 21:46:03 async_llm_engine.py:436] Received request chatcmpl-5eae6b47-e5a1-468c-9e32-f90e10c77973: prompt: '<s><|im_start|>system\nThis is a summary of the chat history as a recap: **引言**\n\n> 本文将介绍如何通过使用 TensorFlow，利用卷积神经网络（CNN）来训练图像分类器。\n\n---\n\n# **简介**\n在计算机视觉领域中，图像识别任务通常被称为“图像分类”。换句话说，给定一个输入的图像，我们希望预测它属于哪个类别。该问题具有广泛的应用场景，例如自动驾驶汽车、安全摄像头监控系统等等。\n\n近年来，深度学习技术的发展使得准确地解决这一问题成为了可能。其中一种广泛使用的模型是卷积神经网络(CNN)。这种类型的神经网络架构非常适合对图像数据进行处理，并且已经在各种计算机视觉应用中被证明可以取得良好的性能结果。\n\n在这篇文章中，我们将详细介绍如何使用 Tensorflow 构建和训练用于图像分类的 CNN 模型。具体来说，我们将涵盖以下内容：\n\n- [TensorFlow](https://www.tensorflow.org/)模型的基本概念和原理；\n- `tf.keras` API 的使用方法以及一些常见功能和技术说明；\n- *LeNet* 架构及其变体的实现和使用方式；\n- LeNet 架构的一些高级扩展模块和技巧，包括残差块、分离式注意力机制等；\n- LSTM 网络和 GRU 网络的实现和使用方式；\n- GANs (生成对抗网络) 的概念、理论和实践知识，包括原论文概述、核心算法分析与推导、代码实现细节解析、实验数据分析解读等内容；\n- CycleGANs(循环一致性生成对抗网络) 的理论背景和方法论框架，并结合具体的案例研究和工程实践经验，重点阐述了交叉模态转换、域适应等问题中的关键挑战及解决方案，以及对当前相关研究领域的最新进展和发展趋势进行了深入剖析和探讨。\n\n---\n\n# **一. TensorFlow Model Fundamentals & Principles**\n\n首先，我们先简单介绍一下 TensorFlow 的基本概念和原理。这主要包括了解什么是 TensorFlow，它的主要组成部分是什么，以及它们之间是如何相互关联工作的。接下来，我们将简要介绍一下 TensorFlow 的一些重要特性和优势，这些特性和优势使其成为目前业界最流行和广泛采用的开源机器学习和人工智能开发平台之一。最后，我们将简单回顾一下 TensorFlow 的历史发展和演进历程，以便更好地理解其背后的动机和技术思路。\n\n---\n\n# **二. tf.keras API Overview and Common Features/Techinques Explanation/Analysis Part One: Core Functionality Introduction + Basic Building Block Design Pattern Demonstration Walkthrough Example Code Snippet Showcase<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2136, 505, 395, 12279, 446, 410, 6392, 3995, 569, 395, 53027, 334, 3235, 60949, 60923, 55098, 330, 262, 70427, 60530, 68387, 68343, 68330, 68271, 26474, 19033, 60353, 68685, 61308, 60963, 69829, 68441, 60414, 54413, 60413, 60383, 69233, 70439, 69412, 60682, 60355, 402, 43916, 324, 3235, 68487, 1160, 60361, 69444, 70906, 69052, 60366, 60353, 70439, 70180, 68565, 69040, 72712, 60419, 70439, 69412, 60420, 60355, 90160, 60353, 60562, 60450, 68252, 68412, 60354, 70439, 60353, 68253, 68397, 72308, 60741, 68693, 70242, 72008, 60355, 60658, 68287, 68537, 70073, 72696, 69928, 60353, 69192, 68532, 69931, 68779, 60359, 68419, 72118, 71998, 68308, 68811, 60355, 402, 72877, 60353, 70907, 68352, 68362, 69745, 70111, 70378, 60415, 68530, 68597, 68287, 71093, 68295, 60355, 68415, 68617, 70073, 70017, 70218, 60357, 61308, 60963, 69829, 68441, 3190, 9880, 313, 60355, 68381, 71761, 69829, 68441, 75075, 78958, 60409, 70439, 68398, 90124, 60353, 68614, 78287, 68459, 69444, 70906, 68481, 77890, 69295, 68251, 69292, 69905, 69165, 68501, 60355, 402, 69962, 79254, 60366, 60353, 73776, 78222, 76664, 26474, 5125, 262, 72962, 60381, 69233, 68815, 70439, 60402, 69091, 19941, 262, 70218, 60355, 68592, 68484, 60353, 73776, 74924, 68544, 68341, 60387, 402, 285, 640, 25771, 19033, 9665, 2580, 1253, 2290, 40332, 5125, 2821, 50002, 86427, 68406, 69662, 60381, 70433, 60506, 364, 285, 1711, 9068, 34770, 350, 5492, 262, 70920, 68256, 68375, 68315, 69305, 68344, 80613, 68789, 60506, 364, 285, 484, 2455, 7104, 297, 262, 75075, 69975, 60650, 69743, 68651, 82154, 68386, 60506, 364, 285, 2117, 7104, 262, 75075, 69961, 69105, 70934, 71055, 60381, 69150, 60353, 68469, 61881, 61042, 61006, 60359, 71759, 60550, 73693, 70778, 60455, 60506, 364, 285, 575, 35810, 262, 86845, 14903, 315, 262, 85408, 68651, 82154, 68386, 60506, 364, 285, 610, 1235, 269, 451, 70563, 74279, 68441, 313, 262, 75879, 60359, 88312, 69804, 68580, 60353, 68469, 60507, 69526, 72222, 60359, 69220, 73060, 68578, 60510, 60876, 60734, 60359, 69681, 68651, 69873, 71921, 60359, 69157, 81120, 74594, 82721, 60506, 364, 285, 41003, 57271, 269, 298, 69875, 70315, 60489, 70563, 74279, 68441, 313, 262, 86374, 68807, 80460, 60831, 72282, 60353, 60573, 68993, 72702, 70533, 84490, 68512, 69804, 68416, 60353, 68894, 77084, 60362, 73085, 60838, 60921, 69556, 60359, 61020, 70188, 76563, 68322, 68802, 69879, 60543, 72134, 60353, 90553, 69672, 68524, 68346, 75020, 69964, 75454, 78637, 70346, 70550, 70354, 85060, 60381, 73286, 60355, 402, 43916, 324, 3235, 60356, 281, 26474, 19033, 5061, 13330, 3002, 1271, 741, 55794, 55098, 68400, 60353, 75026, 90818, 26474, 19033, 262, 71119, 69662, 60381, 70433, 60355, 60376, 81458, 68505, 71878, 26474, 19033, 60353, 68957, 68326, 79579, 69095, 60353, 68375, 69290, 68629, 76348, 70244, 73630, 70693, 60355, 68929, 60353, 73776, 60743, 60371, 70068, 26474, 19033, 262, 69961, 68372, 70534, 60381, 69203, 60353, 68374, 70534, 60381, 69203, 72498, 68479, 68495, 82860, 60442, 70402, 60381, 70073, 83280, 83263, 69690, 79606, 76659, 68640, 68561, 68538, 60355, 68337, 60353, 73776, 68435, 76156, 68300, 26474, 19033, 262, 72357, 82463, 60819, 60433, 75470, 60353, 72816, 74399, 68865, 60451, 79202, 81717, 80613, 71057, 60355, 402, 43916, 324, 3235, 60529, 281, 6564, 34770, 5492, 34817, 454, 7858, 19880, 16864, 4899, 389, 14111, 1519, 35849, 301, 26997, 3819, 3936, 334, 9648, 5865, 2881, 28681, 619, 14758, 16992, 8495, 7132, 18989, 32454, 53580, 12705, 19912, 13523, 6272, 13205, 21818, 7080, 5794, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:46:04 metrics.py:213] Avg prompt throughput: 109.5 tokens/s, Avg generation throughput: 36.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:46:08 async_llm_engine.py:110] Finished request chatcmpl-5eae6b47-e5a1-468c-9e32-f90e10c77973.
2024-03-28 21:46:18.264 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:44686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:46:18 async_llm_engine.py:436] Received request chatcmpl-9e2e4037-4133-4094-b8a9-41fa5240ac64: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:46:18 metrics.py:213] Avg prompt throughput: 8.0 tokens/s, Avg generation throughput: 27.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:46:22 async_llm_engine.py:110] Finished request chatcmpl-9e2e4037-4133-4094-b8a9-41fa5240ac64.
2024-03-28 21:46:35.848 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应产生的，这是工业规模生产的关键过程。\n\n该工艺涉及几个步骤：\n\n1. 氮气压缩和净化：首先，从空气中分离出氮气。然后对氮气进行压缩并进一步纯化，去除任何杂质气体或惰性元素。\n\n2. **Haber-Bosch** 固定床催化氨合成：来自压缩机的高压、高纯度的氮气和氢气被送入固定床反应器中。在高温高压下，两种气体发生化学反应生成氨（NH₃）和水蒸气（H₂O）。在此过程中使用的催化剂主要是铁基的，其中活性成分通常是氧化铁(III)(Fe₂O₃))。 \n\n3. 热交换回收：离开反应器的气体混合物含有大量未反应的氮气和氢气以及生成的氨和水蒸汽。为了最大限度地利用原料，将此混合物流通过一系列热交换器，以加热新鲜进料流并将其冷却至较低温度，从而形成冷凝物可以收集到的液态水。\n\n4. 吸收与解吸：在高浓度条件下获得的液体产物 stream 随后进入一个胺溶液的吸收塔，在这里氨溶解到碱性溶剂中以形成富含氨的“富”溶液。剩余的气体作为贫级流返回系统，在那里它们将在工序中被重新使用。\n\n5. 精馏：氨溶液接着由两个连续操作的精馏塔进行处理。第一个塔被称为预分馏塔，它用于部分浓缩含氨溶液中的氨含量，同时产生称为“回流”的部分浓缩溶液。第二个塔是主要精馏塔，它接收了主要由氨组成的回流，并通过使塔顶馏出物部分冷凝和液化来对其进行进一步提纯。这些液体产物可以直接储存和使用，或者可以被进一步加工以获得更高浓度的特定化学品，例如硝酸铵(NH₄NO₃)等肥料。'}, {'content': 'Please generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.', 'role': 'user'}], 'echo': False}
INFO 03-28 21:46:35 async_llm_engine.py:436] Received request chatcmpl-9b94c7ed-e75e-417b-a6d4-3d4ba5fb8675: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n合成氨是通过氮气和氢气的反应产生的，这是工业规模生产的关键过程。\n\n该工艺涉及几个步骤：\n\n1. 氮气压缩和净化：首先，从空气中分离出氮气。然后对氮气进行压缩并进一步纯化，去除任何杂质气体或惰性元素。\n\n2. **Haber-Bosch** 固定床催化氨合成：来自压缩机的高压、高纯度的氮气和氢气被送入固定床反应器中。在高温高压下，两种气体发生化学反应生成氨（NH₃）和水蒸气（H₂O）。在此过程中使用的催化剂主要是铁基的，其中活性成分通常是氧化铁(III)(Fe₂O₃))。 \n\n3. 热交换回收：离开反应器的气体混合物含有大量未反应的氮气和氢气以及生成的氨和水蒸汽。为了最大限度地利用原料，将此混合物流通过一系列热交换器，以加热新鲜进料流并将其冷却至较低温度，从而形成冷凝物可以收集到的液态水。\n\n4. 吸收与解吸：在高浓度条件下获得的液体产物 stream 随后进入一个胺溶液的吸收塔，在这里氨溶解到碱性溶剂中以形成富含氨的“富”溶液。剩余的气体作为贫级流返回系统，在那里它们将在工序中被重新使用。\n\n5. 精馏：氨溶液接着由两个连续操作的精馏塔进行处理。第一个塔被称为预分馏塔，它用于部分浓缩含氨溶液中的氨含量，同时产生称为“回流”的部分浓缩溶液。第二个塔是主要精馏塔，它接收了主要由氨组成的回流，并通过使塔顶馏出物部分冷凝和液化来对其进行进一步提纯。这些液体产物可以直接储存和使用，或者可以被进一步加工以获得更高浓度的特定化学品，例如硝酸铵(NH₄NO₃)等肥料。<|im_end|>\n<|im_start|>user\nPlease generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 70409, 62715, 76288, 63436, 84721, 63167, 70724, 69076, 72544, 60353, 68472, 69042, 69801, 68548, 73758, 68468, 60355, 402, 60658, 69584, 70432, 68650, 68264, 60387, 402, 312, 281, 262, 63436, 60642, 70879, 60381, 72953, 60387, 68400, 60353, 60577, 84502, 71759, 60389, 63436, 60642, 60355, 68265, 60409, 63436, 60642, 68274, 70879, 60573, 69806, 61487, 60516, 60353, 70694, 68574, 78852, 73341, 60535, 64211, 60489, 69403, 60355, 402, 314, 281, 3235, 318, 42768, 7810, 567, 462, 465, 262, 69393, 61191, 78188, 62715, 70409, 60387, 69033, 86235, 69494, 60952, 60359, 60436, 61487, 69869, 63436, 84721, 63167, 60642, 60549, 89653, 69393, 61191, 69076, 60682, 60366, 60355, 60361, 71909, 73011, 60380, 60353, 69589, 73341, 68526, 91395, 70563, 62715, 60414, 50434, 67969, 60413, 76398, 61649, 60642, 60414, 318, 229, 133, 133, 306, 60413, 60355, 69890, 68835, 70017, 90281, 69802, 61174, 60630, 60354, 60353, 68415, 73094, 69937, 80558, 70101, 61174, 298, 22912, 2530, 6276, 229, 133, 133, 306, 67969, 724, 60355, 4872, 308, 281, 262, 60766, 72124, 72323, 60387, 69365, 69076, 70538, 73341, 86428, 69515, 69436, 60984, 69076, 60354, 63436, 84721, 63167, 60642, 68375, 83475, 62715, 76398, 76081, 60355, 68394, 90022, 60415, 68685, 68296, 60353, 60530, 60603, 69275, 70967, 68330, 72609, 60766, 72124, 60682, 60353, 60367, 70196, 70022, 60433, 60545, 60673, 89478, 71387, 60615, 75856, 69032, 60353, 69172, 68722, 61114, 62210, 60502, 68251, 70507, 69333, 61258, 60921, 60456, 60355, 402, 319, 281, 262, 69664, 60510, 60595, 61124, 60387, 81357, 74249, 76168, 75558, 73128, 77144, 4427, 262, 70322, 68291, 68252, 63292, 74202, 85332, 61322, 60353, 69438, 62715, 75719, 60378, 80722, 82681, 85157, 68722, 72349, 62715, 60354, 60419, 61067, 60420, 74202, 60355, 80879, 73341, 68429, 62085, 60674, 60673, 70121, 68308, 60353, 76667, 69290, 73030, 82083, 77890, 68928, 68271, 60355, 402, 317, 281, 262, 60777, 64987, 60387, 62715, 74202, 68692, 60620, 68451, 69591, 81206, 60777, 64987, 61322, 90124, 60355, 69423, 61322, 72712, 61030, 60402, 64987, 61322, 60353, 60741, 68815, 68340, 82725, 61116, 62715, 74202, 68322, 62715, 70467, 60353, 68405, 68701, 69402, 60419, 60584, 60673, 60420, 71653, 82725, 74202, 60355, 71129, 61322, 60357, 68326, 60777, 64987, 61322, 60353, 60741, 71682, 60362, 85107, 62715, 75887, 60584, 60673, 60353, 83707, 60534, 61322, 61375, 64987, 60389, 60502, 68340, 61114, 62210, 60381, 91629, 60383, 91225, 69806, 60546, 61487, 60355, 68374, 73128, 77144, 71555, 73628, 82154, 60353, 68319, 87756, 69806, 69619, 60367, 68422, 71841, 61822, 69869, 73295, 69383, 60492, 60353, 69192, 82139, 65161, 8337, 318, 229, 133, 135, 9128, 67969, 313, 60455, 78413, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 5658, 7076, 395, 3205, 442, 4393, 3571, 2416, 28634, 5008, 1181, 10571, 2192, 1030, 3154, 3580, 328, 60117, 328, 53245, 15546, 328, 18500, 328, 17880, 328, 14082, 1614, 328, 607, 5268, 1614, 281, 10930, 3374, 17976, 53245, 15546, 15889, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:46:35 metrics.py:213] Avg prompt throughput: 32.5 tokens/s, Avg generation throughput: 22.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:46:35 async_llm_engine.py:110] Finished request chatcmpl-9b94c7ed-e75e-417b-a6d4-3d4ba5fb8675.
INFO:     10.1.96.6:56154 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 21:48:11.081 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '什么是合成氨？', 'role': 'user'}, {'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应产生的，这是工业规模生产的关键过程。\n\n该工艺涉及几个步骤：\n\n1. 氮气压缩和净化：首先，从空气中分离出氮气。然后对氮气进行压缩并进一步纯化，去除任何杂质气体或惰性元素。\n\n2. **Haber-Bosch** 固定床催化氨合成：来自压缩机的高压、高纯度的氮气和氢气被送入固定床反应器中。在高温高压下，两种气体发生化学反应生成氨（NH₃）和水蒸气（H₂O）。在此过程中使用的催化剂主要是铁基的，其中活性成分通常是氧化铁(III)(Fe₂O₃))。 \n\n3. 热交换回收：离开反应器的气体混合物含有大量未反应的氮气和氢气以及生成的氨和水蒸汽。为了最大限度地利用原料，将此混合物流通过一系列热交换器，以加热新鲜进料流并将其冷却至较低温度，从而形成冷凝物可以收集到的液态水。\n\n4. 吸收与解吸：在高浓度条件下获得的液体产物 stream 随后进入一个胺溶液的吸收塔，在这里氨溶解到碱性溶剂中以形成富含氨的“富”溶液。剩余的气体作为贫级流返回系统，在那里它们将在工序中被重新使用。\n\n5. 精馏：氨溶液接着由两个连续操作的精馏塔进行处理。第一个塔被称为预分馏塔，它用于部分浓缩含氨溶液中的氨含量，同时产生称为“回流”的部分浓缩溶液。第二个塔是主要精馏塔，它接收了主要由氨组成的回流，并通过使塔顶馏出物部分冷凝和液化来对其进行进一步提纯。这些液体产物可以直接储存和使用，或者可以被进一步加工以获得更高浓度的特定化学品，例如硝酸铵(NH₄NO₃)等肥料。'}, {'content': '谁发明的？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:56466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:48:11 async_llm_engine.py:436] Received request chatcmpl-bf93f669-0889-4df3-a444-4fa0dad3f1b8: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n什么是合成氨？<|im_end|>\n<|im_start|>assistant\n合成氨是通过氮气和氢气的反应产生的，这是工业规模生产的关键过程。\n\n该工艺涉及几个步骤：\n\n1. 氮气压缩和净化：首先，从空气中分离出氮气。然后对氮气进行压缩并进一步纯化，去除任何杂质气体或惰性元素。\n\n2. **Haber-Bosch** 固定床催化氨合成：来自压缩机的高压、高纯度的氮气和氢气被送入固定床反应器中。在高温高压下，两种气体发生化学反应生成氨（NH₃）和水蒸气（H₂O）。在此过程中使用的催化剂主要是铁基的，其中活性成分通常是氧化铁(III)(Fe₂O₃))。 \n\n3. 热交换回收：离开反应器的气体混合物含有大量未反应的氮气和氢气以及生成的氨和水蒸汽。为了最大限度地利用原料，将此混合物流通过一系列热交换器，以加热新鲜进料流并将其冷却至较低温度，从而形成冷凝物可以收集到的液态水。\n\n4. 吸收与解吸：在高浓度条件下获得的液体产物 stream 随后进入一个胺溶液的吸收塔，在这里氨溶解到碱性溶剂中以形成富含氨的“富”溶液。剩余的气体作为贫级流返回系统，在那里它们将在工序中被重新使用。\n\n5. 精馏：氨溶液接着由两个连续操作的精馏塔进行处理。第一个塔被称为预分馏塔，它用于部分浓缩含氨溶液中的氨含量，同时产生称为“回流”的部分浓缩溶液。第二个塔是主要精馏塔，它接收了主要由氨组成的回流，并通过使塔顶馏出物部分冷凝和液化来对其进行进一步提纯。这些液体产物可以直接储存和使用，或者可以被进一步加工以获得更高浓度的特定化学品，例如硝酸铵(NH₄NO₃)等肥料。<|im_end|>\n<|im_start|>user\n谁发明的？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 70409, 62715, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 70409, 62715, 76288, 63436, 84721, 63167, 70724, 69076, 72544, 60353, 68472, 69042, 69801, 68548, 73758, 68468, 60355, 402, 60658, 69584, 70432, 68650, 68264, 60387, 402, 312, 281, 262, 63436, 60642, 70879, 60381, 72953, 60387, 68400, 60353, 60577, 84502, 71759, 60389, 63436, 60642, 60355, 68265, 60409, 63436, 60642, 68274, 70879, 60573, 69806, 61487, 60516, 60353, 70694, 68574, 78852, 73341, 60535, 64211, 60489, 69403, 60355, 402, 314, 281, 3235, 318, 42768, 7810, 567, 462, 465, 262, 69393, 61191, 78188, 62715, 70409, 60387, 69033, 86235, 69494, 60952, 60359, 60436, 61487, 69869, 63436, 84721, 63167, 60642, 60549, 89653, 69393, 61191, 69076, 60682, 60366, 60355, 60361, 71909, 73011, 60380, 60353, 69589, 73341, 68526, 91395, 70563, 62715, 60414, 50434, 67969, 60413, 76398, 61649, 60642, 60414, 318, 229, 133, 133, 306, 60413, 60355, 69890, 68835, 70017, 90281, 69802, 61174, 60630, 60354, 60353, 68415, 73094, 69937, 80558, 70101, 61174, 298, 22912, 2530, 6276, 229, 133, 133, 306, 67969, 724, 60355, 4872, 308, 281, 262, 60766, 72124, 72323, 60387, 69365, 69076, 70538, 73341, 86428, 69515, 69436, 60984, 69076, 60354, 63436, 84721, 63167, 60642, 68375, 83475, 62715, 76398, 76081, 60355, 68394, 90022, 60415, 68685, 68296, 60353, 60530, 60603, 69275, 70967, 68330, 72609, 60766, 72124, 60682, 60353, 60367, 70196, 70022, 60433, 60545, 60673, 89478, 71387, 60615, 75856, 69032, 60353, 69172, 68722, 61114, 62210, 60502, 68251, 70507, 69333, 61258, 60921, 60456, 60355, 402, 319, 281, 262, 69664, 60510, 60595, 61124, 60387, 81357, 74249, 76168, 75558, 73128, 77144, 4427, 262, 70322, 68291, 68252, 63292, 74202, 85332, 61322, 60353, 69438, 62715, 75719, 60378, 80722, 82681, 85157, 68722, 72349, 62715, 60354, 60419, 61067, 60420, 74202, 60355, 80879, 73341, 68429, 62085, 60674, 60673, 70121, 68308, 60353, 76667, 69290, 73030, 82083, 77890, 68928, 68271, 60355, 402, 317, 281, 262, 60777, 64987, 60387, 62715, 74202, 68692, 60620, 68451, 69591, 81206, 60777, 64987, 61322, 90124, 60355, 69423, 61322, 72712, 61030, 60402, 64987, 61322, 60353, 60741, 68815, 68340, 82725, 61116, 62715, 74202, 68322, 62715, 70467, 60353, 68405, 68701, 69402, 60419, 60584, 60673, 60420, 71653, 82725, 74202, 60355, 71129, 61322, 60357, 68326, 60777, 64987, 61322, 60353, 60741, 71682, 60362, 85107, 62715, 75887, 60584, 60673, 60353, 83707, 60534, 61322, 61375, 64987, 60389, 60502, 68340, 61114, 62210, 60381, 91629, 60383, 91225, 69806, 60546, 61487, 60355, 68374, 73128, 77144, 71555, 73628, 82154, 60353, 68319, 87756, 69806, 69619, 60367, 68422, 71841, 61822, 69869, 73295, 69383, 60492, 60353, 69192, 82139, 65161, 8337, 318, 229, 133, 135, 9128, 67969, 313, 60455, 78413, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 61297, 73214, 60354, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:48:11 metrics.py:213] Avg prompt throughput: 5.6 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:48:11 async_llm_engine.py:110] Finished request chatcmpl-bf93f669-0889-4df3-a444-4fa0dad3f1b8.
2024-03-28 21:48:21.892 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'role': 'assistant', 'content': '合成氨是通过氮气和氢气的反应产生的，这是工业规模生产的关键过程。\n\n该工艺涉及几个步骤：\n\n1. 氮气压缩和净化：首先，从空气中分离出氮气。然后对氮气进行压缩并进一步纯化，去除任何杂质气体或惰性元素。\n\n2. **Haber-Bosch** 固定床催化氨合成：来自压缩机的高压、高纯度的氮气和氢气被送入固定床反应器中。在高温高压下，两种气体发生化学反应生成氨（NH₃）和水蒸气（H₂O）。在此过程中使用的催化剂主要是铁基的，其中活性成分通常是氧化铁(III)(Fe₂O₃))。 \n\n3. 热交换回收：离开反应器的气体混合物含有大量未反应的氮气和氢气以及生成的氨和水蒸汽。为了最大限度地利用原料，将此混合物流通过一系列热交换器，以加热新鲜进料流并将其冷却至较低温度，从而形成冷凝物可以收集到的液态水。\n\n4. 吸收与解吸：在高浓度条件下获得的液体产物 stream 随后进入一个胺溶液的吸收塔，在这里氨溶解到碱性溶剂中以形成富含氨的“富”溶液。剩余的气体作为贫级流返回系统，在那里它们将在工序中被重新使用。\n\n5. 精馏：氨溶液接着由两个连续操作的精馏塔进行处理。第一个塔被称为预分馏塔，它用于部分浓缩含氨溶液中的氨含量，同时产生称为“回流”的部分浓缩溶液。第二个塔是主要精馏塔，它接收了主要由氨组成的回流，并通过使塔顶馏出物部分冷凝和液化来对其进行进一步提纯。这些液体产物可以直接储存和使用，或者可以被进一步加工以获得更高浓度的特定化学品，例如硝酸铵(NH₄NO₃)等肥料。'}, {'content': '谁发明的？', 'role': 'user'}, {'role': 'assistant', 'content': '哈伯-博施法的发明者是两位德国科学家弗里茨·哈伯（Fritz Haber）和卡尔·博施（Carl Bosch）。他们于1909年首次开发出了这一革命性的技术。他们的工作彻底改变了化肥和其他重要产品的生产和供应方式。'}, {'content': '他还发明过什么？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:40620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:48:21 async_llm_engine.py:436] Received request chatcmpl-84d50bec-3692-4ade-8d23-c25751e23a53: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>assistant\n合成氨是通过氮气和氢气的反应产生的，这是工业规模生产的关键过程。\n\n该工艺涉及几个步骤：\n\n1. 氮气压缩和净化：首先，从空气中分离出氮气。然后对氮气进行压缩并进一步纯化，去除任何杂质气体或惰性元素。\n\n2. **Haber-Bosch** 固定床催化氨合成：来自压缩机的高压、高纯度的氮气和氢气被送入固定床反应器中。在高温高压下，两种气体发生化学反应生成氨（NH₃）和水蒸气（H₂O）。在此过程中使用的催化剂主要是铁基的，其中活性成分通常是氧化铁(III)(Fe₂O₃))。 \n\n3. 热交换回收：离开反应器的气体混合物含有大量未反应的氮气和氢气以及生成的氨和水蒸汽。为了最大限度地利用原料，将此混合物流通过一系列热交换器，以加热新鲜进料流并将其冷却至较低温度，从而形成冷凝物可以收集到的液态水。\n\n4. 吸收与解吸：在高浓度条件下获得的液体产物 stream 随后进入一个胺溶液的吸收塔，在这里氨溶解到碱性溶剂中以形成富含氨的“富”溶液。剩余的气体作为贫级流返回系统，在那里它们将在工序中被重新使用。\n\n5. 精馏：氨溶液接着由两个连续操作的精馏塔进行处理。第一个塔被称为预分馏塔，它用于部分浓缩含氨溶液中的氨含量，同时产生称为“回流”的部分浓缩溶液。第二个塔是主要精馏塔，它接收了主要由氨组成的回流，并通过使塔顶馏出物部分冷凝和液化来对其进行进一步提纯。这些液体产物可以直接储存和使用，或者可以被进一步加工以获得更高浓度的特定化学品，例如硝酸铵(NH₄NO₃)等肥料。<|im_end|>\n<|im_start|>user\n谁发明的？<|im_end|>\n<|im_start|>assistant\n哈伯-博施法的发明者是两位德国科学家弗里茨·哈伯（Fritz Haber）和卡尔·博施（Carl Bosch）。他们于1909年首次开发出了这一革命性的技术。他们的工作彻底改变了化肥和其他重要产品的生产和供应方式。<|im_end|>\n<|im_start|>user\n他还发明过什么？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 70409, 62715, 76288, 63436, 84721, 63167, 70724, 69076, 72544, 60353, 68472, 69042, 69801, 68548, 73758, 68468, 60355, 402, 60658, 69584, 70432, 68650, 68264, 60387, 402, 312, 281, 262, 63436, 60642, 70879, 60381, 72953, 60387, 68400, 60353, 60577, 84502, 71759, 60389, 63436, 60642, 60355, 68265, 60409, 63436, 60642, 68274, 70879, 60573, 69806, 61487, 60516, 60353, 70694, 68574, 78852, 73341, 60535, 64211, 60489, 69403, 60355, 402, 314, 281, 3235, 318, 42768, 7810, 567, 462, 465, 262, 69393, 61191, 78188, 62715, 70409, 60387, 69033, 86235, 69494, 60952, 60359, 60436, 61487, 69869, 63436, 84721, 63167, 60642, 60549, 89653, 69393, 61191, 69076, 60682, 60366, 60355, 60361, 71909, 73011, 60380, 60353, 69589, 73341, 68526, 91395, 70563, 62715, 60414, 50434, 67969, 60413, 76398, 61649, 60642, 60414, 318, 229, 133, 133, 306, 60413, 60355, 69890, 68835, 70017, 90281, 69802, 61174, 60630, 60354, 60353, 68415, 73094, 69937, 80558, 70101, 61174, 298, 22912, 2530, 6276, 229, 133, 133, 306, 67969, 724, 60355, 4872, 308, 281, 262, 60766, 72124, 72323, 60387, 69365, 69076, 70538, 73341, 86428, 69515, 69436, 60984, 69076, 60354, 63436, 84721, 63167, 60642, 68375, 83475, 62715, 76398, 76081, 60355, 68394, 90022, 60415, 68685, 68296, 60353, 60530, 60603, 69275, 70967, 68330, 72609, 60766, 72124, 60682, 60353, 60367, 70196, 70022, 60433, 60545, 60673, 89478, 71387, 60615, 75856, 69032, 60353, 69172, 68722, 61114, 62210, 60502, 68251, 70507, 69333, 61258, 60921, 60456, 60355, 402, 319, 281, 262, 69664, 60510, 60595, 61124, 60387, 81357, 74249, 76168, 75558, 73128, 77144, 4427, 262, 70322, 68291, 68252, 63292, 74202, 85332, 61322, 60353, 69438, 62715, 75719, 60378, 80722, 82681, 85157, 68722, 72349, 62715, 60354, 60419, 61067, 60420, 74202, 60355, 80879, 73341, 68429, 62085, 60674, 60673, 70121, 68308, 60353, 76667, 69290, 73030, 82083, 77890, 68928, 68271, 60355, 402, 317, 281, 262, 60777, 64987, 60387, 62715, 74202, 68692, 60620, 68451, 69591, 81206, 60777, 64987, 61322, 90124, 60355, 69423, 61322, 72712, 61030, 60402, 64987, 61322, 60353, 60741, 68815, 68340, 82725, 61116, 62715, 74202, 68322, 62715, 70467, 60353, 68405, 68701, 69402, 60419, 60584, 60673, 60420, 71653, 82725, 74202, 60355, 71129, 61322, 60357, 68326, 60777, 64987, 61322, 60353, 60741, 71682, 60362, 85107, 62715, 75887, 60584, 60673, 60353, 83707, 60534, 61322, 61375, 64987, 60389, 60502, 68340, 61114, 62210, 60381, 91629, 60383, 91225, 69806, 60546, 61487, 60355, 68374, 73128, 77144, 71555, 73628, 82154, 60353, 68319, 87756, 69806, 69619, 60367, 68422, 71841, 61822, 69869, 73295, 69383, 60492, 60353, 69192, 82139, 65161, 8337, 318, 229, 133, 135, 9128, 67969, 313, 60455, 78413, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 61297, 73214, 60354, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60937, 61614, 285, 61068, 61043, 60408, 71545, 60561, 88749, 75560, 69477, 74800, 80707, 62483, 60721, 60937, 61614, 60414, 311, 55615, 29197, 392, 60413, 60381, 75552, 60721, 61068, 61043, 60414, 8987, 270, 28335, 462, 60413, 60355, 68310, 60418, 904, 2640, 60372, 70143, 68640, 68758, 68597, 69769, 68739, 68362, 60355, 69291, 68273, 70348, 78666, 91418, 71842, 68372, 70690, 89611, 70715, 68386, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 74354, 73214, 60417, 68261, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:48:21 metrics.py:213] Avg prompt throughput: 56.8 tokens/s, Avg generation throughput: 5.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:48:24 async_llm_engine.py:110] Finished request chatcmpl-84d50bec-3692-4ade-8d23-c25751e23a53.
2024-03-28 21:49:06.876 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'role': 'assistant', 'content': '哈伯-博施法的发明者是两位德国科学家弗里茨·哈伯（Fritz Haber）和卡尔·博施（Carl Bosch）。他们于1909年首次开发出了这一革命性的技术。他们的工作彻底改变了化肥和其他重要产品的生产和供应方式。'}, {'content': '他还发明过什么？', 'role': 'user'}, {'role': 'assistant', 'content': '除了参与哈伯-博施法的开发之外，弗里茨·哈伯在其职业生涯中还取得了多项其他科学和技术进步。他的一些著名成就包括：\n\n1. 氮肥的生产：除了参与发展氨合成方法外，哈伯还在20世纪初推广农业用氮肥的使用方面发挥了重要作用。这有助于提高作物产量并为全球粮食安全做出贡献。\n\n2.氯化物的研究：哈伯早期从事的研究之一是对氯化合物性质的探索。这项工作的成果之一是发现了四氟乙烯(TFE)，它是聚四氟乙烯(PTFE)的重要组成部分，后者广泛用作不粘涂层和各种应用中的绝缘材料。\n\n3.军事技术的创新：哈伯的工作也对第一次世界大战期间武器技术和毒剂的发展产生了重大影响。具体来说，哈伯参与了有毒气体战争剂氯气的研究和改进。此外，他在一战期间开发的臭氧消毒系统和二氧化硫烟雾探测系统也被用来增强航空作战能力并在战斗情况下检测有害污染物的存在。'}, {'content': '他的历史功过如何评价？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:46192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:49:06 async_llm_engine.py:436] Received request chatcmpl-faceb999-0d18-4cb4-b506-1f8036330bec: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>assistant\n哈伯-博施法的发明者是两位德国科学家弗里茨·哈伯（Fritz Haber）和卡尔·博施（Carl Bosch）。他们于1909年首次开发出了这一革命性的技术。他们的工作彻底改变了化肥和其他重要产品的生产和供应方式。<|im_end|>\n<|im_start|>user\n他还发明过什么？<|im_end|>\n<|im_start|>assistant\n除了参与哈伯-博施法的开发之外，弗里茨·哈伯在其职业生涯中还取得了多项其他科学和技术进步。他的一些著名成就包括：\n\n1. 氮肥的生产：除了参与发展氨合成方法外，哈伯还在20世纪初推广农业用氮肥的使用方面发挥了重要作用。这有助于提高作物产量并为全球粮食安全做出贡献。\n\n2.氯化物的研究：哈伯早期从事的研究之一是对氯化合物性质的探索。这项工作的成果之一是发现了四氟乙烯(TFE)，它是聚四氟乙烯(PTFE)的重要组成部分，后者广泛用作不粘涂层和各种应用中的绝缘材料。\n\n3.军事技术的创新：哈伯的工作也对第一次世界大战期间武器技术和毒剂的发展产生了重大影响。具体来说，哈伯参与了有毒气体战争剂氯气的研究和改进。此外，他在一战期间开发的臭氧消毒系统和二氧化硫烟雾探测系统也被用来增强航空作战能力并在战斗情况下检测有害污染物的存在。<|im_end|>\n<|im_start|>user\n他的历史功过如何评价？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60937, 61614, 285, 61068, 61043, 60408, 71545, 60561, 88749, 75560, 69477, 74800, 80707, 62483, 60721, 60937, 61614, 60414, 311, 55615, 29197, 392, 60413, 60381, 75552, 60721, 61068, 61043, 60414, 8987, 270, 28335, 462, 60413, 60355, 68310, 60418, 904, 2640, 60372, 70143, 68640, 68758, 68597, 69769, 68739, 68362, 60355, 69291, 68273, 70348, 78666, 91418, 71842, 68372, 70690, 89611, 70715, 68386, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 74354, 73214, 60417, 68261, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68632, 69102, 60937, 61614, 285, 61068, 61043, 72444, 68640, 69649, 60353, 80707, 62483, 60721, 60937, 61614, 73695, 74467, 60366, 60430, 74630, 76741, 68345, 68575, 80613, 70212, 60355, 60404, 69961, 70249, 70061, 68469, 60387, 402, 312, 281, 262, 63436, 61365, 80024, 60387, 68632, 69102, 68357, 62715, 70409, 68256, 60525, 60353, 60937, 61614, 69559, 638, 88363, 69765, 69388, 60379, 63436, 61365, 70920, 68503, 69935, 60362, 90030, 60355, 60376, 72195, 68577, 73343, 73676, 86264, 69199, 73503, 68419, 70083, 70661, 60355, 402, 314, 281, 80628, 71298, 68346, 60387, 60937, 61614, 71090, 69398, 71722, 68538, 71118, 63145, 73002, 88175, 70675, 60355, 76683, 70693, 70139, 68538, 60357, 72186, 60651, 63590, 80663, 4299, 11569, 313, 60353, 71661, 61522, 60651, 63590, 80663, 298, 2992, 11569, 313, 69987, 79579, 60353, 74831, 70073, 75732, 79646, 86456, 87892, 68481, 68322, 79572, 68545, 60355, 402, 308, 281, 70787, 74657, 69119, 60387, 60937, 61614, 69508, 88957, 68918, 80183, 68859, 69823, 79491, 61283, 61577, 69745, 75511, 71003, 68434, 60355, 68592, 68484, 60353, 60937, 61614, 85476, 79219, 73341, 69657, 61577, 63145, 70724, 84490, 73535, 60355, 69636, 60353, 69532, 89970, 68859, 78703, 62436, 61858, 71570, 78990, 78401, 62955, 87888, 78149, 68308, 72185, 69612, 69857, 70076, 72595, 68432, 70817, 69762, 69993, 69268, 74108, 70527, 71298, 68570, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68457, 68536, 60659, 60417, 68343, 69604, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:49:06 metrics.py:213] Avg prompt throughput: 9.4 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:49:08 async_llm_engine.py:110] Finished request chatcmpl-faceb999-0d18-4cb4-b506-1f8036330bec.
2024-03-28 21:52:08.978 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'role': 'assistant', 'content': '除了参与哈伯-博施法的开发之外，弗里茨·哈伯在其职业生涯中还取得了多项其他科学和技术进步。他的一些著名成就包括：\n\n1. 氮肥的生产：除了参与发展氨合成方法外，哈伯还在20世纪初推广农业用氮肥的使用方面发挥了重要作用。这有助于提高作物产量并为全球粮食安全做出贡献。\n\n2.氯化物的研究：哈伯早期从事的研究之一是对氯化合物性质的探索。这项工作的成果之一是发现了四氟乙烯(TFE)，它是聚四氟乙烯(PTFE)的重要组成部分，后者广泛用作不粘涂层和各种应用中的绝缘材料。\n\n3.军事技术的创新：哈伯的工作也对第一次世界大战期间武器技术和毒剂的发展产生了重大影响。具体来说，哈伯参与了有毒气体战争剂氯气的研究和改进。此外，他在一战期间开发的臭氧消毒系统和二氧化硫烟雾探测系统也被用来增强航空作战能力并在战斗情况下检测有害污染物的存在。'}, {'content': '他的历史功过如何评价？', 'role': 'user'}, {'role': 'assistant', 'content': '对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。'}, {'content': '你还知道哪些科学家？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:48772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:52:08 async_llm_engine.py:436] Received request chatcmpl-f7df4787-2e96-4fd7-bef4-8095d20cd252: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>assistant\n除了参与哈伯-博施法的开发之外，弗里茨·哈伯在其职业生涯中还取得了多项其他科学和技术进步。他的一些著名成就包括：\n\n1. 氮肥的生产：除了参与发展氨合成方法外，哈伯还在20世纪初推广农业用氮肥的使用方面发挥了重要作用。这有助于提高作物产量并为全球粮食安全做出贡献。\n\n2.氯化物的研究：哈伯早期从事的研究之一是对氯化合物性质的探索。这项工作的成果之一是发现了四氟乙烯(TFE)，它是聚四氟乙烯(PTFE)的重要组成部分，后者广泛用作不粘涂层和各种应用中的绝缘材料。\n\n3.军事技术的创新：哈伯的工作也对第一次世界大战期间武器技术和毒剂的发展产生了重大影响。具体来说，哈伯参与了有毒气体战争剂氯气的研究和改进。此外，他在一战期间开发的臭氧消毒系统和二氧化硫烟雾探测系统也被用来增强航空作战能力并在战斗情况下检测有害污染物的存在。<|im_end|>\n<|im_start|>user\n他的历史功过如何评价？<|im_end|>\n<|im_start|>assistant\n对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。<|im_end|>\n<|im_start|>user\n你还知道哪些科学家？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68632, 69102, 60937, 61614, 285, 61068, 61043, 72444, 68640, 69649, 60353, 80707, 62483, 60721, 60937, 61614, 73695, 74467, 60366, 60430, 74630, 76741, 68345, 68575, 80613, 70212, 60355, 60404, 69961, 70249, 70061, 68469, 60387, 402, 312, 281, 262, 63436, 61365, 80024, 60387, 68632, 69102, 68357, 62715, 70409, 68256, 60525, 60353, 60937, 61614, 69559, 638, 88363, 69765, 69388, 60379, 63436, 61365, 70920, 68503, 69935, 60362, 90030, 60355, 60376, 72195, 68577, 73343, 73676, 86264, 69199, 73503, 68419, 70083, 70661, 60355, 402, 314, 281, 80628, 71298, 68346, 60387, 60937, 61614, 71090, 69398, 71722, 68538, 71118, 63145, 73002, 88175, 70675, 60355, 76683, 70693, 70139, 68538, 60357, 72186, 60651, 63590, 80663, 4299, 11569, 313, 60353, 71661, 61522, 60651, 63590, 80663, 298, 2992, 11569, 313, 69987, 79579, 60353, 74831, 70073, 75732, 79646, 86456, 87892, 68481, 68322, 79572, 68545, 60355, 402, 308, 281, 70787, 74657, 69119, 60387, 60937, 61614, 69508, 88957, 68918, 80183, 68859, 69823, 79491, 61283, 61577, 69745, 75511, 71003, 68434, 60355, 68592, 68484, 60353, 60937, 61614, 85476, 79219, 73341, 69657, 61577, 63145, 70724, 84490, 73535, 60355, 69636, 60353, 69532, 89970, 68859, 78703, 62436, 61858, 71570, 78990, 78401, 62955, 87888, 78149, 68308, 72185, 69612, 69857, 70076, 72595, 68432, 70817, 69762, 69993, 69268, 74108, 70527, 71298, 68570, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68457, 68536, 60659, 60417, 68343, 69604, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60409, 80707, 62483, 60721, 60937, 61614, 60354, 74152, 68274, 78078, 71371, 86538, 69701, 60767, 80219, 74635, 75720, 60355, 72936, 60353, 60937, 61614, 60361, 69383, 69042, 69834, 79390, 60489, 86021, 68370, 74008, 60374, 69497, 68431, 72767, 72151, 70297, 60381, 61018, 66001, 60355, 60577, 69715, 69199, 69178, 68548, 60359, 69215, 86668, 73341, 76333, 60367, 72148, 71776, 68919, 68287, 68375, 70983, 68459, 69592, 77416, 70035, 81832, 69159, 60353, 60937, 61614, 73379, 70360, 69170, 79097, 68428, 60431, 60985, 68608, 68867, 68885, 71457, 88407, 68666, 88063, 68573, 60355, 402, 69104, 60353, 73486, 60353, 68826, 70763, 68551, 60937, 61614, 60510, 90649, 78018, 68558, 73895, 60353, 60573, 77855, 61308, 60411, 77969, 68859, 68552, 86357, 71842, 69657, 61804, 60412, 60355, 70842, 68315, 71347, 74375, 68330, 71378, 60937, 61614, 68429, 70226, 81039, 68567, 68575, 69137, 87412, 90553, 70888, 68685, 61197, 60385, 70747, 68802, 70661, 90075, 69349, 60383, 85800, 60535, 60910, 60624, 68374, 87463, 60353, 60499, 68724, 77368, 68332, 60353, 71729, 60937, 61614, 72357, 69669, 70718, 60409, 68339, 70514, 70102, 68625, 60360, 74635, 75081, 60353, 68614, 77068, 89530, 69574, 68528, 68994, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 75478, 68290, 69264, 74800, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:52:09 metrics.py:213] Avg prompt throughput: 2.9 tokens/s, Avg generation throughput: 0.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:52:11 async_llm_engine.py:110] Finished request chatcmpl-f7df4787-2e96-4fd7-bef4-8095d20cd252.
2024-03-28 21:52:29.838 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'role': 'assistant', 'content': '对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。'}, {'content': '你还知道哪些科学家？', 'role': 'user'}, {'role': 'assistant', 'content': '科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。'}, {'content': '总结聊天内容，越少越好', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:43972 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:52:29 async_llm_engine.py:436] Received request chatcmpl-b37e4cd1-4901-48b2-b8cc-fd29b6c12774: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>assistant\n对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。<|im_end|>\n<|im_start|>user\n你还知道哪些科学家？<|im_end|>\n<|im_start|>assistant\n科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。<|im_end|>\n<|im_start|>user\n总结聊天内容，越少越好<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60409, 80707, 62483, 60721, 60937, 61614, 60354, 74152, 68274, 78078, 71371, 86538, 69701, 60767, 80219, 74635, 75720, 60355, 72936, 60353, 60937, 61614, 60361, 69383, 69042, 69834, 79390, 60489, 86021, 68370, 74008, 60374, 69497, 68431, 72767, 72151, 70297, 60381, 61018, 66001, 60355, 60577, 69715, 69199, 69178, 68548, 60359, 69215, 86668, 73341, 76333, 60367, 72148, 71776, 68919, 68287, 68375, 70983, 68459, 69592, 77416, 70035, 81832, 69159, 60353, 60937, 61614, 73379, 70360, 69170, 79097, 68428, 60431, 60985, 68608, 68867, 68885, 71457, 88407, 68666, 88063, 68573, 60355, 402, 69104, 60353, 73486, 60353, 68826, 70763, 68551, 60937, 61614, 60510, 90649, 78018, 68558, 73895, 60353, 60573, 77855, 61308, 60411, 77969, 68859, 68552, 86357, 71842, 69657, 61804, 60412, 60355, 70842, 68315, 71347, 74375, 68330, 71378, 60937, 61614, 68429, 70226, 81039, 68567, 68575, 69137, 87412, 90553, 70888, 68685, 61197, 60385, 70747, 68802, 70661, 90075, 69349, 60383, 85800, 60535, 60910, 60624, 68374, 87463, 60353, 60499, 68724, 77368, 68332, 60353, 71729, 60937, 61614, 72357, 69669, 70718, 60409, 68339, 70514, 70102, 68625, 60360, 74635, 75081, 60353, 68614, 77068, 89530, 69574, 68528, 68994, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 75478, 68290, 69264, 74800, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68575, 69052, 92206, 60389, 70732, 62015, 68555, 74800, 60353, 68310, 79097, 68865, 68519, 72168, 74791, 68386, 79074, 72397, 60458, 60887, 75537, 70661, 60355, 73622, 68315, 71821, 70781, 60387, 402, 465, 87928, 60721, 85928, 60414, 304, 1725, 8061, 27597, 60413, 465, 60387, 86559, 63034, 68490, 73214, 60396, 60359, 73428, 71446, 60359, 69473, 71166, 88127, 73258, 60353, 76694, 70073, 74832, 74149, 60442, 76433, 73214, 87966, 76385, 79607, 70248, 60355, 79539, 68898, 74467, 60366, 60353, 85928, 60374, 71789, 68512, 60392, 60359, 62164, 76925, 60359, 88219, 71306, 68362, 83289, 69626, 68524, 75020, 70212, 78637, 79074, 70925, 79390, 68739, 68372, 70661, 60355, 68415, 68315, 72505, 68273, 68469, 68949, 60478, 71545, 60561, 60359, 69956, 71659, 84642, 69662, 60359, 85928, 91284, 71011, 68375, 68815, 78123, 70343, 76938, 70471, 60682, 69745, 60455, 60355, 402, 465, 77001, 60721, 61039, 60425, 60414, 12213, 776, 13036, 776, 60413, 465, 60387, 75734, 63034, 69277, 69473, 71166, 60381, 69383, 60396, 60353, 72628, 69423, 68422, 70123, 85129, 61149, 68279, 92395, 904, 2934, 90065, 60419, 60361, 65953, 87176, 72958, 69975, 70534, 69834, 79390, 60489, 68346, 60420, 60458, 73074, 83458, 61149, 60506, 904, 933, 90065, 60419, 90388, 69380, 71722, 60420, 60458, 73074, 69383, 61149, 60355, 68759, 68273, 80953, 85716, 72471, 90034, 60353, 83707, 68271, 90388, 60466, 60496, 60881, 69328, 68256, 60374, 70149, 71422, 87499, 83903, 68641, 78285, 60355, 60564, 90123, 70661, 68538, 60357, 89100, 66346, 69403, 74280, 60353, 88387, 68491, 60549, 68551, 91106, 60355, 402, 88466, 75560, 68537, 88746, 75786, 68575, 69137, 60743, 60371, 68387, 60353, 76079, 84210, 70612, 87779, 80622, 78498, 81252, 60353, 60573, 77852, 75647, 70446, 68339, 75511, 77650, 80895, 87949, 69231, 68434, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68621, 68960, 68341, 60353, 60786, 60605, 73158, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:52:29 metrics.py:213] Avg prompt throughput: 28.4 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:52:30 async_llm_engine.py:110] Finished request chatcmpl-b37e4cd1-4901-48b2-b8cc-fd29b6c12774.
2024-03-28 21:53:40.978 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'role': 'assistant', 'content': '对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。'}, {'content': '你还知道哪些科学家？', 'role': 'user'}, {'role': 'assistant', 'content': '科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。'}, {'content': 'Summarize the chat content, the less the better', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:46858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:53:40 async_llm_engine.py:436] Received request chatcmpl-a6aaba36-4e41-464e-8377-b9369a06e6a8: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>assistant\n对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。<|im_end|>\n<|im_start|>user\n你还知道哪些科学家？<|im_end|>\n<|im_start|>assistant\n科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。<|im_end|>\n<|im_start|>user\nSummarize the chat content, the less the better<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60409, 80707, 62483, 60721, 60937, 61614, 60354, 74152, 68274, 78078, 71371, 86538, 69701, 60767, 80219, 74635, 75720, 60355, 72936, 60353, 60937, 61614, 60361, 69383, 69042, 69834, 79390, 60489, 86021, 68370, 74008, 60374, 69497, 68431, 72767, 72151, 70297, 60381, 61018, 66001, 60355, 60577, 69715, 69199, 69178, 68548, 60359, 69215, 86668, 73341, 76333, 60367, 72148, 71776, 68919, 68287, 68375, 70983, 68459, 69592, 77416, 70035, 81832, 69159, 60353, 60937, 61614, 73379, 70360, 69170, 79097, 68428, 60431, 60985, 68608, 68867, 68885, 71457, 88407, 68666, 88063, 68573, 60355, 402, 69104, 60353, 73486, 60353, 68826, 70763, 68551, 60937, 61614, 60510, 90649, 78018, 68558, 73895, 60353, 60573, 77855, 61308, 60411, 77969, 68859, 68552, 86357, 71842, 69657, 61804, 60412, 60355, 70842, 68315, 71347, 74375, 68330, 71378, 60937, 61614, 68429, 70226, 81039, 68567, 68575, 69137, 87412, 90553, 70888, 68685, 61197, 60385, 70747, 68802, 70661, 90075, 69349, 60383, 85800, 60535, 60910, 60624, 68374, 87463, 60353, 60499, 68724, 77368, 68332, 60353, 71729, 60937, 61614, 72357, 69669, 70718, 60409, 68339, 70514, 70102, 68625, 60360, 74635, 75081, 60353, 68614, 77068, 89530, 69574, 68528, 68994, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 75478, 68290, 69264, 74800, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68575, 69052, 92206, 60389, 70732, 62015, 68555, 74800, 60353, 68310, 79097, 68865, 68519, 72168, 74791, 68386, 79074, 72397, 60458, 60887, 75537, 70661, 60355, 73622, 68315, 71821, 70781, 60387, 402, 465, 87928, 60721, 85928, 60414, 304, 1725, 8061, 27597, 60413, 465, 60387, 86559, 63034, 68490, 73214, 60396, 60359, 73428, 71446, 60359, 69473, 71166, 88127, 73258, 60353, 76694, 70073, 74832, 74149, 60442, 76433, 73214, 87966, 76385, 79607, 70248, 60355, 79539, 68898, 74467, 60366, 60353, 85928, 60374, 71789, 68512, 60392, 60359, 62164, 76925, 60359, 88219, 71306, 68362, 83289, 69626, 68524, 75020, 70212, 78637, 79074, 70925, 79390, 68739, 68372, 70661, 60355, 68415, 68315, 72505, 68273, 68469, 68949, 60478, 71545, 60561, 60359, 69956, 71659, 84642, 69662, 60359, 85928, 91284, 71011, 68375, 68815, 78123, 70343, 76938, 70471, 60682, 69745, 60455, 60355, 402, 465, 77001, 60721, 61039, 60425, 60414, 12213, 776, 13036, 776, 60413, 465, 60387, 75734, 63034, 69277, 69473, 71166, 60381, 69383, 60396, 60353, 72628, 69423, 68422, 70123, 85129, 61149, 68279, 92395, 904, 2934, 90065, 60419, 60361, 65953, 87176, 72958, 69975, 70534, 69834, 79390, 60489, 68346, 60420, 60458, 73074, 83458, 61149, 60506, 904, 933, 90065, 60419, 90388, 69380, 71722, 60420, 60458, 73074, 69383, 61149, 60355, 68759, 68273, 80953, 85716, 72471, 90034, 60353, 83707, 68271, 90388, 60466, 60496, 60881, 69328, 68256, 60374, 70149, 71422, 87499, 83903, 68641, 78285, 60355, 60564, 90123, 70661, 68538, 60357, 89100, 66346, 69403, 74280, 60353, 88387, 68491, 60549, 68551, 91106, 60355, 402, 88466, 75560, 68537, 88746, 75786, 68575, 69137, 60743, 60371, 68387, 60353, 76079, 84210, 70612, 87779, 80622, 78498, 81252, 60353, 60573, 77852, 75647, 70446, 68339, 75511, 77650, 80895, 87949, 69231, 68434, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 9321, 5768, 682, 410, 6392, 2364, 328, 410, 2848, 410, 2826, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:53:41 metrics.py:213] Avg prompt throughput: 8.4 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:53:42 async_llm_engine.py:110] Finished request chatcmpl-a6aaba36-4e41-464e-8377-b9369a06e6a8.
2024-03-28 21:54:55.841 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\n这篇对话内容涵盖了两个主题：1）弗里茨·哈伯（Fritz Haber）的遗产评估，2）其他著名科学家的简介。鉴于您要求摘要尽可能短的要求，我将把这两部分的内容总结如下：\n\n讨论了弗里茨·哈伯的历史意义及他可能参与过的有争议行为，同时还提到了他的成就和贡献。此外，还介绍了另外两位享有盛誉的科学家：玛丽·居里和尼古拉·特斯拉，重点介绍了他们的主要成就在各自专业中的显著地位。\n\n你好，我们继续聊聊吧', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:58378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:54:55 async_llm_engine.py:436] Received request chatcmpl-828713ee-039b-4b76-903e-d755c791ae7b: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n我们之前聊了：\n这篇对话内容涵盖了两个主题：1）弗里茨·哈伯（Fritz Haber）的遗产评估，2）其他著名科学家的简介。鉴于您要求摘要尽可能短的要求，我将把这两部分的内容总结如下：\n\n讨论了弗里茨·哈伯的历史意义及他可能参与过的有争议行为，同时还提到了他的成就和贡献。此外，还介绍了另外两位享有盛誉的科学家：玛丽·居里和尼古拉·特斯拉，重点介绍了他们的主要成就在各自专业中的显著地位。\n\n你好，我们继续聊聊吧<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68253, 68478, 61277, 60362, 60387, 364, 70604, 68983, 68341, 88530, 68451, 69685, 60387, 312, 60413, 80707, 62483, 60721, 60937, 61614, 60414, 311, 55615, 29197, 392, 60413, 60354, 74152, 71371, 60353, 314, 60413, 68345, 70249, 68575, 69137, 68487, 60355, 84627, 61176, 68456, 82635, 72703, 61123, 71076, 60353, 80025, 60581, 72030, 68340, 69979, 77722, 60387, 402, 70069, 60362, 80707, 62483, 60721, 60937, 61614, 72357, 69022, 60543, 60404, 68295, 69102, 69087, 60360, 74635, 68891, 60353, 85110, 60546, 68384, 68457, 70061, 60381, 70661, 60355, 69636, 60353, 60430, 72506, 68721, 75560, 76808, 61600, 61968, 60354, 74800, 60387, 77001, 60721, 61039, 60425, 60381, 87928, 60721, 85928, 60353, 68894, 72506, 69291, 68326, 60397, 69303, 71484, 68388, 68322, 72731, 70248, 60355, 402, 77230, 60353, 68253, 68528, 79084, 60701, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:54:55 metrics.py:213] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 1.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:54:57 async_llm_engine.py:110] Finished request chatcmpl-828713ee-039b-4b76-903e-d755c791ae7b.
2024-03-28 21:55:03.362 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\n这篇对话内容涵盖了两个主题：1）弗里茨·哈伯（Fritz Haber）的遗产评估，2）其他著名科学家的简介。鉴于您要求摘要尽可能短的要求，我将把这两部分的内容总结如下：\n\n讨论了弗里茨·哈伯的历史意义及他可能参与过的有争议行为，同时还提到了他的成就和贡献。此外，还介绍了另外两位享有盛誉的科学家：玛丽·居里和尼古拉·特斯拉，重点介绍了他们的主要成就在各自专业中的显著地位。\n\n你好，我们继续聊聊吧', 'role': 'user'}, {'role': 'assistant', 'content': '当然，我很乐意与您进一步探讨这个话题！如您所知，“合成氨”的发明无疑是一项开创性的技术突破，它不仅彻底改变了化学工业的面貌，而且对全球能源格局产生了深远的影响。 \n\n弗里茨·哈伯在这一领域取得的众多成就之一就是开发了一种高效催化剂，可以大大加快氮气和氢气的反应速率，从而最终导致大规模生产合成氨的成功实现。  \n\n然而，值得注意的是，弗里茨·哈伯在推进该领域的科学发展方面发挥的关键作用不应掩盖他在二战期间可能产生的一些负面影响——例如，他与纳粹党的关系以及他对种族灭绝计划的支持。尽管如此，哈伯作为一名杰出的化学家和先驱者，其历史评价仍然很大程度上取决于人们如何看待与平衡其卓越的技术创新成果与其潜在的有害后果之间的关系。'}, {'content': 'Please generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.', 'role': 'user'}], 'echo': False}
INFO 03-28 21:55:03 async_llm_engine.py:436] Received request chatcmpl-69b5ae11-130a-4c67-ae0a-7d35f35a74b7: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n我们之前聊了：\n这篇对话内容涵盖了两个主题：1）弗里茨·哈伯（Fritz Haber）的遗产评估，2）其他著名科学家的简介。鉴于您要求摘要尽可能短的要求，我将把这两部分的内容总结如下：\n\n讨论了弗里茨·哈伯的历史意义及他可能参与过的有争议行为，同时还提到了他的成就和贡献。此外，还介绍了另外两位享有盛誉的科学家：玛丽·居里和尼古拉·特斯拉，重点介绍了他们的主要成就在各自专业中的显著地位。\n\n你好，我们继续聊聊吧<|im_end|>\n<|im_start|>assistant\n当然，我很乐意与您进一步探讨这个话题！如您所知，“合成氨”的发明无疑是一项开创性的技术突破，它不仅彻底改变了化学工业的面貌，而且对全球能源格局产生了深远的影响。 \n\n弗里茨·哈伯在这一领域取得的众多成就之一就是开发了一种高效催化剂，可以大大加快氮气和氢气的反应速率，从而最终导致大规模生产合成氨的成功实现。  \n\n然而，值得注意的是，弗里茨·哈伯在推进该领域的科学发展方面发挥的关键作用不应掩盖他在二战期间可能产生的一些负面影响——例如，他与纳粹党的关系以及他对种族灭绝计划的支持。尽管如此，哈伯作为一名杰出的化学家和先驱者，其历史评价仍然很大程度上取决于人们如何看待与平衡其卓越的技术创新成果与其潜在的有害后果之间的关系。<|im_end|>\n<|im_start|>user\nPlease generate a four to five word title summarizing our conversation without any lead-in, punctuation, quotation marks, periods, symbols, bold text, or additional text. Remove enclosing quotation marks.<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68253, 68478, 61277, 60362, 60387, 364, 70604, 68983, 68341, 88530, 68451, 69685, 60387, 312, 60413, 80707, 62483, 60721, 60937, 61614, 60414, 311, 55615, 29197, 392, 60413, 60354, 74152, 71371, 60353, 314, 60413, 68345, 70249, 68575, 69137, 68487, 60355, 84627, 61176, 68456, 82635, 72703, 61123, 71076, 60353, 80025, 60581, 72030, 68340, 69979, 77722, 60387, 402, 70069, 60362, 80707, 62483, 60721, 60937, 61614, 72357, 69022, 60543, 60404, 68295, 69102, 69087, 60360, 74635, 68891, 60353, 85110, 60546, 68384, 68457, 70061, 60381, 70661, 60355, 69636, 60353, 60430, 72506, 68721, 75560, 76808, 61600, 61968, 60354, 74800, 60387, 77001, 60721, 61039, 60425, 60381, 87928, 60721, 85928, 60353, 68894, 72506, 69291, 68326, 60397, 69303, 71484, 68388, 68322, 72731, 70248, 60355, 402, 77230, 60353, 68253, 68528, 79084, 60701, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68529, 60353, 70805, 81016, 91569, 69806, 73286, 79772, 60477, 91130, 60431, 60538, 60353, 60419, 70409, 62715, 60420, 71545, 60561, 74008, 86538, 79390, 68739, 68362, 70360, 60353, 60741, 68710, 70348, 78666, 69383, 69042, 74910, 62033, 60353, 68389, 60409, 69199, 70600, 74146, 75511, 60887, 61016, 70514, 60355, 4872, 80707, 62483, 60721, 60937, 61614, 86102, 69052, 92094, 70732, 70061, 68538, 68259, 68640, 77033, 71168, 90281, 60353, 68251, 71208, 71903, 63436, 84721, 63167, 70724, 69076, 80237, 60353, 69172, 68985, 68601, 78601, 68548, 70409, 62715, 81947, 68651, 60355, 18756, 69104, 60353, 88473, 60353, 80707, 62483, 60721, 60937, 61614, 60361, 70983, 60658, 75020, 68575, 68357, 68503, 69935, 73758, 68525, 79695, 82708, 69532, 77969, 68859, 68295, 68701, 69961, 76060, 68434, 92395, 69192, 60353, 83663, 90649, 61147, 71797, 68375, 79691, 76942, 86527, 68784, 78252, 60355, 70842, 68994, 60353, 60937, 61614, 83006, 62015, 68555, 69383, 87966, 60609, 61927, 60497, 60353, 60451, 68536, 69604, 70102, 84513, 75405, 68826, 68343, 75919, 60510, 70204, 60451, 75272, 73379, 69119, 70139, 73327, 79108, 72672, 61022, 73021, 82409, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 5658, 7076, 395, 3205, 442, 4393, 3571, 2416, 28634, 5008, 1181, 10571, 2192, 1030, 3154, 3580, 328, 60117, 328, 53245, 15546, 328, 18500, 328, 17880, 328, 14082, 1614, 328, 607, 5268, 1614, 281, 10930, 3374, 17976, 53245, 15546, 15889, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:55:03 metrics.py:213] Avg prompt throughput: 60.6 tokens/s, Avg generation throughput: 21.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:55:04 async_llm_engine.py:110] Finished request chatcmpl-69b5ae11-130a-4c67-ae0a-7d35f35a74b7.
INFO:     10.1.96.6:49966 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 21:58:02.687 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'role': 'assistant', 'content': '对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。'}, {'content': '你还知道哪些科学家？', 'role': 'user'}, {'role': 'assistant', 'content': '科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。'}, {'content': '如何成为一个科学家？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:53948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:58:02 async_llm_engine.py:436] Received request chatcmpl-685e9a35-6a07-462e-8b5a-27c77acd1bb7: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>assistant\n对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。<|im_end|>\n<|im_start|>user\n你还知道哪些科学家？<|im_end|>\n<|im_start|>assistant\n科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。<|im_end|>\n<|im_start|>user\n如何成为一个科学家？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60409, 80707, 62483, 60721, 60937, 61614, 60354, 74152, 68274, 78078, 71371, 86538, 69701, 60767, 80219, 74635, 75720, 60355, 72936, 60353, 60937, 61614, 60361, 69383, 69042, 69834, 79390, 60489, 86021, 68370, 74008, 60374, 69497, 68431, 72767, 72151, 70297, 60381, 61018, 66001, 60355, 60577, 69715, 69199, 69178, 68548, 60359, 69215, 86668, 73341, 76333, 60367, 72148, 71776, 68919, 68287, 68375, 70983, 68459, 69592, 77416, 70035, 81832, 69159, 60353, 60937, 61614, 73379, 70360, 69170, 79097, 68428, 60431, 60985, 68608, 68867, 68885, 71457, 88407, 68666, 88063, 68573, 60355, 402, 69104, 60353, 73486, 60353, 68826, 70763, 68551, 60937, 61614, 60510, 90649, 78018, 68558, 73895, 60353, 60573, 77855, 61308, 60411, 77969, 68859, 68552, 86357, 71842, 69657, 61804, 60412, 60355, 70842, 68315, 71347, 74375, 68330, 71378, 60937, 61614, 68429, 70226, 81039, 68567, 68575, 69137, 87412, 90553, 70888, 68685, 61197, 60385, 70747, 68802, 70661, 90075, 69349, 60383, 85800, 60535, 60910, 60624, 68374, 87463, 60353, 60499, 68724, 77368, 68332, 60353, 71729, 60937, 61614, 72357, 69669, 70718, 60409, 68339, 70514, 70102, 68625, 60360, 74635, 75081, 60353, 68614, 77068, 89530, 69574, 68528, 68994, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 75478, 68290, 69264, 74800, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68575, 69052, 92206, 60389, 70732, 62015, 68555, 74800, 60353, 68310, 79097, 68865, 68519, 72168, 74791, 68386, 79074, 72397, 60458, 60887, 75537, 70661, 60355, 73622, 68315, 71821, 70781, 60387, 402, 465, 87928, 60721, 85928, 60414, 304, 1725, 8061, 27597, 60413, 465, 60387, 86559, 63034, 68490, 73214, 60396, 60359, 73428, 71446, 60359, 69473, 71166, 88127, 73258, 60353, 76694, 70073, 74832, 74149, 60442, 76433, 73214, 87966, 76385, 79607, 70248, 60355, 79539, 68898, 74467, 60366, 60353, 85928, 60374, 71789, 68512, 60392, 60359, 62164, 76925, 60359, 88219, 71306, 68362, 83289, 69626, 68524, 75020, 70212, 78637, 79074, 70925, 79390, 68739, 68372, 70661, 60355, 68415, 68315, 72505, 68273, 68469, 68949, 60478, 71545, 60561, 60359, 69956, 71659, 84642, 69662, 60359, 85928, 91284, 71011, 68375, 68815, 78123, 70343, 76938, 70471, 60682, 69745, 60455, 60355, 402, 465, 77001, 60721, 61039, 60425, 60414, 12213, 776, 13036, 776, 60413, 465, 60387, 75734, 63034, 69277, 69473, 71166, 60381, 69383, 60396, 60353, 72628, 69423, 68422, 70123, 85129, 61149, 68279, 92395, 904, 2934, 90065, 60419, 60361, 65953, 87176, 72958, 69975, 70534, 69834, 79390, 60489, 68346, 60420, 60458, 73074, 83458, 61149, 60506, 904, 933, 90065, 60419, 90388, 69380, 71722, 60420, 60458, 73074, 69383, 61149, 60355, 68759, 68273, 80953, 85716, 72471, 90034, 60353, 83707, 68271, 90388, 60466, 60496, 60881, 69328, 68256, 60374, 70149, 71422, 87499, 83903, 68641, 78285, 60355, 60564, 90123, 70661, 68538, 60357, 89100, 66346, 69403, 74280, 60353, 88387, 68491, 60549, 68551, 91106, 60355, 402, 88466, 75560, 68537, 88746, 75786, 68575, 69137, 60743, 60371, 68387, 60353, 76079, 84210, 70612, 87779, 80622, 78498, 81252, 60353, 60573, 77852, 75647, 70446, 68339, 75511, 77650, 80895, 87949, 69231, 68434, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68343, 76425, 74800, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:58:02 metrics.py:213] Avg prompt throughput: 3.3 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:58:07 async_llm_engine.py:110] Finished request chatcmpl-685e9a35-6a07-462e-8b5a-27c77acd1bb7.
2024-03-28 21:58:23.948 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'We chatted before:\n**【正文开始】**\n\n# ***二. tf.keras API Overview and Common Features / Techiques Explanation Analysis Part Two : Advanced Extension Modules, Technics Deep Dive Study Tutorial Case Research Report*** \n\n本篇文章将继续讨论 TensorFlow 的相关主题，即关于 *tf.keras* API 的更高级别的功能和技巧的详细分析和解释。在这个部分，我们将更深入地探索有关基于深度学习的先进计算机视觉和自然语言处理应用程序的各种技术和策略的知识。此外，我们还将在本教程中使用多个实际示例进行演示，以帮助读者更好地理解和掌握这些复杂的技术和技能。\n\n---\n\n#  **1. tf.keras API Overview - Key Components Structure Explained in Detail with Visualization Examples for Better Understanding Intuition Acquisition Learning Process Improvement Optimization Enhancement Strategy Framework Development Implementation Execution Procedure Workflow Management Control Flow Guidance Direction Navigation Support System Application Construction Real World Problem Solution Resolution Achievement Goal Attainment Progress Performance Evaluation Measurement Comparison Assessment Quality Assurance Methodology Approach Algorithmic Processing Step-by-step Operation Procedural Specification Description Documentation Generation Preparation Output Presentation Display Representation Rendering Visualize Showcase Demonstrate Exhibit Publicly Present to Audience Share Knowledge Transfer Information Enlighten Teach Inspire Motivate Stir Up Emotionally Arouse Excite Make Thrill Amaze Surprise Delight Rejoice Gladdened Grateful Thankful Appreciative Mindfull Aware Cognizant Perceptive Inspect Scrutineze Investigative Analytical Critical Thinking Reason Logical Deductive Inference Abduction Induction Hypothesis Theory Law Rule Principle Maxim Dictum Canon Truism Folklore Wisdom Lore Myth Legend Anecdote Story Tale Saga Epic Poem Ballad Ode Song Lyric Hymn Prayer Religious Text Document Scroll Manuscript Codex Tablet Stone Carving Chisel Etched Engaved Crafted Fabricated Made Created Formulated Composed Compiled Assembled Put Together Set up Initiated Started Turn On Go Live Deploy Run Execute Implement Practice Use Play Experiment Try Out Test Validate Compare Contrast Measure Evaluate Judge Rate Score Rank Order Prioritize Select Choose Pick Determine Decide Figure out Get Understand Uncover Discover Learn Master Gain Proficiency Develop Cultivat Enhanc Improve Upgrade Elevati Optimi Optimi Perfecti Ideali Idealizzatio Purificatorio Transfigurazione Transformaci Transformatione TranscensionTransformational Evolutionary Ecosystemic Sustainable Eco-Friendly Friendly Environmentally Responsible Green Socially Conscious Ethically Morally Justifiably Defensible', 'role': 'system'}, {'content': '他的历史功过如何评价？', 'role': 'user'}, {'role': 'assistant', 'content': '对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。'}, {'content': '你还知道哪些科学家？', 'role': 'user'}, {'role': 'assistant', 'content': '科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。'}, {'content': '如何成为一个科学家？', 'role': 'user'}, {'role': 'assistant', 'content': '成为一名科学家需要结合天赋、努力工作和奉献精神，以及对学习和探索未知事物的深刻热情。这是一个多步骤的过程，涉及教育、培训和各种实践经验。下面是成为科学家的详细路线图：\n\n1. **培养好奇心和学习欲望：**\n\n   作为一名未来的科学家，第一步也是最关键的一步就是培养强烈的好奇心和学习欲。这意味着您应该始终保持开放的心态，乐于接受新想法和新观点，并对你的知识边界之外的世界充满好奇。这种好奇心和学习欲将激励你不断地深入探究你所选择的科学主题的奥秘和细微差别，并将帮助你开发一种强大的批判性和分析性思维能力，这对于任何成功的科学研究都至关重要。\n\n2. **接受正规教育和培训：**\n\n   接下来，你需要接受正规的科学教育和培训，这通常需要在学院或大学攻读科学相关的学位课程。根据您的具体兴趣和职业目标，您可以选择攻读一系列不同的科学专业方向，如生物学、化学、物理学、数学、天文学等等。在整个学习过程中，您将有机会接触广泛的科学理论和概念，并进行一系列严格的实验和技术训练，以便发展一套全面的技能和专业知识，以满足未来科学工作的需求。\n\n3. **参与科研实践：**\n\n   完成必要的科学教育和培训后，下一步就是开始从事实际的科学研究和实验活动。这可能涉及到加入一个由同行科学家组成的学术团体或研究中心，在那里您可以与其他研究人员一起开展前沿课题项目，并与业内其他专家建立宝贵的联系网络。或者，您也可以选择在一个更独立的条件下独立地设计和执行自己的科学研究和实验计划，例如通过申请个人资助，找到合适的研究设施，招募一支高效的团队成员队伍等方式来实现这一目标。无论是在团队还是在个体层面上，参与实际的科学研究和实验都是至关重要的，因为它可以让您充分展示您在该特定科学领域的专业知识和技能的深度和广度，并为推动科学技术的持续发展和创新做出贡献。\n\n4. **发表研究成果：**\n\n   一旦您完成了必要的研究工作和实验活动，并且在科学期刊上发表了您的研究成果，那么您就已经成功地将自己确立为了一名受人尊敬且有成就的科学家。在这个阶段，您已经对该特定的科学领域做出了重大贡献，并在该领域内建立了良好的声誉和信誉。此外，由于您的工作已经被公之于众，因此它将有可能激发未来几代科学家的灵感和创造力，从而进一步促进科学技术领域的不断进步与发展。'}, {'content': 'Summarize the chat content, the less the better', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:36718 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 21:58:23 async_llm_engine.py:436] Received request chatcmpl-7927b189-2274-40e2-96f4-5617d5b6aeee: prompt: '<s><|im_start|>system\nWe chatted before:\n**【正文开始】**\n\n# ***二. tf.keras API Overview and Common Features / Techiques Explanation Analysis Part Two : Advanced Extension Modules, Technics Deep Dive Study Tutorial Case Research Report*** \n\n本篇文章将继续讨论 TensorFlow 的相关主题，即关于 *tf.keras* API 的更高级别的功能和技巧的详细分析和解释。在这个部分，我们将更深入地探索有关基于深度学习的先进计算机视觉和自然语言处理应用程序的各种技术和策略的知识。此外，我们还将在本教程中使用多个实际示例进行演示，以帮助读者更好地理解和掌握这些复杂的技术和技能。\n\n---\n\n#  **1. tf.keras API Overview - Key Components Structure Explained in Detail with Visualization Examples for Better Understanding Intuition Acquisition Learning Process Improvement Optimization Enhancement Strategy Framework Development Implementation Execution Procedure Workflow Management Control Flow Guidance Direction Navigation Support System Application Construction Real World Problem Solution Resolution Achievement Goal Attainment Progress Performance Evaluation Measurement Comparison Assessment Quality Assurance Methodology Approach Algorithmic Processing Step-by-step Operation Procedural Specification Description Documentation Generation Preparation Output Presentation Display Representation Rendering Visualize Showcase Demonstrate Exhibit Publicly Present to Audience Share Knowledge Transfer Information Enlighten Teach Inspire Motivate Stir Up Emotionally Arouse Excite Make Thrill Amaze Surprise Delight Rejoice Gladdened Grateful Thankful Appreciative Mindfull Aware Cognizant Perceptive Inspect Scrutineze Investigative Analytical Critical Thinking Reason Logical Deductive Inference Abduction Induction Hypothesis Theory Law Rule Principle Maxim Dictum Canon Truism Folklore Wisdom Lore Myth Legend Anecdote Story Tale Saga Epic Poem Ballad Ode Song Lyric Hymn Prayer Religious Text Document Scroll Manuscript Codex Tablet Stone Carving Chisel Etched Engaved Crafted Fabricated Made Created Formulated Composed Compiled Assembled Put Together Set up Initiated Started Turn On Go Live Deploy Run Execute Implement Practice Use Play Experiment Try Out Test Validate Compare Contrast Measure Evaluate Judge Rate Score Rank Order Prioritize Select Choose Pick Determine Decide Figure out Get Understand Uncover Discover Learn Master Gain Proficiency Develop Cultivat Enhanc Improve Upgrade Elevati Optimi Optimi Perfecti Ideali Idealizzatio Purificatorio Transfigurazione Transformaci Transformatione TranscensionTransformational Evolutionary Ecosystemic Sustainable Eco-Friendly Friendly Environmentally Responsible Green Socially Conscious Ethically Morally Justifiably Defensible<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 1803, 653, 12280, 1719, 642, 465, 60781, 74460, 68301, 60783, 55098, 324, 17300, 60529, 281, 6564, 34770, 5492, 34817, 454, 7858, 19880, 740, 17517, 8435, 1519, 35849, 18474, 3819, 9173, 680, 21374, 26901, 43172, 328, 7151, 1357, 18334, 553, 664, 19333, 47364, 11692, 8451, 8391, 12363, 4872, 73993, 68786, 86710, 70069, 26474, 19033, 262, 74194, 69685, 60353, 60646, 68716, 484, 9068, 34770, 297, 5492, 262, 87905, 69105, 69616, 91918, 69150, 60354, 69030, 85072, 69478, 60355, 70156, 68340, 60353, 73776, 60526, 70354, 60415, 70675, 69045, 70513, 70907, 73032, 69592, 69444, 70906, 60381, 68519, 68790, 68500, 73451, 75202, 79491, 70430, 78100, 60355, 69636, 60353, 88128, 73030, 60434, 70277, 82892, 69626, 68763, 76885, 68274, 69580, 60353, 60367, 68417, 70736, 74399, 87702, 69373, 68374, 69701, 73379, 60381, 68594, 60355, 402, 43916, 324, 387, 465, 312, 281, 6564, 34770, 5492, 34817, 612, 5468, 34140, 28931, 18148, 2787, 435, 26210, 579, 20365, 2172, 25746, 500, 23770, 44954, 1479, 36967, 6536, 17343, 21119, 8737, 51744, 56572, 51619, 28118, 24116, 10963, 31034, 31141, 43994, 58859, 9684, 7918, 22736, 12310, 813, 19061, 18123, 9316, 872, 7470, 24407, 8939, 4497, 22347, 12629, 37018, 40840, 7967, 39709, 7851, 597, 609, 16164, 20855, 39081, 53254, 42106, 36201, 18071, 2850, 5922, 6880, 2603, 52157, 40074, 423, 28478, 14952, 14458, 29516, 16863, 1444, 2148, 4333, 50439, 7802, 44013, 23807, 5128, 35134, 9391, 50060, 10765, 3484, 13726, 13990, 418, 20365, 682, 7080, 5794, 32454, 626, 480, 39067, 406, 3231, 528, 27062, 442, 15189, 1984, 11924, 32094, 23532, 8217, 3090, 4303, 399, 2817, 742, 30180, 685, 19133, 864, 927, 534, 3303, 5901, 6108, 878, 493, 712, 456, 38704, 764, 7551, 29847, 614, 3466, 9968, 8214, 9806, 7459, 622, 1175, 7451, 689, 8412, 851, 6909, 2989, 21050, 9866, 1409, 1994, 2922, 52632, 23218, 9012, 53541, 487, 4091, 580, 649, 3777, 57075, 9861, 1127, 32291, 463, 613, 3150, 32241, 1534, 37315, 34676, 34679, 51403, 27176, 2999, 1076, 49618, 57584, 890, 2353, 3840, 23439, 2414, 2815, 38251, 268, 13329, 30672, 7649, 18247, 2492, 16125, 54481, 29437, 503, 37968, 1307, 275, 2295, 565, 22900, 20333, 55024, 52300, 45936, 27342, 1673, 37104, 1419, 15229, 53358, 60318, 39156, 13950, 467, 12987, 460, 637, 581, 19127, 16079, 2367, 603, 1747, 265, 53937, 51202, 3083, 11938, 22677, 2516, 486, 1374, 33750, 458, 56158, 14440, 3424, 4566, 1047, 416, 432, 19044, 2551, 3448, 4300, 24390, 422, 36248, 788, 18957, 4450, 3540, 7896, 1343, 4020, 13458, 2334, 1782, 26345, 10360, 31356, 2733, 837, 15822, 10165, 35775, 12151, 2063, 6148, 11309, 4306, 2139, 6608, 21059, 31280, 27389, 5602, 7203, 46219, 9870, 4532, 3556, 23613, 24131, 34288, 690, 34158, 53137, 20386, 19947, 18261, 19464, 7366, 31588, 26741, 8561, 22477, 19896, 30165, 3874, 708, 19192, 832, 2280, 9577, 2847, 1376, 3848, 33048, 15061, 10973, 48971, 8594, 10525, 7981, 26037, 475, 397, 28987, 1273, 22226, 717, 40452, 53564, 9437, 16690, 25261, 16690, 25261, 23571, 266, 13945, 8092, 47765, 8897, 6423, 14669, 1228, 36523, 4216, 1041, 455, 15138, 15349, 24868, 52697, 261, 4216, 271, 2806, 3332, 1775, 409, 37118, 789, 599, 23618, 423, 59159, 50043, 7423, 17927, 47757, 11740, 878, 32233, 1384, 7978, 9918, 528, 1345, 23449, 14495, 2835, 8581, 878, 4760, 13069, 3009, 4049, 36687, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:58:24 metrics.py:213] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 22.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:58:29 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 96.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:58:29 async_llm_engine.py:110] Finished request chatcmpl-7927b189-2274-40e2-96f4-5617d5b6aeee.
2024-03-28 21:58:38.444 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'We chatted before:\n---\n本篇文章将详细介绍 **Tensorflow 2.x 版本下的 Keras Model Subclassing** 模块中的所有重要细节、概念和技术：包括在构建神经网络模型时如何创建自定义的子类来继承父类的属性和方法；以及如何在 Python 代码中编写和实现这些定制化的子类对象的方法和功能；另外还包括如何使用这个新的模块来进行各种类型的应用场景下的任务，比如图像分类任务、目标检测任务、语义分割任务、序列预测任务、文本生成任务等等；同时还将介绍我们在使用该模块的过程中需要注意的一些重要的事项和问题，比如常见的错误', 'role': 'system'}, {'content': '他的历史功过如何评价？', 'role': 'user'}, {'role': 'assistant', 'content': '对弗里茨·哈伯的遗产进行公正评估是一项复杂且备受争议的任务。一方面，哈伯在化学工业方面的开创性工作和发现无疑为人类社会带来了巨大的利益和福祉。从改善全球食品生产、降低温室气体排放以应对气候变化问题以及推进各种先进材料的研发等领域来看，哈伯的技术突破确实为我们今天所享有的许多现代便利和安全条件奠定了基础。\n\n然而，另一方面，人们普遍认为哈伯与纳粹政权合作密切，并涉嫌卷入二战期间的大屠杀和其他战争罪行。尽管一些学者试图通过强调哈伯作为一位杰出国际科学家的声誉以及对和平利用核能发展的关键贡献等其他因素来淡化或洗白这些指控，但不可否认的是，围绕哈伯的历史形象和他对世界的影响仍然是一个有争议的话题，并且很可能在未来几年继续如此。'}, {'content': '你还知道哪些科学家？', 'role': 'user'}, {'role': 'assistant', 'content': '科学领域涌现出众多杰出的科学家，他们为我们理解自然世界的运作方式做出了巨大而深远的贡献。以下是一些著名的例子：\n\n**尼古拉·特斯拉（Nikola Tesla）**：塞尔维亚裔美国发明家、电气工程师、物理学家和美国公民，他被广泛认为是历史上最伟大的发明家和天才之一的地位。在他的整个职业生涯中，特斯拉为电力工程学、磁力学、无线电通信技术以及其他多个相关领域的进步和发展做出了无数开创性的重要贡献。其中一些最重要的工作包括交流电的发明、无线传输能量的概念、特斯拉线圈的设计以及用于雷达系统的感应加速器的发展等。\n\n**玛丽·居里（Marie Curie）**：波兰裔法国物理学家和化学家，她是第一个获得两次诺贝尔奖的人——1903年因“在铀射线发射及其特性方面的开创性研究”而荣获物理学奖；1911年因“放射性现象的研究”而荣获化学奖。她的工作重点是揭示辐射的特性，并通过使用放射性同位素的新方法为医学诊断和治疗开辟新的可能性。她最著名的贡献之一是确定了镭元素的存在，这在当时被认为是不可能的。\n\n以上是两位具有代表性的伟大科学家的简要介绍，他们在各自的学科中都留下了深刻的印记，并对我们当今生活的世界产生了持久而有影响力的积极影响。'}, {'content': '如何成为一个科学家？', 'role': 'user'}, {'role': 'assistant', 'content': '成为一名科学家需要结合天赋、努力工作和奉献精神，以及对学习和探索未知事物的深刻热情。这是一个多步骤的过程，涉及教育、培训和各种实践经验。下面是成为科学家的详细路线图：\n\n1. **培养好奇心和学习欲望：**\n\n   作为一名未来的科学家，第一步也是最关键的一步就是培养强烈的好奇心和学习欲。这意味着您应该始终保持开放的心态，乐于接受新想法和新观点，并对你的知识边界之外的世界充满好奇。这种好奇心和学习欲将激励你不断地深入探究你所选择的科学主题的奥秘和细微差别，并将帮助你开发一种强大的批判性和分析性思维能力，这对于任何成功的科学研究都至关重要。\n\n2. **接受正规教育和培训：**\n\n   接下来，你需要接受正规的科学教育和培训，这通常需要在学院或大学攻读科学相关的学位课程。根据您的具体兴趣和职业目标，您可以选择攻读一系列不同的科学专业方向，如生物学、化学、物理学、数学、天文学等等。在整个学习过程中，您将有机会接触广泛的科学理论和概念，并进行一系列严格的实验和技术训练，以便发展一套全面的技能和专业知识，以满足未来科学工作的需求。\n\n3. **参与科研实践：**\n\n   完成必要的科学教育和培训后，下一步就是开始从事实际的科学研究和实验活动。这可能涉及到加入一个由同行科学家组成的学术团体或研究中心，在那里您可以与其他研究人员一起开展前沿课题项目，并与业内其他专家建立宝贵的联系网络。或者，您也可以选择在一个更独立的条件下独立地设计和执行自己的科学研究和实验计划，例如通过申请个人资助，找到合适的研究设施，招募一支高效的团队成员队伍等方式来实现这一目标。无论是在团队还是在个体层面上，参与实际的科学研究和实验都是至关重要的，因为它可以让您充分展示您在该特定科学领域的专业知识和技能的深度和广度，并为推动科学技术的持续发展和创新做出贡献。\n\n4. **发表研究成果：**\n\n   一旦您完成了必要的研究工作和实验活动，并且在科学期刊上发表了您的研究成果，那么您就已经成功地将自己确立为了一名受人尊敬且有成就的科学家。在这个阶段，您已经对该特定的科学领域做出了重大贡献，并在该领域内建立了良好的声誉和信誉。此外，由于您的工作已经被公之于众，因此它将有可能激发未来几代科学家的灵感和创造力，从而进一步促进科学技术领域的不断进步与发展。'}, {'content': '科学家、工程师、技术人员的区别是什么？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 21:58:38 async_llm_engine.py:436] Received request chatcmpl-1c588fff-366d-4f6f-a33f-6bfed4b5edab: prompt: '<s><|im_start|>system\nWe chatted before:\n---\n本篇文章将详细介绍 **Tensorflow 2.x 版本下的 Keras Model Subclassing** 模块中的所有重要细节、概念和技术：包括在构建神经网络模型时如何创建自定义的子类来继承父类的属性和方法；以及如何在 Python 代码中编写和实现这些定制化的子类对象的方法和功能；另外还包括如何使用这个新的模块来进行各种类型的应用场景下的任务，比如图像分类任务、目标检测任务、语义分割任务、序列预测任务、文本生成任务等等；同时还将介绍我们在使用该模块的过程中需要注意的一些重要的事项和问题，比如常见的错误<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 1803, 653, 12280, 1719, 642, 11102, 73993, 68786, 60530, 78222, 3235, 25771, 5125, 262, 314, 2143, 262, 68602, 68728, 863, 9380, 5061, 3879, 1182, 418, 465, 262, 71055, 68322, 68379, 68372, 69873, 60359, 69662, 80613, 60387, 68469, 60361, 72962, 69829, 68441, 70218, 60377, 68343, 69012, 71044, 60354, 60401, 60647, 60383, 72108, 61050, 69091, 69098, 80460, 60506, 68375, 74739, 13175, 262, 69681, 60366, 71976, 60381, 68651, 68374, 71322, 69230, 60401, 60647, 69115, 68744, 60381, 68344, 60506, 68721, 86766, 76664, 68262, 68641, 71055, 73025, 68459, 71761, 68481, 69928, 68728, 68565, 60353, 68522, 70439, 69412, 68565, 60359, 68689, 69268, 68565, 60359, 60752, 60954, 71862, 68565, 60359, 73437, 72308, 68565, 60359, 69684, 70563, 68565, 68811, 60506, 68405, 79570, 68387, 78118, 60658, 71055, 70922, 71724, 69961, 69034, 68328, 60381, 68287, 60353, 68522, 70929, 69583, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:58:38 metrics.py:213] Avg prompt throughput: 16.2 tokens/s, Avg generation throughput: 3.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 21:58:43 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 97.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:58:43 async_llm_engine.py:110] Finished request chatcmpl-1c588fff-366d-4f6f-a33f-6bfed4b5edab.
2024-03-28 21:59:40.506 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': 'We chatted before:\n---\n本篇文章将详细介绍 **Tensorflow 2.x 版本下的 Keras Model Subclassing** 模块中的所有重要细节、概念和技术：包括在构建神经网络模型时如何创建自定义的子类来继承父类的属性和方法；以及如何在 Python 代码中编写和实现这些定制化的子类对象的方法和功能；另外还包括如何使用这个新的模块来进行各种类型的应用场景下的任务，比如图像分类任务、目标检测任务、语义分割任务、序列预测任务、文本生成任务等等；同时还将介绍我们在使用该模块的过程中需要注意的一些重要的事项和问题，比如常见的错误类型及其解决方法等；最后还将会通过一些实际的案例研究和实践操作演练的方式来进一步巩固和加深读者对该模块的理解和学习效果。通过这样的方式，我们可以让读者更加深入地了解 TensorFlow 框架下各个组件的功能和使用方式，从而为后续的学习和发展打下坚实的基础。 \n##   一、概述\n###    1.1 引言\n本篇技术文档旨在探讨 TensorFlow 框架中的一个非常重要的组成部分——Keras Model Subclasses（`Keras Model Sub-Classess`）模块。具体来说，本篇文档将全面系统性地分析讲解 TensorFlow-Keras 框架下的一个非常重要的高级特性，即将现有的预训练好的 Keras 层集成到用户自己的自定义开发的网络结构当中，并利用全新的 `Model Sub-classs` 机制来实现对现有模型的可扩展性和灵活性的增强和改进。本篇文档将从以下三个方面出发，分别阐述了 `Keras Model Sublassss/Classes` 模块的核心内容和关键设计思想：首先是对整个模块的基本概念、原理和术语进行了初步的定义和说明，以便读者能够更好地理解接下来将要介绍的更多具体的技术细节和技术要点等内容；其次是通过大量的实例分析和实践演练的方式，生动形象地展示了如何将现成的 Keras Layer 对象无缝集成到一个新创建的具有高度可定制性和适应性等特点的新型 Keras Model 架构之中，并通过这种方式有效地实现了对于传统 Keras Model 架构而言所固有的某些局限性和不足之处的有效改善和提升。在此基础上，我们继续探究了这个模块的其他一系列更为细致入微的细节和技术点内容。比如，在完成了最初的模型结构和算法设计的搭建之后，我们需要考虑如何进行有效的超参数调整优化工作，以保证最终训练出来的 Keras Model 能够在真实的应用场景下取得更好的性能表现和鲁棒性特点；又比如，在进行大规模的数据集上的模型训练工作时，除了需要关注模型的准确率和收敛速度之外，还需要', 'role': 'system'}, {'content': '科学家、工程师、技术人员的区别是什么？', 'role': 'user'}, {'role': 'assistant', 'content': '您好！很高兴为您提供帮助。关于 TensorFlow 2.0 版下基于 Keras API 实现的 Model Subclassing（模型子类化）模块的所有相关信息，我将按照您的要求一一给出详细的解答。\n\n首先，我们先来看一下什么是 TensorFlow 2.0 版下基于 Keras API 实现的 Model Subclassing（模型子类化）模块？它有哪些主要功能和优势呢？请看下文：\n\n##  一、TensorFlow 2.0 版下基于 Keras API 实现的 Model Subclassing（模型子类化）模块简介及概述\n\n### a) TensorFlow 官方文档链接：[https://www.tensorflow.org/guide/keras_subclassing](https://www.tensorflow.org/guide/keras_subclassing)]\n\n### b) TensorFlow 2.0 版下基于 Keras API 实现的 Model Subclassing（模型子类化）模块的主要内容包括以下几个方面：\n\n1\\) Model Subclasses Inheritance Hierarchy：用于描述通过继承关系建立的模型子类的层次结构。具体来说，它是用来表示如何将一个给定的基类 `BaseModel` 通过一系列子类 `SubClassA`, `SubClassB...` 进行扩展的特性或关系的图形化表达方式，其中每个节点代表一个特定的类及其定义的属性和方法，而两个节点之间的箭头则表示它们之间存在一种称为“继承”的关系。也就是说，当创建一个新的子类对象的时候，那么它会自动地从它的父类那里继承所有的基本属性和方法，然后根据实际需求对这些继承而来的方法和属性进行适当的修改、重载或者删除操作，从而使得最终得到的这个新创建的子类对象的特性与行为能够更加符合我们的预期设计方案。\n\n对于这种特殊的子类继承层次结构的可视化图形表现形式而言，通常采用的就是 UML（Unified Modelling Language，统一建模语言）标准规范规定的 Class Diagrams（类图）的方式来呈现和展示出来。简单来说，就是在一张纸上面画出一个看起来像是一个矩形形状的框架结构体，然后在这个矩形形状的框架里面再填充上一些其他的矩形形状的小盒子框，而这些小盒子里面又分别代表着不同的具体的类名，也就是我们之前提到的那个具有复杂子类继承关系的模型的完整数据集的全部成员变量集合。这样一来，我们就可以非常直观形象地看到这个由多个不同大小形状的矩形盒子和里面的文字标签组成的大型矩形框架结构体的整体架构面貌了。当然，除了以这种方式展现之外，'}, {'content': 'Summarize the chat content, the less the better', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:40352 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 21:59:40 async_llm_engine.py:436] Received request chatcmpl-40bf97a9-98d4-4b8c-8947-ebbdc5bb1f2d: prompt: '<s><|im_start|>system\nWe chatted before:\n---\n本篇文章将详细介绍 **Tensorflow 2.x 版本下的 Keras Model Subclassing** 模块中的所有重要细节、概念和技术：包括在构建神经网络模型时如何创建自定义的子类来继承父类的属性和方法；以及如何在 Python 代码中编写和实现这些定制化的子类对象的方法和功能；另外还包括如何使用这个新的模块来进行各种类型的应用场景下的任务，比如图像分类任务、目标检测任务、语义分割任务、序列预测任务、文本生成任务等等；同时还将介绍我们在使用该模块的过程中需要注意的一些重要的事项和问题，比如常见的错误类型及其解决方法等；最后还将会通过一些实际的案例研究和实践操作演练的方式来进一步巩固和加深读者对该模块的理解和学习效果。通过这样的方式，我们可以让读者更加深入地了解 TensorFlow 框架下各个组件的功能和使用方式，从而为后续的学习和发展打下坚实的基础。 \n##   一、概述\n###    1.1 引言\n本篇技术文档旨在探讨 TensorFlow 框架中的一个非常重要的组成部分——Keras Model Subclasses（`Keras Model Sub-Classess`）模块。具体来说，本篇文档将全面系统性地分析讲解 TensorFlow-Keras 框架下的一个非常重要的高级特性，即将现有的预训练好的 Keras 层集成到用户自己的自定义开发的网络结构当中，并利用全新的 `Model Sub-classs` 机制来实现对现有模型的可扩展性和灵活性的增强和改进。本篇文档将从以下三个方面出发，分别阐述了 `Keras Model Sublassss/Classes` 模块的核心内容和关键设计思想：首先是对整个模块的基本概念、原理和术语进行了初步的定义和说明，以便读者能够更好地理解接下来将要介绍的更多具体的技术细节和技术要点等内容；其次是通过大量的实例分析和实践演练的方式，生动形象地展示了如何将现成的 Keras Layer 对象无缝集成到一个新创建的具有高度可定制性和适应性等特点的新型 Keras Model 架构之中，并通过这种方式有效地实现了对于传统 Keras Model 架构而言所固有的某些局限性和不足之处的有效改善和提升。在此基础上，我们继续探究了这个模块的其他一系列更为细致入微的细节和技术点内容。比如，在完成了最初的模型结构和算法设计的搭建之后，我们需要考虑如何进行有效的超参数调整优化工作，以保证最终训练出来的 Keras Model 能够在真实的应用场景下取得更好的性能表现和鲁棒性特点；又比如，在进行大规模的数据集上的模型训练工作时，除了需要关注模型的准确率和收敛速度之外，还需要<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 1803, 653, 12280, 1719, 642, 11102, 73993, 68786, 60530, 78222, 3235, 25771, 5125, 262, 314, 2143, 262, 68602, 68728, 863, 9380, 5061, 3879, 1182, 418, 465, 262, 71055, 68322, 68379, 68372, 69873, 60359, 69662, 80613, 60387, 68469, 60361, 72962, 69829, 68441, 70218, 60377, 68343, 69012, 71044, 60354, 60401, 60647, 60383, 72108, 61050, 69091, 69098, 80460, 60506, 68375, 74739, 13175, 262, 69681, 60366, 71976, 60381, 68651, 68374, 71322, 69230, 60401, 60647, 69115, 68744, 60381, 68344, 60506, 68721, 86766, 76664, 68262, 68641, 71055, 73025, 68459, 71761, 68481, 69928, 68728, 68565, 60353, 68522, 70439, 69412, 68565, 60359, 68689, 69268, 68565, 60359, 60752, 60954, 71862, 68565, 60359, 73437, 72308, 68565, 60359, 69684, 70563, 68565, 68811, 60506, 68405, 79570, 68387, 78118, 60658, 71055, 70922, 71724, 69961, 69034, 68328, 60381, 68287, 60353, 68522, 70929, 69583, 68517, 69975, 76080, 60455, 60506, 68337, 60430, 70827, 68330, 68315, 86244, 70533, 84490, 69804, 68348, 86824, 89014, 69806, 77290, 60381, 77225, 70736, 83929, 71055, 84983, 82393, 68408, 60355, 68330, 68646, 68386, 60353, 68931, 60585, 70736, 68708, 70354, 60415, 68505, 26474, 19033, 262, 72282, 60380, 70098, 74392, 70765, 82154, 68386, 60353, 69172, 60374, 72068, 73238, 78637, 89257, 86647, 70524, 60355, 848, 696, 393, 60356, 60359, 72222, 364, 14511, 388, 312, 281, 312, 262, 60949, 60923, 364, 73993, 68362, 69027, 75608, 73286, 26474, 19033, 262, 72282, 82245, 84850, 79579, 92395, 331, 9380, 5061, 3879, 8990, 60414, 350, 331, 9380, 5061, 3879, 285, 2108, 564, 350, 60413, 71055, 60355, 68592, 68484, 60353, 73993, 69027, 60530, 69386, 68308, 81509, 68578, 70749, 26474, 19033, 15974, 9380, 262, 72282, 71938, 84850, 69105, 70534, 60353, 71277, 74057, 61030, 69233, 68292, 863, 9380, 262, 60956, 71517, 60378, 68508, 68304, 71044, 68640, 70291, 68707, 70314, 60353, 60573, 68685, 73872, 1711, 1862, 3879, 14930, 269, 350, 262, 70778, 78422, 60409, 71598, 86427, 60369, 70934, 71222, 71375, 68739, 69857, 60381, 73535, 60355, 73993, 69027, 60530, 60577, 68544, 68824, 68503, 71321, 60353, 68944, 77084, 60362, 1711, 331, 9380, 5061, 3879, 578, 911, 301, 20252, 350, 262, 71055, 75844, 87438, 68802, 68363, 69149, 60387, 68400, 71118, 68898, 71055, 71119, 69662, 60359, 70433, 60381, 77660, 70550, 74564, 87554, 60381, 68789, 60353, 72816, 70736, 68445, 74399, 68865, 68929, 81871, 86011, 68507, 72702, 68362, 69873, 80613, 73600, 82721, 60506, 70374, 76288, 70618, 73748, 85072, 69804, 86824, 69405, 60353, 76046, 69669, 60415, 83637, 84311, 60438, 69837, 863, 9380, 23039, 262, 69115, 83752, 71517, 75550, 60473, 85375, 68537, 68933, 60369, 71322, 71222, 70188, 60489, 87852, 69328, 60653, 863, 9380, 5061, 262, 75075, 70286, 60353, 83707, 81858, 76742, 74114, 68390, 68876, 863, 9380, 5061, 262, 75075, 69820, 60431, 61340, 68608, 70128, 79918, 71222, 90457, 85688, 69715, 60381, 68726, 60355, 69890, 75094, 60353, 68253, 68528, 85835, 78242, 71055, 76629, 72609, 72029, 75839, 60411, 60804, 88068, 80613, 60390, 68341, 60355, 68522, 60353, 60361, 70181, 81763, 70218, 89912, 73060, 73070, 73982, 68307, 60353, 70092, 68880, 89287, 70972, 60922, 68852, 68660, 70386, 68273, 60353, 91077, 68985, 69233, 69141, 863, 9380, 5061, 262, 79712, 69382, 72696, 69928, 60380, 69292, 69827, 69165, 68794, 60381, 61701, 61963, 60489, 69063, 60506, 60676, 68522, 60353, 79578, 78601, 71212, 60853, 68365, 70218, 69233, 90880, 60353, 68632, 68266, 68588, 86427, 70378, 89270, 83292, 68837, 69649, 60353, 71946, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 21:59:40 metrics.py:213] Avg prompt throughput: 9.5 tokens/s, Avg generation throughput: 0.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:59:45 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 93.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 21:59:46 async_llm_engine.py:110] Finished request chatcmpl-40bf97a9-98d4-4b8c-8947-ebbdc5bb1f2d.
2024-03-28 22:16:26.791 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\n【篇一：美丽的家乡作文】\n\n我的家乡在山东省青岛市胶州市，那里四季分明、风景秀丽。我爱我的家乡！\n\n春天万物复苏，百花齐放。公园里的桃花开了，红的似火；迎春花也开了，黄的如金子般灿烂；樱花也不甘示弱，粉得像一片云霞……我家楼下的大榆树长出了嫩绿的叶子，远远望去就像一把把绿色的小扇子。每当夜幕降临，路灯亮了起来，高大挺拔的柳树上挂满了五颜六色的彩灯，五彩缤纷，美丽极了！\n\n夏天烈日炎炎，骄阳似火。池塘里荷花盛开，荷叶挨挨挤挤的，有的已经结出莲蓬了，蜻蜓立在尖上，好像要展翅高飞似的。我们小孩子最喜欢游泳了，一到晚上，小区内的露天游泳池人山人海，热闹非凡。大家在水中嬉戏玩耍，真是快乐无比啊！\n\n秋天瓜果飘香，硕果累累。果园里的苹果红彤彤的，葡萄紫盈盈的，石榴咧嘴笑了，柿子你挤我碰地挂着灯笼一样，好看得很呢！田野里稻谷笑弯了腰，金黄的玉米棒子漂亮极了！农民伯伯们脸上都洋溢着丰收的喜悦。\n\n冬天白雪皑皑，银装素裹。雪花给大地铺上了厚厚的雪毯，像是冬爷爷送给我们的礼物。孩子们堆起了雪人，打起了雪仗，玩得可开心啦！\n\n这就是一年四季四季分明、风景秀丽的家乡——青岛胶州！我爱我的家乡！\n\n【篇二：美丽的家乡作文】\n\n我的家乡在美丽的海滨城市——大连，这里有山有水，还有许多名胜古迹。我最喜欢的就是那迷人的景色和美食了。\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一个个调皮的孩子，探出头来好奇地看着外面的世界；杏花穿着粉红色的衣裙，显得格外妖娆；梨花开得更美了，白中带着粉红的花瓣随风起舞，散发出淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树抽出新的枝条，长出嫩绿的叶子，犹如小姑娘羞涩的脸庞。燕子也从南方赶来了，叽叽喳喳地叫个不停，仿佛在欢迎春天的到来。\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这就是我的家乡，一个风景优美的地方，你们喜欢吗？', 'role': 'system'}, {'content': '核磁共振氢谱的卫星峰是什么', 'role': 'user'}, {'role': 'assistant', 'content': '在质子核磁共振光谱（proton nuclear magnetic resonance spectroscopy）或简称为核磁共振光谱学(NMR)实验中观察到的卫星峰是由于分子内旋转引起的多重性而产生的。\n\n首先解释一下 NMR 背后的基本原理：原子核中的质子在磁场中被极化，这意味着它们的自旋轴倾向于沿磁场的方向排列。然而，由于量子力学不确定性原理，这种取向不是完美的，而是以某种方式偏离这种完美对齐的状态。该不完美程度被称为“进动角”θ，它给出了关于样品中特定原子核数量的信息。然后，将一束射频辐射照射到样品上，使这些核跃迁到一个更高的能级。吸收的光子的频率取决于磁矩的量子数 m，以及外部施加的磁场强度 B0. 对于具有整数m值的每个单独的 transitions，响应为δνH，给出特征吸收信号。\n\n多重性是指特定原子核周围的化学环境影响着它的弛豫时间τr，进而影响了其在NMR光谱中的可见度。具体来说，如果在分子的π键附近有一个氢原子的轨道杂化形式发生变化时，就会发生多重性，这反过来又改变了相关氢原子核所受的外部磁场的大小。例如，考虑甲醇的结构式CH3-O-H。在该结构中，O 上的氢有两个可能的构象——顺式和平行。这两种情况下的等效场 **B**eff 有所不同，因为邻近氧的孤对电子云屏蔽了背景磁场的效果。因此，这两个氢原子核受到的磁场大小并不相同。结果，它们的预cessional frequencies differs slightly due to the difference in effective field strength.\n\n总之，在NMR光谱中出现卫星峰表明分子内的立体异构体或对称元素的存在，导致了氢原子核受到的不同程度的屏蔽，从而导致吸收峰略有偏移。'}, {'content': '在核磁共振氢谱中，峰的两侧常常会出现很小的峰，请问为什么', 'role': 'user'}, {'role': 'assistant', 'content': '【篇三：美丽的家乡作文】\n\n我的家乡在广东肇庆市鼎湖区广利镇的一个小村庄里，这里风景秀丽，物产丰富，是一个名副其实的好地方。\n\n春天，树木抽出新芽，鲜花绽放笑脸。小鸟欢快地在枝头歌唱，蜜蜂嗡嗡地采蜜，蝴蝶在花丛中翩翩起舞。油菜花、桃花、梨花等各种各样的花朵竞相开放，姹紫嫣红，争妍斗艳。站在山顶上眺望远方，一大片绿色的田野映入眼帘，到处都是一片生机勃勃的样子。\n\n夏天，天气炎热，蝉鸣声此起彼伏。清晨，一轮红日在东边冉冉升起，照耀着大地。中午时分，太阳炙烤着大地，热得连小狗都不敢出门散步了。傍晚时分，夕阳西沉，瑰'}, {'content': '请问高锰酸钾的摩尔吸光系数是多少', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:57350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:16:26 async_llm_engine.py:436] Received request chatcmpl-b97da588-77cd-4c18-ac1b-c307b42a3c67: prompt: '<s><|im_start|>system\n我们之前聊了：\n【篇一：美丽的家乡作文】\n\n我的家乡在山东省青岛市胶州市，那里四季分明、风景秀丽。我爱我的家乡！\n\n春天万物复苏，百花齐放。公园里的桃花开了，红的似火；迎春花也开了，黄的如金子般灿烂；樱花也不甘示弱，粉得像一片云霞……我家楼下的大榆树长出了嫩绿的叶子，远远望去就像一把把绿色的小扇子。每当夜幕降临，路灯亮了起来，高大挺拔的柳树上挂满了五颜六色的彩灯，五彩缤纷，美丽极了！\n\n夏天烈日炎炎，骄阳似火。池塘里荷花盛开，荷叶挨挨挤挤的，有的已经结出莲蓬了，蜻蜓立在尖上，好像要展翅高飞似的。我们小孩子最喜欢游泳了，一到晚上，小区内的露天游泳池人山人海，热闹非凡。大家在水中嬉戏玩耍，真是快乐无比啊！\n\n秋天瓜果飘香，硕果累累。果园里的苹果红彤彤的，葡萄紫盈盈的，石榴咧嘴笑了，柿子你挤我碰地挂着灯笼一样，好看得很呢！田野里稻谷笑弯了腰，金黄的玉米棒子漂亮极了！农民伯伯们脸上都洋溢着丰收的喜悦。\n\n冬天白雪皑皑，银装素裹。雪花给大地铺上了厚厚的雪毯，像是冬爷爷送给我们的礼物。孩子们堆起了雪人，打起了雪仗，玩得可开心啦！\n\n这就是一年四季四季分明、风景秀丽的家乡——青岛胶州！我爱我的家乡！\n\n【篇二：美丽的家乡作文】\n\n我的家乡在美丽的海滨城市——大连，这里有山有水，还有许多名胜古迹。我最喜欢的就是那迷人的景色和美食了。\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一个个调皮的孩子，探出头来好奇地看着外面的世界；杏花穿着粉红色的衣裙，显得格外妖娆；梨花开得更美了，白中带着粉红的花瓣随风起舞，散发出淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树抽出新的枝条，长出嫩绿的叶子，犹如小姑娘羞涩的脸庞。燕子也从南方赶来了，叽叽喳喳地叫个不停，仿佛在欢迎春天的到来。\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这就是我的家乡，一个风景优美的地方，你们喜欢吗？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 60781, 61306, 60356, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 71663, 85307, 61621, 69318, 60353, 69942, 73400, 78799, 60359, 70400, 91759, 60355, 77603, 68306, 73954, 60477, 402, 73047, 76278, 84247, 60353, 84500, 61572, 60524, 60355, 69608, 68664, 74664, 70653, 60353, 77865, 61267, 60790, 60506, 61515, 61167, 60629, 60395, 70653, 60353, 60870, 60354, 60407, 60611, 60401, 60980, 78944, 60506, 79898, 68430, 61772, 60602, 61648, 60353, 60846, 60428, 60770, 70882, 61120, 63118, 92396, 70664, 76109, 68552, 63929, 61357, 60485, 68758, 62239, 91221, 72281, 60353, 73614, 60866, 60461, 69281, 71282, 60581, 69391, 68447, 62433, 60401, 60355, 78599, 61207, 61406, 82865, 60353, 82646, 61224, 77784, 60353, 79634, 61525, 61607, 60354, 62380, 85264, 61680, 75117, 60735, 61166, 60999, 68738, 61263, 61360, 60353, 88064, 88528, 60353, 69732, 80600, 60477, 402, 69876, 61657, 60464, 61576, 61576, 60353, 63273, 60991, 61267, 60790, 60355, 86000, 60425, 83918, 61600, 60405, 60353, 83072, 62802, 62802, 62284, 62284, 60354, 60353, 68608, 68329, 60599, 60389, 62212, 63036, 60362, 60353, 65095, 65080, 60680, 60361, 61867, 60370, 60353, 69123, 60371, 60688, 62397, 60436, 61217, 74613, 60355, 68253, 74000, 78802, 70965, 60362, 60353, 76411, 68742, 60353, 70429, 69336, 84050, 80137, 60364, 84511, 60622, 60353, 75116, 83502, 60355, 77464, 70904, 64650, 60809, 76633, 60353, 69695, 69162, 73850, 60973, 60477, 402, 76665, 61421, 60457, 62574, 60765, 60353, 62111, 60457, 61492, 61492, 60355, 89124, 68664, 68963, 60776, 64189, 64189, 60354, 60353, 69524, 61708, 62506, 62506, 60354, 60353, 79844, 64010, 61693, 76995, 60353, 82281, 60403, 62284, 60363, 61982, 60415, 89741, 82111, 68392, 60353, 69286, 72967, 60827, 60477, 61329, 61411, 60425, 62761, 61696, 61188, 62251, 60362, 61950, 60353, 72932, 60354, 69502, 61963, 60401, 69385, 80600, 60477, 70294, 61614, 61614, 60400, 71562, 60406, 61430, 63084, 60486, 88982, 60354, 79725, 60355, 402, 70564, 89114, 66138, 66138, 60353, 61161, 60634, 60881, 62595, 60355, 79454, 60562, 74811, 61625, 69028, 92223, 61482, 63521, 60353, 73155, 61479, 70607, 77025, 68582, 70240, 60355, 73236, 62073, 71702, 61482, 60364, 60353, 60471, 71702, 61482, 63412, 60353, 92330, 60369, 69166, 61452, 60477, 402, 69853, 90180, 73400, 78799, 60359, 70400, 61261, 75266, 73954, 92395, 71738, 61621, 60745, 60477, 77603, 68306, 73954, 60477, 402, 60781, 61306, 60529, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 69732, 72198, 62498, 68494, 92395, 74158, 60353, 82894, 60631, 60360, 60456, 60353, 91535, 82616, 84395, 60355, 74596, 68986, 68259, 60462, 88508, 77785, 60381, 69613, 60362, 60355, 402, 73047, 60353, 76278, 84247, 60353, 72536, 84159, 90056, 60355, 69608, 68664, 91470, 61236, 61112, 61399, 62515, 60353, 68959, 60576, 60358, 64099, 60521, 60387, 61515, 61167, 60629, 60770, 74451, 86772, 71527, 60353, 61578, 85357, 60383, 73718, 60415, 69082, 78642, 68339, 60506, 62775, 60629, 71294, 60846, 74789, 79093, 60353, 70213, 78894, 62475, 65832, 60506, 62696, 79204, 82040, 60528, 60362, 60353, 60624, 60366, 69609, 90410, 71832, 62127, 91319, 60480, 61609, 60353, 61331, 71611, 78995, 78899, 60353, 63919, 73105, 62204, 60353, 70338, 62245, 62455, 60355, 60398, 61190, 60577, 82256, 60425, 62285, 83320, 60353, 62239, 85004, 60359, 61290, 91221, 60353, 60770, 70516, 61006, 62804, 61341, 82218, 71087, 70849, 60355, 86738, 85188, 68641, 81566, 60353, 87346, 62239, 91221, 72281, 60353, 79490, 81902, 62907, 63284, 78811, 63227, 60355, 88310, 60395, 60577, 71672, 61855, 68830, 60353, 64764, 64764, 65602, 65602, 60415, 61221, 60365, 71080, 60353, 72218, 60361, 69069, 61167, 70091, 73623, 60355, 402, 69876, 60353, 61657, 60464, 61576, 61576, 60353, 63273, 60991, 61267, 60790, 60355, 76931, 61126, 63277, 64888, 63015, 60353, 78454, 70723, 68867, 70005, 80995, 64650, 60809, 76633, 60353, 68608, 60361, 63128, 84026, 60353, 68608, 60361, 84355, 60353, 68350, 80216, 60835, 87655, 28501, 75137, 60804, 76872, 60417, 60353, 78508, 70405, 90612, 79464, 61342, 63663, 60353, 69871, 80600, 60477, 86738, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 74122, 87510, 61405, 60364, 60353, 74922, 83024, 72695, 61873, 60380, 65351, 61626, 77795, 60353, 73322, 64685, 60994, 60486, 68948, 60353, 67281, 67281, 60762, 60361, 83526, 60425, 60419, 60538, 60362, 60353, 60538, 60362, 60420, 60415, 73517, 60353, 70200, 60361, 60423, 60387, 60419, 60591, 69072, 71510, 74122, 61942, 60477, 60420, 402, 76665, 60353, 75224, 61492, 61492, 60353, 61421, 60457, 62574, 60765, 60355, 88436, 82060, 72281, 60650, 60870, 60362, 60353, 72744, 61895, 61895, 61036, 68462, 60353, 60770, 70334, 60539, 72945, 64442, 64442, 60480, 61609, 60506, 63598, 61193, 86600, 60353, 73614, 60866, 60461, 60353, 60770, 90566, 60917, 73377, 74230, 76655, 60355, 61329, 61411, 68664, 61617, 65252, 69571, 60362, 60353, 70294, 61614, 61614, 71562, 75422, 75488, 75715, 60353, 68310, 69610, 81910, 61617, 65252, 60353, 69610, 61491, 60486, 61048, 60762, 60353, 60580, 60546, 69909, 71783, 60362, 60477, 402, 70564, 60353, 89114, 66138, 66138, 60353, 61161, 60634, 60881, 62595, 60355, 62819, 61101, 60368, 61482, 61560, 60429, 61217, 61609, 60353, 79119, 79329, 60370, 60359, 82302, 60370, 60359, 60412, 68351, 76532, 60370, 60353, 68898, 68339, 72330, 89114, 70526, 71721, 60355, 69972, 73314, 68318, 62073, 61482, 60364, 60359, 60471, 61482, 63412, 60353, 92330, 60369, 69166, 60362, 60353, 69125, 69367, 83933, 89795, 60693, 61113, 61113, 87078, 60415, 79780, 60355, 402, 69853, 68306, 73954, 60353, 68252, 70400, 76656, 68704, 60353, 68593, 68299, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:16:26 metrics.py:213] Avg prompt throughput: 0.8 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:16:31 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 96.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:16:32 async_llm_engine.py:110] Finished request chatcmpl-b97da588-77cd-4c18-ac1b-c307b42a3c67.
2024-03-28 22:16:35.406 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\n【篇一：美丽的家乡作文】\n\n我的家乡在山东省青岛市胶州市，那里四季分明、风景秀丽。我爱我的家乡！\n\n春天万物复苏，百花齐放。公园里的桃花开了，红的似火；迎春花也开了，黄的如金子般灿烂；樱花也不甘示弱，粉得像一片云霞……我家楼下的大榆树长出了嫩绿的叶子，远远望去就像一把把绿色的小扇子。每当夜幕降临，路灯亮了起来，高大挺拔的柳树上挂满了五颜六色的彩灯，五彩缤纷，美丽极了！\n\n夏天烈日炎炎，骄阳似火。池塘里荷花盛开，荷叶挨挨挤挤的，有的已经结出莲蓬了，蜻蜓立在尖上，好像要展翅高飞似的。我们小孩子最喜欢游泳了，一到晚上，小区内的露天游泳池人山人海，热闹非凡。大家在水中嬉戏玩耍，真是快乐无比啊！\n\n秋天瓜果飘香，硕果累累。果园里的苹果红彤彤的，葡萄紫盈盈的，石榴咧嘴笑了，柿子你挤我碰地挂着灯笼一样，好看得很呢！田野里稻谷笑弯了腰，金黄的玉米棒子漂亮极了！农民伯伯们脸上都洋溢着丰收的喜悦。\n\n冬天白雪皑皑，银装素裹。雪花给大地铺上了厚厚的雪毯，像是冬爷爷送给我们的礼物。孩子们堆起了雪人，打起了雪仗，玩得可开心啦！\n\n这就是一年四季四季分明、风景秀丽的家乡——青岛胶州！我爱我的家乡！\n\n【篇二：美丽的家乡作文】\n\n我的家乡在美丽的海滨城市——大连，这里有山有水，还有许多名胜古迹。我最喜欢的就是那迷人的景色和美食了。\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一个个调皮的孩子，探出头来好奇地看着外面的世界；杏花穿着粉红色的衣裙，显得格外妖娆；梨花开得更美了，白中带着粉红的花瓣随风起舞，散发出淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树抽出新的枝条，长出嫩绿的叶子，犹如小姑娘羞涩的脸庞。燕子也从南方赶来了，叽叽喳喳地叫个不停，仿佛在欢迎春天的到来。\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这就是我的家乡，一个风景优美的地方，你们喜欢吗？', 'role': 'system'}, {'content': '核磁共振氢谱的卫星峰是什么', 'role': 'user'}, {'role': 'assistant', 'content': '在质子核磁共振光谱（proton nuclear magnetic resonance spectroscopy）或简称为核磁共振光谱学(NMR)实验中观察到的卫星峰是由于分子内旋转引起的多重性而产生的。\n\n首先解释一下 NMR 背后的基本原理：原子核中的质子在磁场中被极化，这意味着它们的自旋轴倾向于沿磁场的方向排列。然而，由于量子力学不确定性原理，这种取向不是完美的，而是以某种方式偏离这种完美对齐的状态。该不完美程度被称为“进动角”θ，它给出了关于样品中特定原子核数量的信息。然后，将一束射频辐射照射到样品上，使这些核跃迁到一个更高的能级。吸收的光子的频率取决于磁矩的量子数 m，以及外部施加的磁场强度 B0. 对于具有整数m值的每个单独的 transitions，响应为δνH，给出特征吸收信号。\n\n多重性是指特定原子核周围的化学环境影响着它的弛豫时间τr，进而影响了其在NMR光谱中的可见度。具体来说，如果在分子的π键附近有一个氢原子的轨道杂化形式发生变化时，就会发生多重性，这反过来又改变了相关氢原子核所受的外部磁场的大小。例如，考虑甲醇的结构式CH3-O-H。在该结构中，O 上的氢有两个可能的构象——顺式和平行。这两种情况下的等效场 **B**eff 有所不同，因为邻近氧的孤对电子云屏蔽了背景磁场的效果。因此，这两个氢原子核受到的磁场大小并不相同。结果，它们的预cessional frequencies differs slightly due to the difference in effective field strength.\n\n总之，在NMR光谱中出现卫星峰表明分子内的立体异构体或对称元素的存在，导致了氢原子核受到的不同程度的屏蔽，从而导致吸收峰略有偏移。'}, {'content': '在核磁共振氢谱中，峰的两侧常常会出现很小的峰，请问为什么', 'role': 'user'}, {'role': 'assistant', 'content': '【篇三：美丽的家乡作文】\n\n我的家乡在广东肇庆市鼎湖区广利镇的一个小村庄里，这里风景秀丽，物产丰富，是一个名副其实的好地方。\n\n春天，树木抽出新芽，鲜花绽放笑脸。小鸟欢快地在枝头歌唱，蜜蜂嗡嗡地采蜜，蝴蝶在花丛中翩翩起舞。油菜花、桃花、梨花等各种各样的花朵竞相开放，姹紫嫣红，争妍斗艳。站在山顶上眺望远方，一大片绿色的田野映入眼帘，到处都是一片生机勃勃的样子。\n\n夏天，天气炎热，蝉鸣声此起彼伏。清晨，一轮红日在东边冉冉升起，照耀着大地。中午时分，太阳炙烤着大地，热得连小狗都不敢出门散步了。傍晚时分，夕阳西沉，瑰'}, {'content': '请问高锰酸钾的摩尔吸光系数是多少', 'role': 'user'}, {'role': 'assistant', 'content': '【篇三：美丽的家乡作文】\n\n我的家乡在四川省眉山市东坡区，这是一个美丽富饶的城市，也是我国著名的历史文化名城之一。在这座历史悠久的城市里，有许多闻名遐迩的名胜古迹和特色美食，这些都是这座城市的独特魅力所在。下面就让我们一起来领略一下这座美丽富饶的历史文化名城的独特魅力吧！\n\n春天，百花齐放，万木吐翠，到处生机勃勃，充满了无限的活力与希望。这时候，正是踏青赏花的最佳时节。漫步于郊外的田间小道上，呼吸着清新的空气，欣赏着沿途的美景，感受着大自然带给我们的无限美好，是多么惬意而幸福的事情啊！\n\n夏日炎炎，烈日炎炎，酷暑难耐。这时候，最惬意的莫过于到河边或湖边纳凉避暑，吹吹风，听听蝉鸣鸟叫声，看看美景，闻闻花香，放松心情，多么惬意而幸福的事情啊！\n\n秋高气爽，风轻云淡，天空湛蓝深远，阳光明媚温暖，处处充满着无限生机与活力。这时候，正是登高望远的好时节。来到山顶，极目远眺，远处连绵起伏的山峦，近处绿意盎然的树林，以及点缀其间的一幢幢高楼大厦，构成了这美丽壮阔的自然风光画卷。此时此刻，心中不禁感叹道：“多么美的自然风光画卷呀！这是天地造化的神奇杰作，更是人类文明发展的智慧结晶！”\n\n冬季来临，天气渐渐转冷，寒风凛冽刺骨，但依然挡不住人们外出游玩赏景的热切渴望之心。这时候，最适合的就是到市区的各大公园、风景区等地去尽情享受户外休闲游玩的乐趣。在这里，你可以呼吸到新鲜的空气，观赏到大自然的鬼斧神工之美妙绝伦之处，感受到大自然的无穷无尽的生命力和无限创造力所带来的无以言表的心灵震撼和精神愉悦之感。这个时候，你的内心深处一定会油然而生出一种对大自然的无限敬畏之情和对生命的无限热爱之情。这种情感将会伴随着你的一生，成为你人生道路上最为宝贵的精神财富。\n\n这就是我的家乡，一座美丽富饶的历史文化名城，它以其独特优美的自然风光和多姿多彩的人文景观，吸引着无数游客纷至沓来的前来观光游览。来吧，朋友们！让我们一起走进这座美丽富饶的历史文化名城，共同领略它的独特魅力吧！\n\n【'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:60694 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:16:35 async_llm_engine.py:436] Received request chatcmpl-5af01d4d-d564-4521-9b7d-1105d781435f: prompt: '<s><|im_start|>system\n我们之前聊了：\n【篇一：美丽的家乡作文】\n\n我的家乡在山东省青岛市胶州市，那里四季分明、风景秀丽。我爱我的家乡！\n\n春天万物复苏，百花齐放。公园里的桃花开了，红的似火；迎春花也开了，黄的如金子般灿烂；樱花也不甘示弱，粉得像一片云霞……我家楼下的大榆树长出了嫩绿的叶子，远远望去就像一把把绿色的小扇子。每当夜幕降临，路灯亮了起来，高大挺拔的柳树上挂满了五颜六色的彩灯，五彩缤纷，美丽极了！\n\n夏天烈日炎炎，骄阳似火。池塘里荷花盛开，荷叶挨挨挤挤的，有的已经结出莲蓬了，蜻蜓立在尖上，好像要展翅高飞似的。我们小孩子最喜欢游泳了，一到晚上，小区内的露天游泳池人山人海，热闹非凡。大家在水中嬉戏玩耍，真是快乐无比啊！\n\n秋天瓜果飘香，硕果累累。果园里的苹果红彤彤的，葡萄紫盈盈的，石榴咧嘴笑了，柿子你挤我碰地挂着灯笼一样，好看得很呢！田野里稻谷笑弯了腰，金黄的玉米棒子漂亮极了！农民伯伯们脸上都洋溢着丰收的喜悦。\n\n冬天白雪皑皑，银装素裹。雪花给大地铺上了厚厚的雪毯，像是冬爷爷送给我们的礼物。孩子们堆起了雪人，打起了雪仗，玩得可开心啦！\n\n这就是一年四季四季分明、风景秀丽的家乡——青岛胶州！我爱我的家乡！\n\n【篇二：美丽的家乡作文】\n\n我的家乡在美丽的海滨城市——大连，这里有山有水，还有许多名胜古迹。我最喜欢的就是那迷人的景色和美食了。\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一个个调皮的孩子，探出头来好奇地看着外面的世界；杏花穿着粉红色的衣裙，显得格外妖娆；梨花开得更美了，白中带着粉红的花瓣随风起舞，散发出淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树抽出新的枝条，长出嫩绿的叶子，犹如小姑娘羞涩的脸庞。燕子也从南方赶来了，叽叽喳喳地叫个不停，仿佛在欢迎春天的到来。\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这就是我的家乡，一个风景优美的地方，你们喜欢吗？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 60781, 61306, 60356, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 71663, 85307, 61621, 69318, 60353, 69942, 73400, 78799, 60359, 70400, 91759, 60355, 77603, 68306, 73954, 60477, 402, 73047, 76278, 84247, 60353, 84500, 61572, 60524, 60355, 69608, 68664, 74664, 70653, 60353, 77865, 61267, 60790, 60506, 61515, 61167, 60629, 60395, 70653, 60353, 60870, 60354, 60407, 60611, 60401, 60980, 78944, 60506, 79898, 68430, 61772, 60602, 61648, 60353, 60846, 60428, 60770, 70882, 61120, 63118, 92396, 70664, 76109, 68552, 63929, 61357, 60485, 68758, 62239, 91221, 72281, 60353, 73614, 60866, 60461, 69281, 71282, 60581, 69391, 68447, 62433, 60401, 60355, 78599, 61207, 61406, 82865, 60353, 82646, 61224, 77784, 60353, 79634, 61525, 61607, 60354, 62380, 85264, 61680, 75117, 60735, 61166, 60999, 68738, 61263, 61360, 60353, 88064, 88528, 60353, 69732, 80600, 60477, 402, 69876, 61657, 60464, 61576, 61576, 60353, 63273, 60991, 61267, 60790, 60355, 86000, 60425, 83918, 61600, 60405, 60353, 83072, 62802, 62802, 62284, 62284, 60354, 60353, 68608, 68329, 60599, 60389, 62212, 63036, 60362, 60353, 65095, 65080, 60680, 60361, 61867, 60370, 60353, 69123, 60371, 60688, 62397, 60436, 61217, 74613, 60355, 68253, 74000, 78802, 70965, 60362, 60353, 76411, 68742, 60353, 70429, 69336, 84050, 80137, 60364, 84511, 60622, 60353, 75116, 83502, 60355, 77464, 70904, 64650, 60809, 76633, 60353, 69695, 69162, 73850, 60973, 60477, 402, 76665, 61421, 60457, 62574, 60765, 60353, 62111, 60457, 61492, 61492, 60355, 89124, 68664, 68963, 60776, 64189, 64189, 60354, 60353, 69524, 61708, 62506, 62506, 60354, 60353, 79844, 64010, 61693, 76995, 60353, 82281, 60403, 62284, 60363, 61982, 60415, 89741, 82111, 68392, 60353, 69286, 72967, 60827, 60477, 61329, 61411, 60425, 62761, 61696, 61188, 62251, 60362, 61950, 60353, 72932, 60354, 69502, 61963, 60401, 69385, 80600, 60477, 70294, 61614, 61614, 60400, 71562, 60406, 61430, 63084, 60486, 88982, 60354, 79725, 60355, 402, 70564, 89114, 66138, 66138, 60353, 61161, 60634, 60881, 62595, 60355, 79454, 60562, 74811, 61625, 69028, 92223, 61482, 63521, 60353, 73155, 61479, 70607, 77025, 68582, 70240, 60355, 73236, 62073, 71702, 61482, 60364, 60353, 60471, 71702, 61482, 63412, 60353, 92330, 60369, 69166, 61452, 60477, 402, 69853, 90180, 73400, 78799, 60359, 70400, 61261, 75266, 73954, 92395, 71738, 61621, 60745, 60477, 77603, 68306, 73954, 60477, 402, 60781, 61306, 60529, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 69732, 72198, 62498, 68494, 92395, 74158, 60353, 82894, 60631, 60360, 60456, 60353, 91535, 82616, 84395, 60355, 74596, 68986, 68259, 60462, 88508, 77785, 60381, 69613, 60362, 60355, 402, 73047, 60353, 76278, 84247, 60353, 72536, 84159, 90056, 60355, 69608, 68664, 91470, 61236, 61112, 61399, 62515, 60353, 68959, 60576, 60358, 64099, 60521, 60387, 61515, 61167, 60629, 60770, 74451, 86772, 71527, 60353, 61578, 85357, 60383, 73718, 60415, 69082, 78642, 68339, 60506, 62775, 60629, 71294, 60846, 74789, 79093, 60353, 70213, 78894, 62475, 65832, 60506, 62696, 79204, 82040, 60528, 60362, 60353, 60624, 60366, 69609, 90410, 71832, 62127, 91319, 60480, 61609, 60353, 61331, 71611, 78995, 78899, 60353, 63919, 73105, 62204, 60353, 70338, 62245, 62455, 60355, 60398, 61190, 60577, 82256, 60425, 62285, 83320, 60353, 62239, 85004, 60359, 61290, 91221, 60353, 60770, 70516, 61006, 62804, 61341, 82218, 71087, 70849, 60355, 86738, 85188, 68641, 81566, 60353, 87346, 62239, 91221, 72281, 60353, 79490, 81902, 62907, 63284, 78811, 63227, 60355, 88310, 60395, 60577, 71672, 61855, 68830, 60353, 64764, 64764, 65602, 65602, 60415, 61221, 60365, 71080, 60353, 72218, 60361, 69069, 61167, 70091, 73623, 60355, 402, 69876, 60353, 61657, 60464, 61576, 61576, 60353, 63273, 60991, 61267, 60790, 60355, 76931, 61126, 63277, 64888, 63015, 60353, 78454, 70723, 68867, 70005, 80995, 64650, 60809, 76633, 60353, 68608, 60361, 63128, 84026, 60353, 68608, 60361, 84355, 60353, 68350, 80216, 60835, 87655, 28501, 75137, 60804, 76872, 60417, 60353, 78508, 70405, 90612, 79464, 61342, 63663, 60353, 69871, 80600, 60477, 86738, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 74122, 87510, 61405, 60364, 60353, 74922, 83024, 72695, 61873, 60380, 65351, 61626, 77795, 60353, 73322, 64685, 60994, 60486, 68948, 60353, 67281, 67281, 60762, 60361, 83526, 60425, 60419, 60538, 60362, 60353, 60538, 60362, 60420, 60415, 73517, 60353, 70200, 60361, 60423, 60387, 60419, 60591, 69072, 71510, 74122, 61942, 60477, 60420, 402, 76665, 60353, 75224, 61492, 61492, 60353, 61421, 60457, 62574, 60765, 60355, 88436, 82060, 72281, 60650, 60870, 60362, 60353, 72744, 61895, 61895, 61036, 68462, 60353, 60770, 70334, 60539, 72945, 64442, 64442, 60480, 61609, 60506, 63598, 61193, 86600, 60353, 73614, 60866, 60461, 60353, 60770, 90566, 60917, 73377, 74230, 76655, 60355, 61329, 61411, 68664, 61617, 65252, 69571, 60362, 60353, 70294, 61614, 61614, 71562, 75422, 75488, 75715, 60353, 68310, 69610, 81910, 61617, 65252, 60353, 69610, 61491, 60486, 61048, 60762, 60353, 60580, 60546, 69909, 71783, 60362, 60477, 402, 70564, 60353, 89114, 66138, 66138, 60353, 61161, 60634, 60881, 62595, 60355, 62819, 61101, 60368, 61482, 61560, 60429, 61217, 61609, 60353, 79119, 79329, 60370, 60359, 82302, 60370, 60359, 60412, 68351, 76532, 60370, 60353, 68898, 68339, 72330, 89114, 70526, 71721, 60355, 69972, 73314, 68318, 62073, 61482, 60364, 60359, 60471, 61482, 63412, 60353, 92330, 60369, 69166, 60362, 60353, 69125, 69367, 83933, 89795, 60693, 61113, 61113, 87078, 60415, 79780, 60355, 402, 69853, 68306, 73954, 60353, 68252, 70400, 76656, 68704, 60353, 68593, 68299, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:16:36 metrics.py:213] Avg prompt throughput: 167.6 tokens/s, Avg generation throughput: 33.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:16:40 async_llm_engine.py:110] Finished request chatcmpl-5af01d4d-d564-4521-9b7d-1105d781435f.
2024-03-28 22:16:52.021 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\n【篇三：美丽的家乡作文】\n\n我的家乡在河南郑州这座美丽的城市，这里四季分明，风景秀丽。我爱我的家乡！\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一群活泼可爱的小孩子，探出头来好奇地看着外面的世界；杏花穿着淡粉色连衣裙，显得格外妩媚动人；梨花开得更美了，白中带粉的莲花花瓣随风起舞，散发着淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这是我的家乡，一个风景优美的地方，你想来看看吗？爱我就给我点赞吧！^_^(^_^)\n【篇四：美丽的家乡作文】\n\n我的家乡在山东烟台市的一个小镇——招', 'role': 'system'}, {'content': '在核磁共振氢谱中，峰的两侧常常会出现很小的峰，请问为什么', 'role': 'user'}, {'role': 'assistant', 'content': '【篇三：美丽的家乡作文】\n\n我的家乡在广东肇庆市鼎湖区广利镇的一个小村庄里，这里风景秀丽，物产丰富，是一个名副其实的好地方。\n\n春天，树木抽出新芽，鲜花绽放笑脸。小鸟欢快地在枝头歌唱，蜜蜂嗡嗡地采蜜，蝴蝶在花丛中翩翩起舞。油菜花、桃花、梨花等各种各样的花朵竞相开放，姹紫嫣红，争妍斗艳。站在山顶上眺望远方，一大片绿色的田野映入眼帘，到处都是一片生机勃勃的样子。\n\n夏天，天气炎热，蝉鸣声此起彼伏。清晨，一轮红日在东边冉冉升起，照耀着大地。中午时分，太阳炙烤着大地，热得连小狗都不敢出门散步了。傍晚时分，夕阳西沉，瑰'}, {'content': '请问高锰酸钾的摩尔吸光系数是多少', 'role': 'user'}, {'role': 'assistant', 'content': '【篇三：美丽的家乡作文】\n\n我的家乡在四川省眉山市东坡区，这是一个美丽富饶的城市，也是我国著名的历史文化名城之一。在这座历史悠久的城市里，有许多闻名遐迩的名胜古迹和特色美食，这些都是这座城市的独特魅力所在。下面就让我们一起来领略一下这座美丽富饶的历史文化名城的独特魅力吧！\n\n春天，百花齐放，万木吐翠，到处生机勃勃，充满了无限的活力与希望。这时候，正是踏青赏花的最佳时节。漫步于郊外的田间小道上，呼吸着清新的空气，欣赏着沿途的美景，感受着大自然带给我们的无限美好，是多么惬意而幸福的事情啊！\n\n夏日炎炎，烈日炎炎，酷暑难耐。这时候，最惬意的莫过于到河边或湖边纳凉避暑，吹吹风，听听蝉鸣鸟叫声，看看美景，闻闻花香，放松心情，多么惬意而幸福的事情啊！\n\n秋高气爽，风轻云淡，天空湛蓝深远，阳光明媚温暖，处处充满着无限生机与活力。这时候，正是登高望远的好时节。来到山顶，极目远眺，远处连绵起伏的山峦，近处绿意盎然的树林，以及点缀其间的一幢幢高楼大厦，构成了这美丽壮阔的自然风光画卷。此时此刻，心中不禁感叹道：“多么美的自然风光画卷呀！这是天地造化的神奇杰作，更是人类文明发展的智慧结晶！”\n\n冬季来临，天气渐渐转冷，寒风凛冽刺骨，但依然挡不住人们外出游玩赏景的热切渴望之心。这时候，最适合的就是到市区的各大公园、风景区等地去尽情享受户外休闲游玩的乐趣。在这里，你可以呼吸到新鲜的空气，观赏到大自然的鬼斧神工之美妙绝伦之处，感受到大自然的无穷无尽的生命力和无限创造力所带来的无以言表的心灵震撼和精神愉悦之感。这个时候，你的内心深处一定会油然而生出一种对大自然的无限敬畏之情和对生命的无限热爱之情。这种情感将会伴随着你的一生，成为你人生道路上最为宝贵的精神财富。\n\n这就是我的家乡，一座美丽富饶的历史文化名城，它以其独特优美的自然风光和多姿多彩的人文景观，吸引着无数游客纷至沓来的前来观光游览。来吧，朋友们！让我们一起走进这座美丽富饶的历史文化名城，共同领略它的独特魅力吧！\n\n【'}, {'content': '请问高锰酸钾溶液的摩尔吸光系数是多少', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:37162 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:16:52 async_llm_engine.py:436] Received request chatcmpl-a8f7efec-04a9-448c-a386-9c7b2d8a72bc: prompt: '<s><|im_start|>system\n我们之前聊了：\n【篇三：美丽的家乡作文】\n\n我的家乡在河南郑州这座美丽的城市，这里四季分明，风景秀丽。我爱我的家乡！\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一群活泼可爱的小孩子，探出头来好奇地看着外面的世界；杏花穿着淡粉色连衣裙，显得格外妩媚动人；梨花开得更美了，白中带粉的莲花花瓣随风起舞，散发着淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这是我的家乡，一个风景优美的地方，你想来看看吗？爱我就给我点赞吧！^_^(^_^)\n【篇四：美丽的家乡作文】\n\n我的家乡在山东烟台市的一个小镇——招<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 60781, 61306, 60479, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 69419, 73533, 75903, 73027, 68494, 60353, 68409, 73400, 78799, 60353, 70400, 91759, 60355, 77603, 68306, 73954, 60477, 402, 73047, 60353, 76278, 84247, 60353, 72536, 84159, 90056, 60355, 69608, 68664, 91470, 61236, 61112, 61399, 62515, 60353, 68959, 60576, 60358, 64099, 60521, 60387, 61515, 61167, 60629, 60770, 72754, 74853, 78410, 68303, 60353, 61578, 85357, 60383, 73718, 60415, 69082, 78642, 68339, 60506, 62775, 60629, 71294, 61481, 75562, 79547, 60353, 70213, 78894, 65421, 63543, 88041, 60506, 62696, 79204, 82040, 60528, 60362, 60353, 60624, 60366, 60681, 89661, 77561, 75123, 91319, 60480, 61609, 60353, 77687, 60486, 78995, 78899, 60353, 63919, 73105, 62204, 60353, 70338, 62245, 62455, 60355, 60398, 61190, 60577, 82256, 60425, 62285, 83320, 60353, 62239, 85004, 60359, 61290, 91221, 60353, 60770, 70516, 61006, 62804, 61341, 82218, 71087, 70849, 60355, 86738, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 74122, 87510, 61405, 60364, 60353, 74922, 83024, 72695, 61873, 60380, 65351, 61626, 77795, 60353, 73322, 64685, 60994, 60486, 68948, 60353, 67281, 67281, 60762, 60361, 83526, 60425, 60419, 60538, 60362, 60353, 60538, 60362, 60420, 60415, 73517, 60353, 70200, 60361, 60423, 60387, 60419, 60591, 69072, 71510, 74122, 61942, 60477, 60420, 402, 69876, 60353, 61657, 60464, 61576, 61576, 60353, 63273, 60991, 61267, 60790, 60355, 76931, 61126, 63277, 64888, 63015, 60353, 78454, 70723, 68867, 70005, 80995, 64650, 60809, 76633, 60353, 68608, 60361, 63128, 84026, 60353, 68608, 60361, 84355, 60353, 68350, 80216, 60835, 87655, 28501, 75137, 60804, 76872, 60417, 60353, 78508, 70405, 90612, 79464, 61342, 63663, 60353, 69871, 80600, 60477, 86738, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 74122, 87510, 61405, 60364, 60353, 74922, 83024, 72695, 61873, 60380, 65351, 61626, 77795, 60353, 73322, 64685, 60994, 60486, 68948, 60353, 67281, 67281, 60762, 60361, 83526, 60425, 60419, 60538, 60362, 60353, 60538, 60362, 60420, 60415, 73517, 60353, 70200, 60361, 60423, 60387, 60419, 60591, 69072, 71510, 74122, 61942, 60477, 60420, 402, 76665, 60353, 75224, 61492, 61492, 60353, 61421, 60457, 62574, 60765, 60355, 88436, 82060, 72281, 60650, 60870, 60362, 60353, 72744, 61895, 61895, 61036, 68462, 60353, 60770, 70334, 60539, 72945, 64442, 64442, 60480, 61609, 60506, 63598, 61193, 86600, 60353, 73614, 60866, 60461, 60353, 60770, 90566, 60917, 73377, 74230, 76655, 60355, 61329, 61411, 68664, 61617, 65252, 69571, 60362, 60353, 70294, 61614, 61614, 71562, 75422, 75488, 75715, 60353, 68310, 69610, 81910, 61617, 65252, 60353, 69610, 61491, 60486, 61048, 60762, 60353, 60580, 60546, 69909, 71783, 60362, 60477, 402, 70564, 60353, 89114, 66138, 66138, 60353, 61161, 60634, 60881, 62595, 60355, 62819, 61101, 60368, 61482, 61560, 60429, 61217, 61609, 60353, 79119, 79329, 60370, 60359, 82302, 60370, 60359, 60412, 68351, 76532, 60370, 60353, 68898, 68339, 72330, 89114, 70526, 71721, 60355, 69972, 73314, 68318, 62073, 61482, 60364, 60359, 60471, 61482, 63412, 60353, 92330, 60369, 69166, 60362, 60353, 69125, 69367, 83933, 89795, 60693, 61113, 61113, 87078, 60415, 79780, 60355, 402, 68472, 68306, 73954, 60353, 68252, 70400, 76656, 68704, 60353, 71804, 69249, 61076, 60504, 60632, 68600, 68706, 69625, 60701, 60477, 353, 284, 13409, 353, 284, 353, 471, 60781, 61306, 60651, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 69293, 82551, 60511, 68520, 77043, 92395, 61305, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:16:52 metrics.py:213] Avg prompt throughput: 35.6 tokens/s, Avg generation throughput: 24.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:16:57 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 96.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:16:57 async_llm_engine.py:110] Finished request chatcmpl-a8f7efec-04a9-448c-a386-9c7b2d8a72bc.
2024-03-28 22:16:59.371 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\n【篇三：美丽的家乡作文】\n\n我的家乡在河南郑州这座美丽的城市，这里四季分明，风景秀丽。我爱我的家乡！\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一群活泼可爱的小孩子，探出头来好奇地看着外面的世界；杏花穿着淡粉色连衣裙，显得格外妩媚动人；梨花开得更美了，白中带粉的莲花花瓣随风起舞，散发着淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这是我的家乡，一个风景优美的地方，你想来看看吗？爱我就给我点赞吧！^_^(^_^)\n【篇四：美丽的家乡作文】\n\n我的家乡在山东烟台市的一个小镇——招', 'role': 'system'}, {'content': '请问高锰酸钾溶液的摩尔吸光系数是多少', 'role': 'user'}, {'role': 'assistant', 'content': '远，那里一年四季景色诱人。\n春天，百花齐放，争妍斗丽。看！桃花开了，一朵朵粉红的桃花挂满了枝头，就像一位位美丽的仙女在树上翩翩起舞呢；杏花也开了，一簇簇白色的花朵缀满枝头，犹如片片白云；迎春花也不甘落后，它们已经迫不及待地绽放了，那一丛丛金黄色的花朵挂在枝条上，好像一个个金色的小喇叭，正对着天空吹奏起来呢。\n夏天，树木郁郁葱葱，鲜花争奇斗艳。看！荷花开了，荷叶圆圆的，碧绿的，像一把把绿色的大伞，遮住了湖面，又像是被谁抖动了一下似的，一圈圈波纹扩散开来，好看极了！有的荷花含苞欲放，像一位害羞的小姑娘躲在荷叶后面不敢出来；有的荷花盛开怒放，亭亭玉立在碧绿的荷叶中间，白的像雪一样纯洁无瑕，真是漂亮极了！远处偶尔传来几声蝉鸣，仿佛是在给这副美景伴奏呢！\n秋天，硕果累累，金风送爽。看！苹果熟了，一个个红彤彤的苹果挂满枝头，就像无数个红灯笼一样，看起来喜气洋洋的；柿子也熟了，一个个红通通的柿子压弯了枝头，就像是树上挂着的一盏盏小灯笼一样，美丽极了！橘子也熟了，一个个黄灿灿的橘子像一盏盏小灯笼挂在树上，可爱极了！\n冬天，雪花飘飘洒洒，大地一片银装素裹。看！梅花开了，一朵朵红色的梅花傲然挺立在冰雪之中，那鲜艳的红与晶莹的白交相辉映，构成了一幅绝美的冬景图！\n这就是我家乡一年四季的美景，你们喜欢吗？欢迎你来这里游玩哦！\n【篇五：美丽的家乡作文】\n我有一个美丽的家乡，它坐落在山东省烟台市莱山区，这是一个环境优美、空气清新的地方，这个地方就是我的家乡——烟台市区。\n说起我的家乡烟台市区，它的名字就给人一种非常亲切的感觉。没错，它确实是一个很亲切的城市，因为它地处渤海之滨，背靠巍峨的太行山，因此形成了沿海和内陆两种不同的气候特征，这种独特的地理位置造就了我家乡特有的自然风光与人文景观。\n说到人文景观，那就不得不提到我们烟台市区最著名的景点之一——芝罘岛风景区。这个景区位于烟台市的'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:37168 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:16:59 async_llm_engine.py:436] Received request chatcmpl-fab04f3e-a47b-4e99-adc2-d6159428daf6: prompt: '<s><|im_start|>system\n我们之前聊了：\n【篇三：美丽的家乡作文】\n\n我的家乡在河南郑州这座美丽的城市，这里四季分明，风景秀丽。我爱我的家乡！\n\n春天，万物复苏，到处生机勃勃。公园里的花儿争奇斗艳，让人目不暇接：迎春花像一群活泼可爱的小孩子，探出头来好奇地看着外面的世界；杏花穿着淡粉色连衣裙，显得格外妩媚动人；梨花开得更美了，白中带粉的莲花花瓣随风起舞，散发着淡淡的清香，沁人心脾，令人陶醉。小草从泥土里钻了出来，嫩嫩的、绿绿的，像一块块碧玉镶嵌在大地上。大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n夏天，烈日炎炎，骄阳似火。大海波涛汹涌，沙滩上有许多人在海边嬉戏玩耍，有的在捡贝壳，有的在晒太阳，还有的在玩沙子......一阵微风吹过，海水轻轻拍打着我的脚丫，舒服极了！大树长得郁郁葱葱，为人们遮阳蔽日。夜晚凉爽宜人，月亮在天空中撒下皎洁月光，星星眨巴着眼睛，蛐蛐儿在草丛里“知了，知了”地唱歌，似乎在说：“真是个美好的夜晚呀！”\n\n秋天，果实累累，瓜果飘香。银杏树的叶子变黄了，纷纷扬扬落下来，像一只只蝴蝶翩翩起舞；枫叶红了，远远望去，像一团团燃烧着的火焰。田野里的庄稼成熟了，农民伯伯脸上露出幸福的笑容，他们一边收割庄稼，一边唱着歌儿，别提有多高兴了！\n\n冬天，白雪皑皑，银装素裹。鹅毛大雪漫天飞舞，落在屋顶上、树枝上、行人的肩膀上，整个世界都被白雪覆盖住了。我和小伙伴们一起堆雪人、打雪仗，玩得可开心了，直到太阳公公下山才依依不舍地回家了。\n\n这是我的家乡，一个风景优美的地方，你想来看看吗？爱我就给我点赞吧！^_^(^_^)\n【篇四：美丽的家乡作文】\n\n我的家乡在山东烟台市的一个小镇——招<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 60781, 61306, 60479, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 69419, 73533, 75903, 73027, 68494, 60353, 68409, 73400, 78799, 60353, 70400, 91759, 60355, 77603, 68306, 73954, 60477, 402, 73047, 60353, 76278, 84247, 60353, 72536, 84159, 90056, 60355, 69608, 68664, 91470, 61236, 61112, 61399, 62515, 60353, 68959, 60576, 60358, 64099, 60521, 60387, 61515, 61167, 60629, 60770, 72754, 74853, 78410, 68303, 60353, 61578, 85357, 60383, 73718, 60415, 69082, 78642, 68339, 60506, 62775, 60629, 71294, 61481, 75562, 79547, 60353, 70213, 78894, 65421, 63543, 88041, 60506, 62696, 79204, 82040, 60528, 60362, 60353, 60624, 60366, 60681, 89661, 77561, 75123, 91319, 60480, 61609, 60353, 77687, 60486, 78995, 78899, 60353, 63919, 73105, 62204, 60353, 70338, 62245, 62455, 60355, 60398, 61190, 60577, 82256, 60425, 62285, 83320, 60353, 62239, 85004, 60359, 61290, 91221, 60353, 60770, 70516, 61006, 62804, 61341, 82218, 71087, 70849, 60355, 86738, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 74122, 87510, 61405, 60364, 60353, 74922, 83024, 72695, 61873, 60380, 65351, 61626, 77795, 60353, 73322, 64685, 60994, 60486, 68948, 60353, 67281, 67281, 60762, 60361, 83526, 60425, 60419, 60538, 60362, 60353, 60538, 60362, 60420, 60415, 73517, 60353, 70200, 60361, 60423, 60387, 60419, 60591, 69072, 71510, 74122, 61942, 60477, 60420, 402, 69876, 60353, 61657, 60464, 61576, 61576, 60353, 63273, 60991, 61267, 60790, 60355, 76931, 61126, 63277, 64888, 63015, 60353, 78454, 70723, 68867, 70005, 80995, 64650, 60809, 76633, 60353, 68608, 60361, 63128, 84026, 60353, 68608, 60361, 84355, 60353, 68350, 80216, 60835, 87655, 28501, 75137, 60804, 76872, 60417, 60353, 78508, 70405, 90612, 79464, 61342, 63663, 60353, 69871, 80600, 60477, 86738, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 74122, 87510, 61405, 60364, 60353, 74922, 83024, 72695, 61873, 60380, 65351, 61626, 77795, 60353, 73322, 64685, 60994, 60486, 68948, 60353, 67281, 67281, 60762, 60361, 83526, 60425, 60419, 60538, 60362, 60353, 60538, 60362, 60420, 60415, 73517, 60353, 70200, 60361, 60423, 60387, 60419, 60591, 69072, 71510, 74122, 61942, 60477, 60420, 402, 76665, 60353, 75224, 61492, 61492, 60353, 61421, 60457, 62574, 60765, 60355, 88436, 82060, 72281, 60650, 60870, 60362, 60353, 72744, 61895, 61895, 61036, 68462, 60353, 60770, 70334, 60539, 72945, 64442, 64442, 60480, 61609, 60506, 63598, 61193, 86600, 60353, 73614, 60866, 60461, 60353, 60770, 90566, 60917, 73377, 74230, 76655, 60355, 61329, 61411, 68664, 61617, 65252, 69571, 60362, 60353, 70294, 61614, 61614, 71562, 75422, 75488, 75715, 60353, 68310, 69610, 81910, 61617, 65252, 60353, 69610, 61491, 60486, 61048, 60762, 60353, 60580, 60546, 69909, 71783, 60362, 60477, 402, 70564, 60353, 89114, 66138, 66138, 60353, 61161, 60634, 60881, 62595, 60355, 62819, 61101, 60368, 61482, 61560, 60429, 61217, 61609, 60353, 79119, 79329, 60370, 60359, 82302, 60370, 60359, 60412, 68351, 76532, 60370, 60353, 68898, 68339, 72330, 89114, 70526, 71721, 60355, 69972, 73314, 68318, 62073, 61482, 60364, 60359, 60471, 61482, 63412, 60353, 92330, 60369, 69166, 60362, 60353, 69125, 69367, 83933, 89795, 60693, 61113, 61113, 87078, 60415, 79780, 60355, 402, 68472, 68306, 73954, 60353, 68252, 70400, 76656, 68704, 60353, 71804, 69249, 61076, 60504, 60632, 68600, 68706, 69625, 60701, 60477, 353, 284, 13409, 353, 284, 353, 471, 60781, 61306, 60651, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 69293, 82551, 60511, 68520, 77043, 92395, 61305, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:17:02 metrics.py:213] Avg prompt throughput: 108.3 tokens/s, Avg generation throughput: 57.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:17:04 async_llm_engine.py:110] Finished request chatcmpl-fab04f3e-a47b-4e99-adc2-d6159428daf6.
2024-03-28 22:17:16.618 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\n兰店镇。那里一年四季景色诱人，真是美丽如画啊！\n\n春天，冰雪融化了，大地披上了绿色的新衣裳。柳树抽出了新的枝条，长出了嫩绿的叶子；桃花也开了，一朵朵粉红色的小花缀满枝头，散发出阵阵诱人的芳香；小燕子从南方赶来了，它们叽叽喳喳地在电线上跳来跳去，好像在开一场演唱会呢！小鸟们在树上唧唧喳喳地叫个不停，它们是在告诉我们：“春天到了，赶快出来活动一下吧！”\n\n夏天，树木长得郁郁葱葱，为人们遮阳蔽日。池塘里的荷花开了，荷叶圆圆的，大的可以坐两个人呢，小的只能坐着一个小朋友；粉红的荷花亭亭玉立地站在荷叶中间，像一位位婀娜多姿的仙女在风中舞蹈；还有几只蜻蜓在荷花上面飞来飞往，给炎热的夏日增添了一丝清凉和无限的生机与活力！\n\n秋天，天气渐渐转凉了，树叶也开始慢慢变黄了，然后一片片慢慢地飘落了下来，铺满了大地，像是给大地铺上了一张金黄色的地毯，又像是给大地穿了一件金灿灿的大衣衫，好看极了！\n\n冬天，雪花飘飘洒洒地下了起来，寒风呼啸，吹在脸上冷冰冰的，冻得人直哆嗦，但萧瑟的冬景也别有一番情趣呢！我喜欢冬天的雪景，它纯洁、晶莹、透亮、剔透，宛若一个个调皮可爱的小精灵，绽放着璀璨夺目的光芒，为寂静无声的冬季带来了无限生机和无穷乐趣！\n\n我爱我的家乡，这里有迷人的山水风光、多彩多姿的自然景观以及浓郁淳朴的民俗风情，这一切都让我深深地爱上了我的家乡，我爱我的家乡，我为我的家乡感到自豪！\n【篇五：美丽的家乡作文】\n\n我的家乡在河南省南阳市邓州市穰东镇董营村。那里一年四季景色诱人，真是美丽如画啊！\n\n春天，冰雪融化了，大地披上了绿色的新衣裳。柳树抽出了新的枝条，长出了嫩绿的叶子；桃花也开了，一朵朵粉红色的小花缀满枝头，散发出阵阵诱人的芳香；小燕子从南方赶来了，它们叽叽喳喳地在电线上跳来跳去，好像在开一场演唱会呢！小鸟们在树上唧唧喳喳地叫个不停，它们是在', 'role': 'system'}, {'content': '高锰酸钾溶液的摩尔吸光系数是多少', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:48684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:17:16 async_llm_engine.py:436] Received request chatcmpl-5015bd6b-91a3-4b94-9f65-ef96c56ca7e4: prompt: '<s><|im_start|>system\n我们之前聊了：\n兰店镇。那里一年四季景色诱人，真是美丽如画啊！\n\n春天，冰雪融化了，大地披上了绿色的新衣裳。柳树抽出了新的枝条，长出了嫩绿的叶子；桃花也开了，一朵朵粉红色的小花缀满枝头，散发出阵阵诱人的芳香；小燕子从南方赶来了，它们叽叽喳喳地在电线上跳来跳去，好像在开一场演唱会呢！小鸟们在树上唧唧喳喳地叫个不停，它们是在告诉我们：“春天到了，赶快出来活动一下吧！”\n\n夏天，树木长得郁郁葱葱，为人们遮阳蔽日。池塘里的荷花开了，荷叶圆圆的，大的可以坐两个人呢，小的只能坐着一个小朋友；粉红的荷花亭亭玉立地站在荷叶中间，像一位位婀娜多姿的仙女在风中舞蹈；还有几只蜻蜓在荷花上面飞来飞往，给炎热的夏日增添了一丝清凉和无限的生机与活力！\n\n秋天，天气渐渐转凉了，树叶也开始慢慢变黄了，然后一片片慢慢地飘落了下来，铺满了大地，像是给大地铺上了一张金黄色的地毯，又像是给大地穿了一件金灿灿的大衣衫，好看极了！\n\n冬天，雪花飘飘洒洒地下了起来，寒风呼啸，吹在脸上冷冰冰的，冻得人直哆嗦，但萧瑟的冬景也别有一番情趣呢！我喜欢冬天的雪景，它纯洁、晶莹、透亮、剔透，宛若一个个调皮可爱的小精灵，绽放着璀璨夺目的光芒，为寂静无声的冬季带来了无限生机和无穷乐趣！\n\n我爱我的家乡，这里有迷人的山水风光、多彩多姿的自然景观以及浓郁淳朴的民俗风情，这一切都让我深深地爱上了我的家乡，我爱我的家乡，我为我的家乡感到自豪！\n【篇五：美丽的家乡作文】\n\n我的家乡在河南省南阳市邓州市穰东镇董营村。那里一年四季景色诱人，真是美丽如画啊！\n\n春天，冰雪融化了，大地披上了绿色的新衣裳。柳树抽出了新的枝条，长出了嫩绿的叶子；桃花也开了，一朵朵粉红色的小花缀满枝头，散发出阵阵诱人的芳香；小燕子从南方赶来了，它们叽叽喳喳地在电线上跳来跳去，好像在开一场演唱会呢！小鸟们在树上唧唧喳喳地叫个不停，它们是在<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 61178, 60899, 61013, 60355, 69942, 90180, 77785, 90534, 60353, 69695, 69732, 60407, 60797, 60973, 60477, 402, 73047, 60353, 82837, 73063, 60362, 60353, 74811, 62671, 69028, 77018, 60473, 61051, 64821, 60355, 62380, 61357, 61339, 68758, 68641, 81566, 60353, 60485, 68758, 62239, 91221, 72281, 60506, 74664, 60395, 70653, 60353, 82629, 62019, 88776, 68447, 60629, 63168, 60951, 62076, 60614, 60353, 61331, 71611, 61755, 61755, 62553, 68351, 84207, 60506, 60398, 88310, 60577, 71672, 61855, 68830, 60353, 69290, 64764, 64764, 65602, 65602, 82048, 60478, 70649, 61474, 60383, 61474, 60461, 60353, 69123, 60361, 60405, 70793, 79098, 60827, 60477, 85404, 85857, 85264, 64308, 64308, 65602, 65602, 60415, 61221, 60365, 71080, 60353, 69290, 68657, 80749, 60387, 60419, 73047, 68384, 60353, 77874, 68356, 68444, 72726, 60477, 60420, 402, 69876, 60353, 77054, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 86000, 68664, 83918, 70653, 60353, 83072, 61202, 80669, 60353, 68383, 68251, 61213, 69969, 60827, 60353, 69379, 68665, 75841, 70647, 68305, 60506, 60846, 77865, 83918, 62608, 62608, 61341, 60680, 60415, 70421, 83072, 68922, 60353, 60770, 70226, 60496, 66768, 62183, 60393, 62329, 60354, 76116, 60361, 60713, 60366, 72095, 60506, 68350, 60686, 60539, 65095, 65080, 60361, 83918, 68813, 61217, 60383, 61217, 60890, 60353, 60562, 90333, 77418, 76325, 68401, 61146, 79435, 60381, 89656, 84159, 60510, 73123, 60477, 402, 76665, 60353, 69946, 71920, 60796, 85529, 60353, 80039, 80566, 68893, 60650, 60870, 60362, 60353, 68265, 70882, 60621, 79761, 62574, 61036, 80023, 60353, 61625, 75117, 74811, 60353, 73155, 60562, 74811, 81700, 82328, 72932, 68738, 79071, 60353, 60676, 73155, 60562, 74811, 61145, 89869, 60611, 63595, 63595, 68552, 61051, 62943, 60353, 69286, 80600, 60477, 402, 70564, 60353, 79454, 91690, 62690, 62690, 70015, 77784, 60353, 61752, 60713, 61579, 64286, 60353, 61947, 86662, 61114, 82717, 60354, 60353, 62065, 60428, 60364, 60578, 64842, 64677, 60353, 60499, 62946, 62668, 60354, 61479, 60934, 83340, 68510, 61917, 86304, 60827, 60477, 72535, 89500, 61482, 60934, 60353, 60741, 83013, 60359, 90148, 60359, 61370, 61224, 60359, 63717, 61370, 60353, 63701, 61369, 74451, 86772, 78410, 72165, 60353, 64128, 83872, 91009, 62361, 68977, 82817, 60353, 60374, 62865, 61353, 80536, 60354, 70590, 72767, 71131, 84159, 60381, 75833, 73152, 60477, 402, 77603, 68306, 73954, 60353, 82894, 88508, 74397, 76269, 60359, 76468, 60393, 62329, 86987, 71364, 68375, 74712, 63628, 62808, 60354, 79110, 76847, 60353, 75118, 60406, 68678, 75865, 60415, 83975, 68306, 73954, 60353, 77603, 68306, 73954, 60353, 90706, 68306, 73954, 69836, 81603, 60477, 364, 60781, 61306, 60735, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 72033, 60606, 71575, 63045, 69318, 67381, 60636, 61013, 62209, 60885, 60864, 60355, 69942, 90180, 77785, 90534, 60353, 69695, 69732, 60407, 60797, 60973, 60477, 402, 73047, 60353, 82837, 73063, 60362, 60353, 74811, 62671, 69028, 77018, 60473, 61051, 64821, 60355, 62380, 61357, 61339, 68758, 68641, 81566, 60353, 60485, 68758, 62239, 91221, 72281, 60506, 74664, 60395, 70653, 60353, 82629, 62019, 88776, 68447, 60629, 63168, 60951, 62076, 60614, 60353, 61331, 71611, 61755, 61755, 62553, 68351, 84207, 60506, 60398, 88310, 60577, 71672, 61855, 68830, 60353, 69290, 64764, 64764, 65602, 65602, 82048, 60478, 70649, 61474, 60383, 61474, 60461, 60353, 69123, 60361, 60405, 70793, 79098, 60827, 60477, 85404, 85857, 85264, 64308, 64308, 65602, 65602, 60415, 61221, 60365, 71080, 60353, 69290, 68657, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:17:16 metrics.py:213] Avg prompt throughput: 37.2 tokens/s, Avg generation throughput: 17.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:17:21 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 97.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:17:21 async_llm_engine.py:110] Finished request chatcmpl-5015bd6b-91a3-4b94-9f65-ef96c56ca7e4.
2024-03-28 22:17:23.097 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '高锰酸钾溶液的摩尔吸光系数是多少', 'role': 'user'}, {'role': 'assistant', 'content': '告诉我们：“春天到了，赶快出来活动一下吧！”\n\n夏天，树木长得郁郁葱葱，为人们遮阳蔽日。池塘里的荷花开了，荷叶圆圆的，大的可以坐两个人呢，小的只能坐着一个小朋友；粉红的荷花亭亭玉立地站在荷叶中间，像一位位婀娜多姿的仙女在风中舞蹈；还有几只蜻蜓在荷花上面飞来飞往，给炎热的夏日增添了一丝清凉和无限的生机与活力！\n\n秋天，天气渐渐转凉了，树叶也开始慢慢变黄了，然后一片片慢慢地飘落了下来，铺满了大地，像是给大地铺上了一张金黄色的地毯，又像是给大地穿了一件金灿灿的大衣衫，好看极了！\n\n冬天，雪花飘飘洒洒地下了起来，寒风呼啸，吹在脸上冷冰冰的，冻得人直哆嗦，但萧瑟的冬景也别有一番情趣呢！我喜欢冬天的雪景，它纯洁、晶莹、透亮、剔透，宛若一个个调皮可爱的小精灵，绽放着璀璨夺目的光芒，为寂静无声的冬季带来了无限生机和无穷乐趣！\n\n我爱我的家乡，这里有迷人的山水风光、多彩多姿的自然景观以及浓郁淳朴的民俗风情，这一切都让我深深地爱上了我的家乡，我爱我的家乡，我为我的家乡感到自豪！\n【篇六：美丽的家乡作文】\n\n我的家乡在河南省南阳市邓州市穰东镇董营村，这里一年四季风景优美，让人流连忘返！\n\n春天，万物复苏，到处一片春意盎然景象。田野里到处都是绿油油的秧苗，一阵微风吹过，秧苗随风轻轻摇曳着，犹如一曲美妙的乐章，令人心旷神怡！\n\n夏天的太阳火辣辣的炙烤着大地，空气中弥漫着一股难闻的热浪气息。然而，在这样的高温下，却依然挡不住大自然勃勃生机的力量！你看那路边的花草树木，经过烈日的暴晒之后，虽然它们的枝叶被晒得蔫蔫儿的，但是它们的根茎却是牢牢地扎在了泥土里面，无论外界环境如何恶劣，都无法阻挡住这些顽强的生命力！看着这充满生机活力的自然景象，我不禁感叹道：“大自然的神奇之处就在于它的创造力和再生能力是如此之强大，而且从不轻易言败！”\n\n秋天的阳光温暖而又舒适宜人，此时的天空湛蓝深远，仿佛一眼就可以望到'}, {'content': '使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”', 'role': 'user'}], 'echo': False}
INFO 03-28 22:17:23 async_llm_engine.py:436] Received request chatcmpl-660752b1-0d1f-44ba-9e81-e245f09e49fc: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n高锰酸钾溶液的摩尔吸光系数是多少<|im_end|>\n<|im_start|>assistant\n告诉我们：“春天到了，赶快出来活动一下吧！”\n\n夏天，树木长得郁郁葱葱，为人们遮阳蔽日。池塘里的荷花开了，荷叶圆圆的，大的可以坐两个人呢，小的只能坐着一个小朋友；粉红的荷花亭亭玉立地站在荷叶中间，像一位位婀娜多姿的仙女在风中舞蹈；还有几只蜻蜓在荷花上面飞来飞往，给炎热的夏日增添了一丝清凉和无限的生机与活力！\n\n秋天，天气渐渐转凉了，树叶也开始慢慢变黄了，然后一片片慢慢地飘落了下来，铺满了大地，像是给大地铺上了一张金黄色的地毯，又像是给大地穿了一件金灿灿的大衣衫，好看极了！\n\n冬天，雪花飘飘洒洒地下了起来，寒风呼啸，吹在脸上冷冰冰的，冻得人直哆嗦，但萧瑟的冬景也别有一番情趣呢！我喜欢冬天的雪景，它纯洁、晶莹、透亮、剔透，宛若一个个调皮可爱的小精灵，绽放着璀璨夺目的光芒，为寂静无声的冬季带来了无限生机和无穷乐趣！\n\n我爱我的家乡，这里有迷人的山水风光、多彩多姿的自然景观以及浓郁淳朴的民俗风情，这一切都让我深深地爱上了我的家乡，我爱我的家乡，我为我的家乡感到自豪！\n【篇六：美丽的家乡作文】\n\n我的家乡在河南省南阳市邓州市穰东镇董营村，这里一年四季风景优美，让人流连忘返！\n\n春天，万物复苏，到处一片春意盎然景象。田野里到处都是绿油油的秧苗，一阵微风吹过，秧苗随风轻轻摇曳着，犹如一曲美妙的乐章，令人心旷神怡！\n\n夏天的太阳火辣辣的炙烤着大地，空气中弥漫着一股难闻的热浪气息。然而，在这样的高温下，却依然挡不住大自然勃勃生机的力量！你看那路边的花草树木，经过烈日的暴晒之后，虽然它们的枝叶被晒得蔫蔫儿的，但是它们的根茎却是牢牢地扎在了泥土里面，无论外界环境如何恶劣，都无法阻挡住这些顽强的生命力！看着这充满生机活力的自然景象，我不禁感叹道：“大自然的神奇之处就在于它的创造力和再生能力是如此之强大，而且从不轻易言败！”\n\n秋天的阳光温暖而又舒适宜人，此时的天空湛蓝深远，仿佛一眼就可以望到<|im_end|>\n<|im_start|>user\n使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60436, 64585, 61199, 63407, 74202, 60354, 77563, 61124, 60689, 75857, 82089, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 80749, 60387, 60419, 73047, 68384, 60353, 77874, 68356, 68444, 72726, 60477, 60420, 402, 69876, 60353, 77054, 70916, 62117, 62117, 61303, 61303, 60353, 60374, 68826, 88420, 63059, 60464, 60355, 86000, 68664, 83918, 70653, 60353, 83072, 61202, 80669, 60353, 68383, 68251, 61213, 69969, 60827, 60353, 69379, 68665, 75841, 70647, 68305, 60506, 60846, 77865, 83918, 62608, 62608, 61341, 60680, 60415, 70421, 83072, 68922, 60353, 60770, 70226, 60496, 66768, 62183, 60393, 62329, 60354, 76116, 60361, 60713, 60366, 72095, 60506, 68350, 60686, 60539, 65095, 65080, 60361, 83918, 68813, 61217, 60383, 61217, 60890, 60353, 60562, 90333, 77418, 76325, 68401, 61146, 79435, 60381, 89656, 84159, 60510, 73123, 60477, 402, 76665, 60353, 69946, 71920, 60796, 85529, 60353, 80039, 80566, 68893, 60650, 60870, 60362, 60353, 68265, 70882, 60621, 79761, 62574, 61036, 80023, 60353, 61625, 75117, 74811, 60353, 73155, 60562, 74811, 81700, 82328, 72932, 68738, 79071, 60353, 60676, 73155, 60562, 74811, 61145, 89869, 60611, 63595, 63595, 68552, 61051, 62943, 60353, 69286, 80600, 60477, 402, 70564, 60353, 79454, 91690, 62690, 62690, 70015, 77784, 60353, 61752, 60713, 61579, 64286, 60353, 61947, 86662, 61114, 82717, 60354, 60353, 62065, 60428, 60364, 60578, 64842, 64677, 60353, 60499, 62946, 62668, 60354, 61479, 60934, 83340, 68510, 61917, 86304, 60827, 60477, 72535, 89500, 61482, 60934, 60353, 60741, 83013, 60359, 90148, 60359, 61370, 61224, 60359, 63717, 61370, 60353, 63701, 61369, 74451, 86772, 78410, 72165, 60353, 64128, 83872, 91009, 62361, 68977, 82817, 60353, 60374, 62865, 61353, 80536, 60354, 70590, 72767, 71131, 84159, 60381, 75833, 73152, 60477, 402, 77603, 68306, 73954, 60353, 82894, 88508, 74397, 76269, 60359, 76468, 60393, 62329, 86987, 71364, 68375, 74712, 63628, 62808, 60354, 79110, 76847, 60353, 75118, 60406, 68678, 75865, 60415, 83975, 68306, 73954, 60353, 77603, 68306, 73954, 60353, 90706, 68306, 73954, 69836, 81603, 60477, 364, 60781, 61306, 60999, 60387, 73027, 73954, 72091, 60783, 402, 68306, 73954, 60361, 72033, 60606, 71575, 63045, 69318, 67381, 60636, 61013, 62209, 60885, 60864, 60353, 68409, 90180, 70400, 76656, 60353, 68959, 60673, 60907, 61530, 61799, 60477, 402, 73047, 60353, 76278, 84247, 60353, 72536, 70882, 61167, 60467, 64522, 60432, 84075, 60355, 61329, 61411, 60425, 91280, 61290, 60657, 76438, 64816, 61996, 60353, 75137, 60804, 76872, 60417, 60353, 64816, 61996, 91319, 70405, 62310, 64910, 60486, 60353, 79490, 60356, 61064, 60528, 75060, 60808, 60813, 60353, 70338, 60447, 64043, 60780, 63395, 60477, 402, 91986, 69367, 60790, 61416, 82136, 64520, 61449, 60486, 74811, 60353, 84502, 86197, 60486, 76521, 60850, 61523, 72339, 61536, 73028, 60355, 69104, 60353, 91788, 71909, 60380, 60353, 61032, 69640, 62327, 69691, 82279, 90056, 60384, 70000, 69429, 60477, 72729, 60462, 60586, 69036, 84943, 77054, 60353, 68879, 61657, 71985, 85104, 68307, 60353, 68477, 78591, 90810, 60549, 62029, 60428, 66022, 66022, 74246, 60353, 68276, 78591, 60772, 62974, 72691, 89400, 60415, 61909, 72647, 82256, 68546, 60353, 69007, 75201, 68476, 68343, 79147, 60353, 82621, 82423, 60852, 68374, 63658, 69995, 68851, 60481, 60477, 69082, 60376, 69911, 84159, 60571, 69310, 68519, 84075, 60353, 69124, 61724, 76523, 60469, 60387, 60419, 60368, 74956, 71866, 71632, 84371, 68957, 69544, 74018, 76228, 68432, 60357, 68994, 60424, 71237, 60353, 68389, 75316, 72682, 60923, 61603, 60477, 60420, 402, 61564, 70091, 69711, 70457, 76252, 70182, 61405, 60364, 60353, 69260, 90284, 63601, 61392, 60887, 61016, 60353, 72218, 73794, 68359, 60866, 60378, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68271, 60651, 60378, 72719, 60666, 68376, 70121, 72363, 60354, 60743, 60371, 69685, 60353, 68313, 69478, 60359, 68313, 60618, 60390, 60359, 68313, 76806, 61132, 60359, 68313, 77022, 69684, 60353, 68313, 92322, 60353, 71097, 69685, 60353, 60836, 68376, 70121, 60419, 61791, 61277, 60420, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:17:25 async_llm_engine.py:110] Finished request chatcmpl-660752b1-0d1f-44ba-9e81-e245f09e49fc.
INFO:     10.1.96.6:57570 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 22:17:41.306 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '高锰酸钾溶液的摩尔吸光系数？', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:44246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:17:41 async_llm_engine.py:436] Received request chatcmpl-5e438a01-7d75-4320-b522-c96cf6e14bf1: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n高锰酸钾溶液的摩尔吸光系数？<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60436, 64585, 61199, 63407, 74202, 60354, 77563, 61124, 60689, 75857, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:17:41 metrics.py:213] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 10.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:17:42 async_llm_engine.py:110] Finished request chatcmpl-5e438a01-7d75-4320-b522-c96cf6e14bf1.
2024-03-28 22:17:43.217 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '高锰酸钾溶液的摩尔吸光系数？', 'role': 'user'}, {'role': 'assistant', 'content': '对于波长为 **589 nm** 的光，高锰酸钾 (*K*~2~, *O*)）溶液的最大吸收峰处的摩尔吸光系数值约为 $$\\varepsilon = \\pu{23000 M cm^(-1)}$$。\n\n请记住，这是在特定条件下测量的值，并且可能会因温度、压力和溶剂等因素而发生变化。因此，在进行任何测量或计算时，最好查阅最新的文献资料。'}, {'content': '使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”', 'role': 'user'}], 'echo': False}
INFO 03-28 22:17:43 async_llm_engine.py:436] Received request chatcmpl-ec34099f-cf37-4460-9d9d-7b9e49feee2f: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n高锰酸钾溶液的摩尔吸光系数？<|im_end|>\n<|im_start|>assistant\n对于波长为 **589 nm** 的光，高锰酸钾 (*K*~2~, *O*)）溶液的最大吸收峰处的摩尔吸光系数值约为 $$\\varepsilon = \\pu{23000 M cm^(-1)}$$。\n\n请记住，这是在特定条件下测量的值，并且可能会因温度、压力和溶剂等因素而发生变化。因此，在进行任何测量或计算时，最好查阅最新的文献资料。<|im_end|>\n<|im_start|>user\n使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60436, 64585, 61199, 63407, 74202, 60354, 77563, 61124, 60689, 75857, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68390, 61126, 60485, 60374, 3235, 22397, 26164, 465, 262, 72449, 60353, 60436, 64585, 61199, 63407, 4770, 331, 297, 351, 314, 53502, 484, 306, 3924, 60413, 74202, 79056, 69664, 61685, 72126, 77563, 61124, 60689, 60541, 71429, 75053, 26543, 272, 286, 677, 58588, 415, 1268, 5739, 339, 1540, 1057, 516, 10098, 353, 4239, 312, 9268, 14223, 60355, 402, 60836, 70616, 60353, 68472, 60361, 73295, 76168, 61060, 68916, 60889, 60353, 68614, 69345, 60498, 69032, 60359, 68912, 60381, 82681, 84292, 60458, 86943, 60355, 68521, 60353, 79578, 68574, 70782, 60535, 68679, 60377, 60353, 68681, 82540, 74562, 70834, 68791, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68271, 60651, 60378, 72719, 60666, 68376, 70121, 72363, 60354, 60743, 60371, 69685, 60353, 68313, 69478, 60359, 68313, 60618, 60390, 60359, 68313, 76806, 61132, 60359, 68313, 77022, 69684, 60353, 68313, 92322, 60353, 71097, 69685, 60353, 60836, 68376, 70121, 60419, 61791, 61277, 60420, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:17:43 async_llm_engine.py:110] Finished request chatcmpl-ec34099f-cf37-4460-9d9d-7b9e49feee2f.
INFO:     10.1.96.6:44248 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 22:18:17.085 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '高锰酸钾溶液的摩尔吸光系数？', 'role': 'user'}, {'role': 'assistant', 'content': '对于波长为 **589 nm** 的光，高锰酸钾 (*K*~2~, *O*)）溶液的最大吸收峰处的摩尔吸光系数值约为 $$\\varepsilon = \\pu{23000 M cm^(-1)}$$。\n\n请记住，这是在特定条件下测量的值，并且可能会因温度、压力和溶剂等因素而发生变化。因此，在进行任何测量或计算时，最好查阅最新的文献资料。'}, {'content': '什么是拓扑绝缘体', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:48986 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:18:17 async_llm_engine.py:436] Received request chatcmpl-81b1b60b-484d-4184-b40b-6b3e7db307c9: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n高锰酸钾溶液的摩尔吸光系数？<|im_end|>\n<|im_start|>assistant\n对于波长为 **589 nm** 的光，高锰酸钾 (*K*~2~, *O*)）溶液的最大吸收峰处的摩尔吸光系数值约为 $$\\varepsilon = \\pu{23000 M cm^(-1)}$$。\n\n请记住，这是在特定条件下测量的值，并且可能会因温度、压力和溶剂等因素而发生变化。因此，在进行任何测量或计算时，最好查阅最新的文献资料。<|im_end|>\n<|im_start|>user\n什么是拓扑绝缘体<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60436, 64585, 61199, 63407, 74202, 60354, 77563, 61124, 60689, 75857, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68390, 61126, 60485, 60374, 3235, 22397, 26164, 465, 262, 72449, 60353, 60436, 64585, 61199, 63407, 4770, 331, 297, 351, 314, 53502, 484, 306, 3924, 60413, 74202, 79056, 69664, 61685, 72126, 77563, 61124, 60689, 60541, 71429, 75053, 26543, 272, 286, 677, 58588, 415, 1268, 5739, 339, 1540, 1057, 516, 10098, 353, 4239, 312, 9268, 14223, 60355, 402, 60836, 70616, 60353, 68472, 60361, 73295, 76168, 61060, 68916, 60889, 60353, 68614, 69345, 60498, 69032, 60359, 68912, 60381, 82681, 84292, 60458, 86943, 60355, 68521, 60353, 79578, 68574, 70782, 60535, 68679, 60377, 60353, 68681, 82540, 74562, 70834, 68791, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 71878, 62274, 62932, 79572, 60474, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:18:17 metrics.py:213] Avg prompt throughput: 14.6 tokens/s, Avg generation throughput: 2.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:18:22 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 97.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:18:22 async_llm_engine.py:110] Finished request chatcmpl-81b1b60b-484d-4184-b40b-6b3e7db307c9.
2024-03-28 22:18:23.318 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '', 'role': 'system'}, {'content': '高锰酸钾溶液的摩尔吸光系数？', 'role': 'user'}, {'role': 'assistant', 'content': '对于波长为 **589 nm** 的光，高锰酸钾 (*K*~2~, *O*)）溶液的最大吸收峰处的摩尔吸光系数值约为 $$\\varepsilon = \\pu{23000 M cm^(-1)}$$。\n\n请记住，这是在特定条件下测量的值，并且可能会因温度、压力和溶剂等因素而发生变化。因此，在进行任何测量或计算时，最好查阅最新的文献资料。'}, {'content': '什么是拓扑绝缘体', 'role': 'user'}, {'role': 'assistant', 'content': '作为电子学材料科学中的一个重要概念，“拓扑绝缘体”指的是表现出能隙绝缘行为但具有非平凡拓扑特性的固体材料。这一特性导致这些材料的边缘处发生显著的电荷载流子导电性。这种独特的性质使它们适用于下一代自旋电子器件和量子信息处理技术的开发。  \n\n有关更多详细信息，请参阅：[An Introduction To Topological Insulators](https://journals.aps.org/pr/materials/10.1103/s10035390950024x.pdf?origin=publication_list&utm_campaign=ps_journalfront&utm_source=socialbuttons&utm_medium=webcite&utm_content=bibliography)\n或者 [Topologically Protected Dirac Cones in Thin Films of the Superconductor Mo$_6$Sb$_9$(Se,S)**)**: A New Route Towards One-Dimensional Fermi Liquids（DOI：`http://dx.doi.org/doi:1143/JPSJ751258>`） 提供了对该主题的深入探讨。 \n\n此外，您还可以参考以下内容以获取更详细的讨论： \n  - [The Physics Behind High-Temperature "Supercondutors"](https://www.sciencenewsforstudents.org/article/the-physics-behind-high%C4%E8%A0%B5-superducto#.WpYVzPYw)\n\n    该文章介绍了高温超导体背后的物理原理，包括其与传统低温超导体的根本区别以及其在未来技术发展中的潜在应用。\n\n     其他相关资源可能还包括：\n    - [What Is Quantum Mechanics Anyway?! - Part I ](http://hyperphysics.phy-astr.gsu.edu/hbase/matcom.html), [Part II](part ii)(http://tutorial.math.lamar.edu/classes/apcalcu/topical15.aspx),\n   [Part III & IV)]((http://mathworld.wolfram.com/MonteCarloMethod.html)),\n   and [[Part V]](((http://chemed.chem.purdue.edu/fastpush/chapter13_7.html))).\n\n   请注意，虽然上述部分涵盖了广泛的数学理论和实践方法，但是，某些特定的术语和技术可能会超出高中水平的理解范围。因此，建议读者谨慎阅读并根据需要寻求额外的指导和解释。\n   \n   \n   \n\n---\n\n原文链接：[Talk about manganese dioxide\'s properties as well! :D https://chemistry.stackexchange'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:54756 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:18:23 async_llm_engine.py:436] Received request chatcmpl-4ce38029-0496-4ac2-b6bc-317462844b9f: prompt: '<s><|im_start|>system\n<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:18:27 metrics.py:213] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 79.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:18:28 async_llm_engine.py:110] Finished request chatcmpl-4ce38029-0496-4ac2-b6bc-317462844b9f.
2024-03-28 22:18:57.860 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\nHere\'s a small Python program that demonstrates the use of `yield` and coroutines in generating an infinite series.\n\n```\ndef generate_series():\n    i = 0\n\n    while True:\n        next_value = (1 / ((4 * i) + next(i))) if not math.isinf(next_value)\n                                                                                                                            else float(\'-inf\'))\n        \n \n            \n            if isinstance(prev_value, int):\n                curr_value = prev_value - abs(int((prev_value/2)**(3*int(((abs(prev_value)-100)/200)))))\n                                                             - ((((-5 ** (-8)))) ^ (~(abs(float(str(len(ansible))))))\n                                                              + str(re.sub(\'[^a-zA-Z]\', \'\', \'Python\'))))\n                                                         else None )\n                                                \n                                                elif callable(curr_value):  # If curr_value is itself iterable.\n                    for val in list(curr_value()):\n                        print(val)\n\n\n\n\n\n                    \n                  \n                  try: # Try to calculate value for current round.    \n                      new_val = self.calculate_value(round)\n                      \n              \n              except Exception as e :\n                  traceback.print_exc()\n      \n          \n          finally :  \n              round += step \n\n\n\n\n\n\n                                \n                            \n                            #print("Next Value:", new_val)\n\n\n                           try :\n\n                           \n \n                             ### Check weather there are any previous values or just starting from scratch ###\n            \n             \n               \n               self.prev_values.append(new_val)\n\n\n\n                 \n                   ###### Print all previously calculated terms #######\n                   \n                   \n           \n           \n        \n         \n         \n    \n       \n\n\n\n\n       \n     \n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n             \n  \n            \n\n            \n            \n          \n                \n                 \n\n\n\n\n\n        \n\n  \n\n   \n     \n\n\n\n \n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n \n\n\n    \n    \n \n        \n \n \n \n    \n    \n\n\n  \n  \n      \n\n   \n\n          \n      \n    \n\n      \n    \n                        \n                               \n                              \n                       \n                         \n   \n                     \r\n    \r\n                      \r\n   \r\n        \r\n   \r\n    \r\n  \r\n    \r\n      \r\n        \r\n   \r\n   \r\n   \r\n    \r\n   \r\n    \r\n   \r\n    \r\n  \r\n┌──────────┐\r│ Generate Infinite Series Using Coroutine & Yield |\r└──────────┘\r\n\r\nThis code defines two functions named "generate_series()" which generates infinitely many random numbers using multiple generators inside it.\r\n\r\nThe first function simply uses yield keyword after assigning initial number `(10)`.\r\nIt basically returns each successive integer by one at time until infinity without ever actually terminating execution flow! \r\n\r\nLet me explain this with some examples:\r\n\r\nSuppose we run our script once like below:\r\n```python \r\nfrom module import generate_series\r\n\r\n\r\ngen = generate_series()\r\nval = gen.__anext__()\r\nvalue_list=[]\r\n\r\nValue_list.append([str(value),', 'role': 'system'}, {'content': '高锰酸钾溶液的摩尔吸光系数？', 'role': 'user'}, {'role': 'assistant', 'content': '对于波长为 **589 nm** 的光，高锰酸钾 (*K*~2~, *O*)）溶液的最大吸收峰处的摩尔吸光系数值约为 $$\\varepsilon = \\pu{23000 M cm^(-1)}$$。\n\n请记住，这是在特定条件下测量的值，并且可能会因温度、压力和溶剂等因素而发生变化。因此，在进行任何测量或计算时，最好查阅最新的文献资料。'}, {'content': '什么是拓扑绝缘体', 'role': 'user'}, {'role': 'assistant', 'content': '作为电子学材料科学中的一个重要概念，“拓扑绝缘体”指的是表现出能隙绝缘行为但具有非平凡拓扑特性的固体材料。这一特性导致这些材料的边缘处发生显著的电荷载流子导电性。这种独特的性质使它们适用于下一代自旋电子器件和量子信息处理技术的开发。  \n\n有关更多详细信息，请参阅：[An Introduction To Topological Insulators](https://journals.aps.org/pr/materials/10.1103/s10035390950024x.pdf?origin=publication_list&utm_campaign=ps_journalfront&utm_source=socialbuttons&utm_medium=webcite&utm_content=bibliography)\n或者 [Topologically Protected Dirac Cones in Thin Films of the Superconductor Mo$_6$Sb$_9$(Se,S)**)**: A New Route Towards One-Dimensional Fermi Liquids（DOI：`http://dx.doi.org/doi:1143/JPSJ751258>`） 提供了对该主题的深入探讨。 \n\n此外，您还可以参考以下内容以获取更详细的讨论： \n  - [The Physics Behind High-Temperature "Supercondutors"](https://www.sciencenewsforstudents.org/article/the-physics-behind-high%C4%E8%A0%B5-superducto#.WpYVzPYw)\n\n    该文章介绍了高温超导体背后的物理原理，包括其与传统低温超导体的根本区别以及其在未来技术发展中的潜在应用。\n\n     其他相关资源可能还包括：\n    - [What Is Quantum Mechanics Anyway?! - Part I ](http://hyperphysics.phy-astr.gsu.edu/hbase/matcom.html), [Part II](part ii)(http://tutorial.math.lamar.edu/classes/apcalcu/topical15.aspx),\n   [Part III & IV)]((http://mathworld.wolfram.com/MonteCarloMethod.html)),\n   and [[Part V]](((http://chemed.chem.purdue.edu/fastpush/chapter13_7.html))).\n\n   请注意，虽然上述部分涵盖了广泛的数学理论和实践方法，但是，某些特定的术语和技术可能会超出高中水平的理解范围。因此，建议读者谨慎阅读并根据需要寻求额外的指导和解释。\n   \n   \n   \n\n---\n\n原文链接：[Talk about manganese dioxide\'s properties as well! :D https://chemistry.stackexchange'}, {'content': '能否描述一下黑磷的结构', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:56778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:18:57 async_llm_engine.py:436] Received request chatcmpl-7dd6a985-8a07-4ffa-8229-0f61cd53dcd2: prompt: '<s><|im_start|>system\n我们之前聊了：\nHere\'s a small Python program that demonstrates the use of `yield` and coroutines in generating an infinite series.\n\n```\ndef generate_series():\n    i = 0\n\n    while True:\n        next_value = (1 / ((4 * i) + next(i))) if not math.isinf(next_value)\n                                                                                                                            else float(\'-inf\'))\n        \n \n            \n            if isinstance(prev_value, int):\n                curr_value = prev_value - abs(int((prev_value/2)**(3*int(((abs(prev_value)-100)/200)))))\n                                                             - ((((-5 ** (-8)))) ^ (~(abs(float(str(len(ansible))))))\n                                                              + str(re.sub(\'[^a-zA-Z]\', \'\', \'Python\'))))\n                                                         else None )\n                                                \n                                                elif callable(curr_value):  # If curr_value is itself iterable.\n                    for val in list(curr_value()):\n                        print(val)\n\n\n\n\n\n                    \n                  \n                  try: # Try to calculate value for current round.    \n                      new_val = self.calculate_value(round)\n                      \n              \n              except Exception as e :\n                  traceback.print_exc()\n      \n          \n          finally :  \n              round += step \n\n\n\n\n\n\n                                \n                            \n                            #print("Next Value:", new_val)\n\n\n                           try :\n\n                           \n \n                             ### Check weather there are any previous values or just starting from scratch ###\n            \n             \n               \n               self.prev_values.append(new_val)\n\n\n\n                 \n                   ###### Print all previously calculated terms #######\n                   \n                   \n           \n           \n        \n         \n         \n    \n       \n\n\n\n\n       \n     \n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n             \n  \n            \n\n            \n            \n          \n                \n                 \n\n\n\n\n\n        \n\n  \n\n   \n     \n\n\n\n \n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n \n\n\n    \n    \n \n        \n \n \n \n    \n    \n\n\n  \n  \n      \n\n   \n\n          \n      \n    \n\n      \n    \n                        \n                               \n                              \n                       \n                         \n   \n                     \r\n    \r\n                      \r\n   \r\n        \r\n   \r\n    \r\n  \r\n    \r\n      \r\n        \r\n   \r\n   \r\n   \r\n    \r\n   \r\n    \r\n   \r\n    \r\n  \r\n┌──────────┐\r│ Generate Infinite Series Using Coroutine & Yield |\r└──────────┘\r\n\r\nThis code defines two functions named "generate_series()" which generates infinitely many random numbers using multiple generators inside it.\r\n\r\nThe first function simply uses yield keyword after assigning initial number `(10)`.\r\nIt basically returns each successive integer by one at time until infinity without ever actually terminating execution flow! \r\n\r\nLet me explain this with some examples:\r\n\r\nSuppose we run our script once like below:\r\n```python \r\nfrom module import generate_series\r\n\r\n\r\ngen = generate_series()\r\nval = gen.__anext__()\r\nvalue_list=[]\r\n\r\nValue_list.append([str(value),<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 8554, 725, 395, 2773, 13175, 2175, 560, 31319, 410, 1130, 446, 1711, 29971, 350, 454, 1978, 28960, 435, 23492, 589, 24174, 4169, 512, 14016, 4145, 882, 7076, 35019, 4089, 388, 266, 415, 262, 300, 402, 388, 3634, 3173, 642, 391, 3761, 3307, 415, 451, 312, 740, 1933, 319, 484, 731, 313, 619, 1942, 2107, 7845, 552, 668, 7041, 2230, 13713, 17050, 3307, 471, 5398, 38315, 1649, 2375, 623, 46643, 7137, 1941, 848, 3537, 1947, 464, 11552, 31961, 3307, 328, 658, 1122, 469, 15550, 3307, 415, 8011, 3307, 612, 3808, 1693, 1333, 10018, 3307, 301, 314, 32444, 298, 308, 297, 526, 6788, 3596, 31961, 3307, 7434, 1166, 5776, 1174, 724, 6082, 32146, 285, 11754, 4239, 317, 3235, 10429, 294, 26199, 6463, 30980, 30755, 8400, 4357, 7054, 33631, 1384, 724, 23097, 36988, 342, 739, 5953, 4469, 20778, 353, 264, 21301, 11321, 28207, 9113, 495, 30523, 3945, 1316, 29123, 902, 2391, 1878, 919, 6516, 18899, 12608, 40647, 27312, 3307, 1796, 387, 324, 1562, 9939, 3307, 505, 5247, 50027, 756, 3980, 2109, 1186, 435, 1284, 27312, 3307, 33257, 5269, 1496, 9228, 47347, 10828, 36512, 4453, 1685, 334, 802, 9870, 442, 11201, 1033, 500, 1628, 4940, 281, 1208, 5339, 1069, 6343, 415, 787, 43543, 3307, 32501, 471, 51809, 26719, 2442, 11833, 4270, 569, 514, 6417, 4453, 15190, 1565, 2365, 45136, 874, 7078, 16292, 1992, 38971, 680, 2454, 2442, 1191, 1567, 3185, 23005, 1552, 33714, 25875, 6682, 24021, 576, 6002, 5321, 12299, 632, 6343, 3784, 6122, 1576, 14649, 1139, 27223, 4758, 14511, 4406, 9234, 1194, 657, 1030, 3841, 2914, 607, 1244, 6069, 635, 18933, 7844, 5115, 3537, 28596, 26970, 524, 854, 29307, 9275, 2209, 1907, 6343, 12661, 41327, 634, 954, 696, 8346, 810, 8731, 16722, 3949, 26709, 27252, 40085, 40085, 19165, 441, 9078, 15809, 820, 7362, 417, 14754, 12457, 11097, 1121, 6113, 34607, 1202, 14031, 39631, 34661, 16292, 6516, 1848, 5294, 23796, 18756, 6026, 545, 1163, 4872, 393, 25033, 44645, 47764, 14862, 9528, 49238, 32077, 36765, 60059, 31001, 59635, 33998, 16292, 7078, 14938, 7078, 1208, 15996, 1529, 364, 7702, 364, 50300, 3663, 57710, 2706, 33277, 5339, 450, 20521, 9129, 20521, 6578, 10556, 6578, 17401, 9129, 20521, 20521, 20521, 6578, 20521, 6578, 20521, 6578, 10556, 67874, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 67970, 367, 67193, 19987, 53543, 11282, 12243, 4624, 14299, 741, 943, 950, 892, 367, 229, 151, 151, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 63877, 229, 151, 155, 1007, 2136, 2189, 18801, 1524, 5899, 7092, 461, 19532, 35019, 35065, 1028, 27295, 4291, 7619, 1806, 4352, 5270, 1817, 5408, 42697, 4928, 563, 17970, 918, 1300, 862, 5095, 5864, 7681, 16306, 1428, 59403, 3020, 1517, 47977, 734, 45650, 3388, 2286, 13362, 4838, 1966, 48232, 7687, 684, 959, 650, 1018, 3245, 53891, 2192, 3673, 3681, 10341, 1237, 11471, 6551, 346, 23675, 10198, 884, 10475, 550, 579, 1187, 10431, 32147, 10185, 3064, 713, 1745, 1181, 5475, 3220, 1217, 3845, 2998, 14016, 350, 12819, 2686, 1645, 4851, 1303, 7076, 35019, 8695, 4531, 415, 7076, 35019, 3729, 965, 415, 4240, 5006, 407, 558, 694, 3729, 1096, 2169, 30918, 1007, 1274, 2169, 2209, 2720, 626, 3839, 833, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:18:57 metrics.py:213] Avg prompt throughput: 17.6 tokens/s, Avg generation throughput: 4.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:19:02 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 96.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:19:03 async_llm_engine.py:110] Finished request chatcmpl-7dd6a985-8a07-4ffa-8229-0f61cd53dcd2.
2024-03-28 22:19:20.243 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '能否描述一下黑磷的结构', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:46434 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:19:20 async_llm_engine.py:436] Received request chatcmpl-3d73710d-0b10-4ca9-a05e-9acd023930bb: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n能否描述一下黑磷的结构<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 73312, 69401, 68300, 60913, 62928, 81466, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:19:20 metrics.py:213] Avg prompt throughput: 6.4 tokens/s, Avg generation throughput: 1.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:19:20 async_llm_engine.py:110] Finished request chatcmpl-3d73710d-0b10-4ca9-a05e-9acd023930bb.
2024-03-28 22:19:21.917 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '能否描述一下黑磷的结构', 'role': 'user'}, {'role': 'assistant', 'content': '黑磷具有独特的蜂窝状层状结构，由交替排列的六元环组成。与石墨相比，这种结构赋予了黑磷一些独特而有趣的特性。'}, {'content': '使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”', 'role': 'user'}], 'echo': False}
INFO 03-28 22:19:21 async_llm_engine.py:436] Received request chatcmpl-ab1c12ed-31d1-4fa5-8f57-dc87a7a871e3: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n能否描述一下黑磷的结构<|im_end|>\n<|im_start|>assistant\n黑磷具有独特的蜂窝状层状结构，由交替排列的六元环组成。与石墨相比，这种结构赋予了黑磷一些独特而有趣的特性。<|im_end|>\n<|im_start|>user\n使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 73312, 69401, 68300, 60913, 62928, 81466, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60913, 62928, 68537, 72377, 83393, 60883, 60956, 60883, 68707, 60353, 60620, 79533, 72591, 60354, 60999, 60670, 60914, 69094, 60355, 60510, 92049, 70146, 60353, 68381, 68707, 76381, 60362, 60913, 62928, 68315, 70216, 60458, 77312, 70534, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68271, 60651, 60378, 72719, 60666, 68376, 70121, 72363, 60354, 60743, 60371, 69685, 60353, 68313, 69478, 60359, 68313, 60618, 60390, 60359, 68313, 76806, 61132, 60359, 68313, 77022, 69684, 60353, 68313, 92322, 60353, 71097, 69685, 60353, 60836, 68376, 70121, 60419, 61791, 61277, 60420, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:19:22 async_llm_engine.py:110] Finished request chatcmpl-ab1c12ed-31d1-4fa5-8f57-dc87a7a871e3.
INFO:     10.1.96.6:46436 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 22:19:41.709 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '能否描述一下黑磷的结构', 'role': 'user'}, {'role': 'assistant', 'content': '黑磷具有独特的蜂窝状层状结构，由交替排列的六元环组成。与石墨相比，这种结构赋予了黑磷一些独特而有趣的特性。'}, {'content': '是否能更详细一点', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:39348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:19:41 async_llm_engine.py:436] Received request chatcmpl-24eb6d35-1c07-433c-891a-01e9dc97a7e5: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n能否描述一下黑磷的结构<|im_end|>\n<|im_start|>assistant\n黑磷具有独特的蜂窝状层状结构，由交替排列的六元环组成。与石墨相比，这种结构赋予了黑磷一些独特而有趣的特性。<|im_end|>\n<|im_start|>user\n是否能更详细一点<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 73312, 69401, 68300, 60913, 62928, 81466, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60913, 62928, 68537, 72377, 83393, 60883, 60956, 60883, 68707, 60353, 60620, 79533, 72591, 60354, 60999, 60670, 60914, 69094, 60355, 60510, 92049, 70146, 60353, 68381, 68707, 76381, 60362, 60913, 62928, 68315, 70216, 60458, 77312, 70534, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 83765, 60526, 69030, 68414, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:19:41 metrics.py:213] Avg prompt throughput: 18.4 tokens/s, Avg generation throughput: 3.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:19:44 async_llm_engine.py:110] Finished request chatcmpl-24eb6d35-1c07-433c-891a-01e9dc97a7e5.
2024-03-28 22:20:13.497 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '能否描述一下黑磷的结构', 'role': 'user'}, {'role': 'assistant', 'content': '黑磷具有独特的蜂窝状层状结构，由交替排列的六元环组成。与石墨相比，这种结构赋予了黑磷一些独特而有趣的特性。'}, {'content': '是否能更详细一点', 'role': 'user'}, {'role': 'assistant', 'content': '当然！如您所知，石墨烯是二维碳薄片，其原子以sp²杂化轨道排列成六角晶格图案。\n\n然而，在压力下，石墨会经历一系列相变，最终形成一种被称为“白磷”或“α-P”的新形式。在这个阶段，大部分分子之间的共价键被破坏，导致分子间作用力显著增强。这反过来又使材料变得更加致密和坚硬。\n\n当施加更大的压力时，α-P 会发生进一步的转变，形成称为“红磷”（β-P）的第二种稳定相。这个过程涉及对原子的重新定位，从而形成了新的、高度有序的、类似金刚石的晶体结构。与之前的相位相比，这个新结构的密度更高，硬度更大，并且由于其高度对称性和强大的电子相关性，表现出许多不寻常的特性。\n\n最后，继续增加压力，P物质会发生第三次转变，形成“青磷”（γ-P）的第三种稳定相。不幸的是，人们对这个阶段的了解相对较少，而且关于它的确切性质和行为仍然存在很多争议。 \n\n总之，这些不同的转化阶段展示了材料的结构和物理化学性质的巨大变化，凸显了这个非凡系统中固有的丰富多样性和复杂性。'}, {'content': '请详细地描述黑磷的结构，不要少于100字', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:59972 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:20:13 async_llm_engine.py:436] Received request chatcmpl-5050e1f9-71ec-4238-9fb2-38866442bbfa: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n能否描述一下黑磷的结构<|im_end|>\n<|im_start|>assistant\n黑磷具有独特的蜂窝状层状结构，由交替排列的六元环组成。与石墨相比，这种结构赋予了黑磷一些独特而有趣的特性。<|im_end|>\n<|im_start|>user\n是否能更详细一点<|im_end|>\n<|im_start|>assistant\n当然！如您所知，石墨烯是二维碳薄片，其原子以sp²杂化轨道排列成六角晶格图案。\n\n然而，在压力下，石墨会经历一系列相变，最终形成一种被称为“白磷”或“α-P”的新形式。在这个阶段，大部分分子之间的共价键被破坏，导致分子间作用力显著增强。这反过来又使材料变得更加致密和坚硬。\n\n当施加更大的压力时，α-P 会发生进一步的转变，形成称为“红磷”（β-P）的第二种稳定相。这个过程涉及对原子的重新定位，从而形成了新的、高度有序的、类似金刚石的晶体结构。与之前的相位相比，这个新结构的密度更高，硬度更大，并且由于其高度对称性和强大的电子相关性，表现出许多不寻常的特性。\n\n最后，继续增加压力，P物质会发生第三次转变，形成“青磷”（γ-P）的第三种稳定相。不幸的是，人们对这个阶段的了解相对较少，而且关于它的确切性质和行为仍然存在很多争议。 \n\n总之，这些不同的转化阶段展示了材料的结构和物理化学性质的巨大变化，凸显了这个非凡系统中固有的丰富多样性和复杂性。<|im_end|>\n<|im_start|>user\n请详细地描述黑磷的结构，不要少于100字<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 73312, 69401, 68300, 60913, 62928, 81466, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 60913, 62928, 68537, 72377, 83393, 60883, 60956, 60883, 68707, 60353, 60620, 79533, 72591, 60354, 60999, 60670, 60914, 69094, 60355, 60510, 92049, 70146, 60353, 68381, 68707, 76381, 60362, 60913, 62928, 68315, 70216, 60458, 77312, 70534, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 83765, 60526, 69030, 68414, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 68529, 60477, 91130, 60431, 60538, 60353, 92049, 63282, 60357, 71692, 62390, 75601, 60353, 60451, 74168, 60367, 2307, 65211, 61441, 60516, 71188, 72591, 60397, 91391, 61954, 60592, 70742, 60355, 402, 69104, 60353, 60361, 68912, 60380, 60353, 92049, 60382, 68823, 72609, 60544, 60650, 60353, 68985, 68722, 68617, 72712, 60419, 60624, 62928, 60420, 60535, 60419, 64130, 9429, 60420, 69328, 69048, 60355, 70156, 69106, 60353, 69061, 70241, 69713, 60792, 60791, 60939, 60549, 70722, 60353, 68601, 70241, 60470, 68525, 60481, 72731, 69857, 60355, 60376, 83307, 60676, 60534, 68545, 79596, 60962, 60940, 60381, 90690, 60355, 402, 60513, 88338, 74357, 68912, 60377, 60353, 64130, 9429, 262, 80997, 69806, 60354, 75223, 60353, 68722, 69402, 60419, 60776, 62928, 60420, 60414, 64593, 9429, 60413, 60354, 79033, 69210, 60544, 60355, 82693, 70432, 60409, 60507, 68787, 68928, 69659, 60353, 69172, 73696, 68641, 60359, 68933, 78557, 60354, 60359, 69485, 77183, 85208, 79782, 68707, 60355, 60510, 72398, 60544, 60496, 70146, 60353, 68262, 60473, 79803, 69284, 71841, 60353, 77915, 73884, 60353, 68614, 68560, 60451, 68933, 75892, 71222, 71358, 68774, 68524, 60489, 60353, 77460, 68867, 60358, 83889, 90034, 60355, 402, 68337, 60353, 68528, 68557, 68912, 60353, 299, 69138, 80997, 77535, 75223, 60353, 68722, 60419, 60965, 62928, 60420, 60414, 65597, 9429, 60413, 88949, 60476, 69210, 60544, 60355, 75820, 68332, 60353, 68826, 80275, 83864, 68505, 69142, 78444, 60353, 68389, 68716, 68957, 60788, 60756, 71512, 60381, 68891, 70102, 68570, 68281, 74635, 60355, 4872, 71247, 60353, 68374, 68793, 71515, 69106, 83637, 77416, 89912, 69473, 69383, 88175, 72397, 68919, 60353, 80513, 78242, 83502, 76859, 61340, 68608, 68771, 73231, 71222, 69701, 60489, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60836, 69030, 60415, 69401, 60913, 62928, 81466, 60353, 68313, 60605, 60418, 1166, 60666, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:20:13 metrics.py:213] Avg prompt throughput: 14.8 tokens/s, Avg generation throughput: 7.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:20:16 async_llm_engine.py:110] Finished request chatcmpl-5050e1f9-71ec-4238-9fb2-38866442bbfa.
2024-03-28 22:20:18.876 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '', 'role': 'system'}, {'content': '能否描述一下黑磷的结构', 'role': 'user'}, {'role': 'assistant', 'content': '黑磷具有独特的蜂窝状层状结构，由交替排列的六元环组成。与石墨相比，这种结构赋予了黑磷一些独特而有趣的特性。'}, {'content': '是否能更详细一点', 'role': 'user'}, {'role': 'assistant', 'content': '当然！如您所知，石墨烯是二维碳薄片，其原子以sp²杂化轨道排列成六角晶格图案。\n\n然而，在压力下，石墨会经历一系列相变，最终形成一种被称为“白磷”或“α-P”的新形式。在这个阶段，大部分分子之间的共价键被破坏，导致分子间作用力显著增强。这反过来又使材料变得更加致密和坚硬。\n\n当施加更大的压力时，α-P 会发生进一步的转变，形成称为“红磷”（β-P）的第二种稳定相。这个过程涉及对原子的重新定位，从而形成了新的、高度有序的、类似金刚石的晶体结构。与之前的相位相比，这个新结构的密度更高，硬度更大，并且由于其高度对称性和强大的电子相关性，表现出许多不寻常的特性。\n\n最后，继续增加压力，P物质会发生第三次转变，形成“青磷”（γ-P）的第三种稳定相。不幸的是，人们对这个阶段的了解相对较少，而且关于它的确切性质和行为仍然存在很多争议。 \n\n总之，这些不同的转化阶段展示了材料的结构和物理化学性质的巨大变化，凸显了这个非凡系统中固有的丰富多样性和复杂性。'}, {'content': '请详细地描述黑磷的结构，不要少于100字', 'role': 'user'}, {'role': 'assistant', 'content': '您将会了解到有关黑磷的令人着迷的细节——它是一种具有独特层状结构的二维半导体。为了给您一个全面的概述，让我们深入研究黑磷的原子和分子层面。\n\n首先，需要注意的是，黑磷是由磷原子组成的，就像其他形式的磷一样。但是，最有趣的事情之一在于黑磷中磷原子的特定排布方式。\n\n具体来说，在黑磷的结构内，磷原子以类似于石墨烯的方式布置在一个六角形晶格上。同样值得注意的是，在这种特定的磷原子排列中，每六个相邻磷原子中的一个位于晶格的中心位置，而不是像石墨烯那样位于边缘位置。这一关键的几何特征极大地影响了整个系统的整体结构和性能属性。\n\n除了这些基本方面之外，值得一提的是，黑磷还显示出额外的层次复杂性和动态可调节性。例如，最近的研究表明，可以通过改变外部刺激因素，如温度、电场等，来操纵黑磷内的原子级缺陷状态、能带结构和载流子输运机制，从而实现对其光电特性的精细控制和优化。\n\n总而言之，正如我们所看到的，黑磷的结构是一个引人入胜且复杂的课题，其中涉及到原子层的精确放置以及各种内部相互作用效应的微妙平衡。所有这些错综复杂的设计元素和功能模块共同构成了黑磷作为一种新型二维半导体的核心身份和卓越品质。'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:59988 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:20:18 async_llm_engine.py:436] Received request chatcmpl-3fcdd883-a331-41e9-aedd-892d0a7a657e: prompt: '<s><|im_start|>system\n<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:20:18 metrics.py:213] Avg prompt throughput: 4.7 tokens/s, Avg generation throughput: 51.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:20:23 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 98.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:20:24 async_llm_engine.py:110] Finished request chatcmpl-3fcdd883-a331-41e9-aedd-892d0a7a657e.
2024-03-28 22:22:34.547 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:53442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:22:34 async_llm_engine.py:436] Received request chatcmpl-4e9a742b-8400-433d-9965-b09e048dcd9e: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:22:34 metrics.py:213] Avg prompt throughput: 0.8 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:22:34 async_llm_engine.py:110] Finished request chatcmpl-4e9a742b-8400-433d-9965-b09e048dcd9e.
2024-03-28 22:24:50.784 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:59864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:24:50 async_llm_engine.py:436] Received request chatcmpl-40f41080-3b98-4843-9e22-16da5bbcd66a: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:24:50 metrics.py:213] Avg prompt throughput: 0.8 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:24:50 async_llm_engine.py:110] Finished request chatcmpl-40f41080-3b98-4843-9e22-16da5bbcd66a.
2024-03-28 22:24:55.326 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}, {'role': 'assistant', 'content': '您好！\n\n请问有什么我可以帮助您的吗？'}, {'content': '你好好', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:59864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:24:55 async_llm_engine.py:436] Received request chatcmpl-e2d3d8cd-3db9-4943-b5bc-742e2c1538d9: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n您好！\n\n请问有什么我可以帮助您的吗？<|im_end|>\n<|im_start|>user\n你好好<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 61176, 60391, 60477, 402, 80571, 69259, 74010, 68417, 70266, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60403, 69407, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:24:55 async_llm_engine.py:110] Finished request chatcmpl-e2d3d8cd-3db9-4943-b5bc-742e2c1538d9.
2024-03-28 22:24:56.640 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}, {'role': 'assistant', 'content': '您好！\n\n请问有什么我可以帮助您的吗？'}, {'content': '你好好', 'role': 'user'}, {'role': 'assistant', 'content': '感谢你的善意之言，它让我的一天更加美好。 如果您需要任何进一步的帮助，请随时告诉我！'}, {'content': '使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”', 'role': 'user'}], 'echo': False}
INFO 03-28 22:24:56 async_llm_engine.py:436] Received request chatcmpl-d5f43de0-61e8-4682-98db-ba39ec820117: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n您好！\n\n请问有什么我可以帮助您的吗？<|im_end|>\n<|im_start|>user\n你好好<|im_end|>\n<|im_start|>assistant\n感谢你的善意之言，它让我的一天更加美好。 如果您需要任何进一步的帮助，请随时告诉我！<|im_end|>\n<|im_start|>user\n使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 61176, 60391, 60477, 402, 80571, 69259, 74010, 68417, 70266, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60403, 69407, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 69894, 68364, 92039, 60424, 60923, 60353, 60741, 68678, 77558, 68708, 70485, 60355, 262, 72309, 68266, 68574, 69806, 84868, 60353, 60836, 70425, 71404, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68271, 60651, 60378, 72719, 60666, 68376, 70121, 72363, 60354, 60743, 60371, 69685, 60353, 68313, 69478, 60359, 68313, 60618, 60390, 60359, 68313, 76806, 61132, 60359, 68313, 77022, 69684, 60353, 68313, 92322, 60353, 71097, 69685, 60353, 60836, 68376, 70121, 60419, 61791, 61277, 60420, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:24:56 metrics.py:213] Avg prompt throughput: 66.4 tokens/s, Avg generation throughput: 6.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:24:57 async_llm_engine.py:110] Finished request chatcmpl-d5f43de0-61e8-4682-98db-ba39ec820117.
INFO:     10.1.96.6:59876 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
2024-03-28 22:24:59.450 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好', 'role': 'user'}, {'role': 'assistant', 'content': '您好！\n\n请问有什么我可以帮助您的吗？'}, {'content': '你好好', 'role': 'user'}, {'role': 'assistant', 'content': '感谢你的善意之言，它让我的一天更加美好。 如果您需要任何进一步的帮助，请随时告诉我！'}, {'content': '你再好', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:59864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:24:59 async_llm_engine.py:436] Received request chatcmpl-ecfb146e-5a5b-4e0a-b42b-89b736afc3d0: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好<|im_end|>\n<|im_start|>assistant\n您好！\n\n请问有什么我可以帮助您的吗？<|im_end|>\n<|im_start|>user\n你好好<|im_end|>\n<|im_start|>assistant\n感谢你的善意之言，它让我的一天更加美好。 如果您需要任何进一步的帮助，请随时告诉我！<|im_end|>\n<|im_start|>user\n你再好<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 61176, 60391, 60477, 402, 80571, 69259, 74010, 68417, 70266, 61076, 60504, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60403, 69407, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 69894, 68364, 92039, 60424, 60923, 60353, 60741, 68678, 77558, 68708, 70485, 60355, 262, 72309, 68266, 68574, 69806, 84868, 60353, 60836, 70425, 71404, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 85159, 60391, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:24:59 async_llm_engine.py:110] Finished request chatcmpl-ecfb146e-5a5b-4e0a-b42b-89b736afc3d0.
2024-03-28 22:25:04.242 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好好', 'role': 'user'}, {'role': 'assistant', 'content': '感谢你的善意之言，它让我的一天更加美好。 如果您需要任何进一步的帮助，请随时告诉我！'}, {'content': '你再好', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你再次表达对我的赞扬之情。作为一名 AI 聊天机器人，我的目标是为您提供尽可能最好的体验和准确的信息。 \n\n如果您有任何问题或任务需要我协助完成，请不要犹豫地向我提问！'}, {'content': '你三号', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:59864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:25:04 async_llm_engine.py:436] Received request chatcmpl-fb93643e-50bd-478c-887f-d8b1f1f4da17: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好好<|im_end|>\n<|im_start|>assistant\n感谢你的善意之言，它让我的一天更加美好。 如果您需要任何进一步的帮助，请随时告诉我！<|im_end|>\n<|im_start|>user\n你再好<|im_end|>\n<|im_start|>assistant\n谢谢你再次表达对我的赞扬之情。作为一名 AI 聊天机器人，我的目标是为您提供尽可能最好的体验和准确的信息。 \n\n如果您有任何问题或任务需要我协助完成，请不要犹豫地向我提问！<|im_end|>\n<|im_start|>user\n你三号<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60403, 69407, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 69894, 68364, 92039, 60424, 60923, 60353, 60741, 68678, 77558, 68708, 70485, 60355, 262, 72309, 68266, 68574, 69806, 84868, 60353, 60836, 70425, 71404, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 85159, 60391, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 87727, 68976, 69418, 77256, 61478, 61895, 82874, 60355, 83006, 15358, 262, 68960, 72396, 60353, 68306, 85734, 78267, 72703, 69714, 68954, 60381, 70378, 72021, 60355, 4872, 72309, 81488, 68287, 60535, 68565, 68266, 60363, 73165, 68360, 60353, 78709, 73866, 60415, 79439, 73912, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60403, 60479, 60675, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:25:04 metrics.py:213] Avg prompt throughput: 57.4 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:25:04 async_llm_engine.py:110] Finished request chatcmpl-fb93643e-50bd-478c-887f-d8b1f1f4da17.
2024-03-28 22:25:08.992 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你再好', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你再次表达对我的赞扬之情。作为一名 AI 聊天机器人，我的目标是为您提供尽可能最好的体验和准确的信息。 \n\n如果您有任何问题或任务需要我协助完成，请不要犹豫地向我提问！'}, {'content': '你三号', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你再次称赞我的能力！作为一名 AI 语言模型，我被设计为能够根据您提供给我的信息生成自然且连贯的响应。\n\n如您所愿，我很乐意回答您的所有问题和任务请求！'}, {'content': '好好好', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:56582 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:25:08 async_llm_engine.py:436] Received request chatcmpl-5d9690fe-9530-4b4b-8ed2-ed480b6571a3: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你再好<|im_end|>\n<|im_start|>assistant\n谢谢你再次表达对我的赞扬之情。作为一名 AI 聊天机器人，我的目标是为您提供尽可能最好的体验和准确的信息。 \n\n如果您有任何问题或任务需要我协助完成，请不要犹豫地向我提问！<|im_end|>\n<|im_start|>user\n你三号<|im_end|>\n<|im_start|>assistant\n谢谢你再次称赞我的能力！作为一名 AI 语言模型，我被设计为能够根据您提供给我的信息生成自然且连贯的响应。\n\n如您所愿，我很乐意回答您的所有问题和任务请求！<|im_end|>\n<|im_start|>user\n好好好<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 85159, 60391, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 87727, 68976, 69418, 77256, 61478, 61895, 82874, 60355, 83006, 15358, 262, 68960, 72396, 60353, 68306, 85734, 78267, 72703, 69714, 68954, 60381, 70378, 72021, 60355, 4872, 72309, 81488, 68287, 60535, 68565, 68266, 60363, 73165, 68360, 60353, 78709, 73866, 60415, 79439, 73912, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60403, 60479, 60675, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 87727, 68976, 83648, 68306, 68432, 60477, 83006, 15358, 262, 68790, 70218, 60353, 80191, 68363, 60374, 68445, 68420, 61176, 68403, 75101, 68347, 70563, 68519, 60767, 60907, 62391, 60354, 74369, 60355, 402, 91130, 60431, 61280, 60353, 70805, 81016, 68855, 70266, 68379, 89532, 68565, 72463, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 69407, 60391, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:25:09 metrics.py:213] Avg prompt throughput: 50.8 tokens/s, Avg generation throughput: 13.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:25:09 async_llm_engine.py:110] Finished request chatcmpl-5d9690fe-9530-4b4b-8ed2-ed480b6571a3.
2024-03-28 22:25:14.686 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你三号', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你再次称赞我的能力！作为一名 AI 语言模型，我被设计为能够根据您提供给我的信息生成自然且连贯的响应。\n\n如您所愿，我很乐意回答您的所有问题和任务请求！'}, {'content': '好好好', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你对我能力的认可！作为一名训练有素的、先进的对话系统，我的主要目标是协助用户完成任务，并以清晰简洁的方式回答问题。\n\n如果我有机会为您服务，请随时提出任何您认为合适的问题或任务要求！'}, {'content': '行行行', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:49066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:25:14 async_llm_engine.py:436] Received request chatcmpl-e00e6331-043e-47cc-be08-89924d8b4dee: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你三号<|im_end|>\n<|im_start|>assistant\n谢谢你再次称赞我的能力！作为一名 AI 语言模型，我被设计为能够根据您提供给我的信息生成自然且连贯的响应。\n\n如您所愿，我很乐意回答您的所有问题和任务请求！<|im_end|>\n<|im_start|>user\n好好好<|im_end|>\n<|im_start|>assistant\n谢谢你对我能力的认可！作为一名训练有素的、先进的对话系统，我的主要目标是协助用户完成任务，并以清晰简洁的方式回答问题。\n\n如果我有机会为您服务，请随时提出任何您认为合适的问题或任务要求！<|im_end|>\n<|im_start|>user\n行行行<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60403, 60479, 60675, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 87727, 68976, 83648, 68306, 68432, 60477, 83006, 15358, 262, 68790, 70218, 60353, 80191, 68363, 60374, 68445, 68420, 61176, 68403, 75101, 68347, 70563, 68519, 60767, 60907, 62391, 60354, 74369, 60355, 402, 91130, 60431, 61280, 60353, 70805, 81016, 68855, 70266, 68379, 89532, 68565, 72463, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 69407, 60391, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 87727, 69880, 74781, 71243, 60477, 83006, 69233, 60360, 79245, 60359, 74776, 68983, 68308, 60353, 68306, 68326, 85734, 73165, 68508, 77268, 60353, 81771, 70214, 73986, 69405, 85625, 60355, 402, 68263, 72049, 68863, 72048, 68320, 60353, 60836, 70425, 69549, 68574, 61176, 68551, 69197, 68804, 60535, 68565, 68456, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60412, 60412, 60412, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:25:14 metrics.py:213] Avg prompt throughput: 47.8 tokens/s, Avg generation throughput: 4.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:25:17 async_llm_engine.py:110] Finished request chatcmpl-e00e6331-043e-47cc-be08-89924d8b4dee.
2024-03-28 22:25:18.456 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '', 'role': 'system'}, {'content': '你好', 'role': 'user'}, {'role': 'assistant', 'content': '您好！\n\n请问有什么我可以帮助您的吗？'}, {'content': '你好好', 'role': 'user'}, {'role': 'assistant', 'content': '感谢你的善意之言，它让我的一天更加美好。 如果您需要任何进一步的帮助，请随时告诉我！'}, {'content': '你再好', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你再次表达对我的赞扬之情。作为一名 AI 聊天机器人，我的目标是为您提供尽可能最好的体验和准确的信息。 \n\n如果您有任何问题或任务需要我协助完成，请不要犹豫地向我提问！'}, {'content': '你三号', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你再次称赞我的能力！作为一名 AI 语言模型，我被设计为能够根据您提供给我的信息生成自然且连贯的响应。\n\n如您所愿，我很乐意回答您的所有问题和任务请求！'}, {'content': '好好好', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你对我能力的认可！作为一名训练有素的、先进的对话系统，我的主要目标是协助用户完成任务，并以清晰简洁的方式回答问题。\n\n如果我有机会为您服务，请随时提出任何您认为合适的问题或任务要求！'}, {'content': '行行行', 'role': 'user'}, {'role': 'assistant', 'content': '很高兴为您提供帮助！以下是一些可能对您有用的提示：\n\n1. **探索主题** - 如果您正在寻找有关特定主题的信息，可以通过在搜索引擎中输入相关关键字来开始探索该主题。这将为您提供与该主题相关的文章、研究论文和其他资源的链接列表。\n\n2. **利用在线资源** - 除了搜索引擎之外，还有许多其他在线资源可用于查找各种类型的主题和问题的信息。其中一些流行网站包括维基百科（Wikipedia）、TED Talks、YouTube Edited、Coursera 和 Udemy。这些平台提供了广泛的课程、讲座、演示和其他教育内容，涵盖了广泛的主题和专业领域。\n\n3. **向专家咨询** - 如果您需要某个具体问题或任务的深入指导或建议，最好直接联系在该领域的专家寻求他们的专业知识。这可以采取多种形式，例如访问当地图书馆并浏览其馆藏以获取相关信息；联系行业协会或其他组织，看看他们是否有关于此事的资源或指南；或者，通过 LinkedIn 等社交媒体平台搜索在该领域工作的专业人士，并通过电子邮件或其他方式直接联系他们并询问他们的意见或建议。\n\n希望这些技巧对您有所帮助！如果您还有任何其他问题或疑虑，请随时告诉我！'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:49070 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:25:18 async_llm_engine.py:436] Received request chatcmpl-7722314e-8ecd-4225-956d-14981b3b0465: prompt: '<s><|im_start|>system\n<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:25:19 metrics.py:213] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 75.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
2024-03-28 22:25:22.881 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '好好好', 'role': 'user'}, {'role': 'assistant', 'content': '谢谢你对我能力的认可！作为一名训练有素的、先进的对话系统，我的主要目标是协助用户完成任务，并以清晰简洁的方式回答问题。\n\n如果我有机会为您服务，请随时提出任何您认为合适的问题或任务要求！'}, {'content': '行行行', 'role': 'user'}, {'role': 'assistant', 'content': '很高兴为您提供帮助！以下是一些可能对您有用的提示：\n\n1. **探索主题** - 如果您正在寻找有关特定主题的信息，可以通过在搜索引擎中输入相关关键字来开始探索该主题。这将为您提供与该主题相关的文章、研究论文和其他资源的链接列表。\n\n2. **利用在线资源** - 除了搜索引擎之外，还有许多其他在线资源可用于查找各种类型的主题和问题的信息。其中一些流行网站包括维基百科（Wikipedia）、TED Talks、YouTube Edited、Coursera 和 Udemy。这些平台提供了广泛的课程、讲座、演示和其他教育内容，涵盖了广泛的主题和专业领域。\n\n3. **向专家咨询** - 如果您需要某个具体问题或任务的深入指导或建议，最好直接联系在该领域的专家寻求他们的专业知识。这可以采取多种形式，例如访问当地图书馆并浏览其馆藏以获取相关信息；联系行业协会或其他组织，看看他们是否有关于此事的资源或指南；或者，通过 LinkedIn 等社交媒体平台搜索在该领域工作的专业人士，并通过电子邮件或其他方式直接联系他们并询问他们的意见或建议。\n\n希望这些技巧对您有所帮助！如果您还有任何其他问题或疑虑，请随时告诉我！'}, {'content': '好吧', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:58302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:25:22 async_llm_engine.py:436] Received request chatcmpl-e8c1d68e-278d-4c9e-9e80-ba0132da66c5: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n好好好<|im_end|>\n<|im_start|>assistant\n谢谢你对我能力的认可！作为一名训练有素的、先进的对话系统，我的主要目标是协助用户完成任务，并以清晰简洁的方式回答问题。\n\n如果我有机会为您服务，请随时提出任何您认为合适的问题或任务要求！<|im_end|>\n<|im_start|>user\n行行行<|im_end|>\n<|im_start|>assistant\n很高兴为您提供帮助！以下是一些可能对您有用的提示：\n\n1. **探索主题** - 如果您正在寻找有关特定主题的信息，可以通过在搜索引擎中输入相关关键字来开始探索该主题。这将为您提供与该主题相关的文章、研究论文和其他资源的链接列表。\n\n2. **利用在线资源** - 除了搜索引擎之外，还有许多其他在线资源可用于查找各种类型的主题和问题的信息。其中一些流行网站包括维基百科（Wikipedia）、TED Talks、YouTube Edited、Coursera 和 Udemy。这些平台提供了广泛的课程、讲座、演示和其他教育内容，涵盖了广泛的主题和专业领域。\n\n3. **向专家咨询** - 如果您需要某个具体问题或任务的深入指导或建议，最好直接联系在该领域的专家寻求他们的专业知识。这可以采取多种形式，例如访问当地图书馆并浏览其馆藏以获取相关信息；联系行业协会或其他组织，看看他们是否有关于此事的资源或指南；或者，通过 LinkedIn 等社交媒体平台搜索在该领域工作的专业人士，并通过电子邮件或其他方式直接联系他们并询问他们的意见或建议。\n\n希望这些技巧对您有所帮助！如果您还有任何其他问题或疑虑，请随时告诉我！<|im_end|>\n<|im_start|>user\n好吧<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 69407, 60391, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 87727, 69880, 74781, 71243, 60477, 83006, 69233, 60360, 79245, 60359, 74776, 68983, 68308, 60353, 68306, 68326, 85734, 73165, 68508, 77268, 60353, 81771, 70214, 73986, 69405, 85625, 60355, 402, 68263, 72049, 68863, 72048, 68320, 60353, 60836, 70425, 69549, 68574, 61176, 68551, 69197, 68804, 60535, 68565, 68456, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60412, 60412, 60412, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 86955, 78267, 68417, 60477, 73622, 68315, 68295, 75436, 81697, 68806, 60387, 402, 312, 281, 3235, 70675, 69685, 465, 612, 262, 72309, 69202, 69899, 69045, 73295, 69685, 72021, 60353, 70357, 60361, 76340, 71417, 68524, 81850, 60383, 68301, 70675, 60658, 69685, 60355, 60376, 60530, 78267, 60510, 60658, 69685, 70709, 68786, 60359, 68346, 69526, 71842, 82017, 69675, 69180, 60355, 402, 314, 281, 3235, 68685, 69627, 68711, 465, 612, 262, 68632, 76340, 69649, 60353, 91535, 68345, 69627, 68711, 81826, 70854, 68459, 68517, 76693, 60381, 70670, 68347, 60355, 68415, 68315, 70402, 68729, 68469, 60909, 60630, 74160, 60414, 325, 15067, 60413, 60359, 33557, 19132, 269, 60359, 52789, 3365, 1755, 60359, 42874, 932, 264, 262, 60381, 678, 273, 4686, 60355, 68374, 68561, 70572, 82747, 69218, 60359, 79304, 60359, 69580, 71842, 68410, 68341, 60353, 88530, 70073, 76693, 60381, 68388, 69052, 60355, 402, 308, 281, 3235, 60691, 69212, 69127, 465, 612, 262, 72309, 68266, 71014, 68592, 68287, 60535, 87991, 70354, 69343, 60535, 68571, 60353, 68681, 68376, 68795, 73826, 75020, 69212, 74625, 69291, 82926, 60355, 60376, 68251, 70714, 69326, 69048, 60353, 69192, 70501, 69888, 71285, 60573, 68864, 60451, 86959, 60367, 69464, 79848, 60506, 68795, 68611, 69472, 76531, 68591, 60353, 68518, 68310, 72504, 68716, 60603, 77108, 68711, 60535, 71338, 60506, 68319, 60353, 68330, 32888, 262, 60455, 70646, 69171, 68561, 68699, 73826, 69052, 70693, 82173, 60353, 83707, 84619, 76531, 68386, 68376, 68795, 68310, 60573, 73477, 69291, 70126, 60535, 68571, 60355, 402, 68397, 68374, 69150, 91661, 60477, 72309, 68350, 68574, 68345, 68287, 60535, 61499, 61524, 60353, 60836, 70425, 71404, 60477, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 73243, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:25:23 async_llm_engine.py:110] Finished request chatcmpl-7722314e-8ecd-4225-956d-14981b3b0465.
INFO 03-28 22:25:24 async_llm_engine.py:110] Finished request chatcmpl-e8c1d68e-278d-4c9e-9e80-ba0132da66c5.
2024-03-28 22:25:54.199 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好，给我讲个故事', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:51482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:25:54 async_llm_engine.py:436] Received request chatcmpl-746aa72a-60b1-4c99-9c9d-b83cce772106: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好，给我讲个故事<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 60353, 68706, 61077, 60365, 68654, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:25:54 metrics.py:213] Avg prompt throughput: 16.6 tokens/s, Avg generation throughput: 15.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:25:56 async_llm_engine.py:110] Finished request chatcmpl-746aa72a-60b1-4c99-9c9d-b83cce772106.
2024-03-28 22:25:57.377 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '', 'role': 'system'}, {'content': '你好，给我讲个故事', 'role': 'user'}, {'role': 'assistant', 'content': '从前有一只小鱼，它一直梦想着探索海洋深处。有一天，小鱼遇到了一位智慧的老龟，老龟告诉小鱼：“如果你想实现你的梦想，你必须勇敢地面对未知的深海世界。”\n\n小鱼听了老龟的话后，决定踏上探险之旅。一路上，小鱼经历了许多困难和挑战，包括遇到凶猛的天敌、遭遇剧烈的水流等等。\n\n但是，小鱼并没有放弃自己的梦想。相反，每当面临困境时，小鱼总是充满信心地说道：“我相信我可以克服任何障碍！”\n\n就这样，小鱼凭借着坚韧不拔的精神和不屈服于困难的决心，终于到达了深海世界的尽头。在那里，小鱼发现了无数奇妙的生物和壮丽的景色，并意识到它的梦想已经真正实现了。\n\n从此以后，小鱼每年都会回到深海世界的尽头，与那里的神奇生物们一起分享它们的喜悦和冒险经历。而这一切，都源于那只勇敢的小鱼不屈不挠的努力追求自己的梦想的故事。'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:51496 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:25:57 async_llm_engine.py:436] Received request chatcmpl-ab04bd2d-9d7a-4ff5-967d-45bdcaf9c5d0: prompt: '<s><|im_start|>system\n<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
2024-03-28 22:25:57.606 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': False, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好，给我讲个故事', 'role': 'user'}, {'role': 'assistant', 'content': '从前有一只小鱼，它一直梦想着探索海洋深处。有一天，小鱼遇到了一位智慧的老龟，老龟告诉小鱼：“如果你想实现你的梦想，你必须勇敢地面对未知的深海世界。”\n\n小鱼听了老龟的话后，决定踏上探险之旅。一路上，小鱼经历了许多困难和挑战，包括遇到凶猛的天敌、遭遇剧烈的水流等等。\n\n但是，小鱼并没有放弃自己的梦想。相反，每当面临困境时，小鱼总是充满信心地说道：“我相信我可以克服任何障碍！”\n\n就这样，小鱼凭借着坚韧不拔的精神和不屈服于困难的决心，终于到达了深海世界的尽头。在那里，小鱼发现了无数奇妙的生物和壮丽的景色，并意识到它的梦想已经真正实现了。\n\n从此以后，小鱼每年都会回到深海世界的尽头，与那里的神奇生物们一起分享它们的喜悦和冒险经历。而这一切，都源于那只勇敢的小鱼不屈不挠的努力追求自己的梦想的故事。'}, {'content': '使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”', 'role': 'user'}], 'echo': False}
INFO 03-28 22:25:57 async_llm_engine.py:436] Received request chatcmpl-401d8dca-79c4-47bb-a5cd-892b37907166: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好，给我讲个故事<|im_end|>\n<|im_start|>assistant\n从前有一只小鱼，它一直梦想着探索海洋深处。有一天，小鱼遇到了一位智慧的老龟，老龟告诉小鱼：“如果你想实现你的梦想，你必须勇敢地面对未知的深海世界。”\n\n小鱼听了老龟的话后，决定踏上探险之旅。一路上，小鱼经历了许多困难和挑战，包括遇到凶猛的天敌、遭遇剧烈的水流等等。\n\n但是，小鱼并没有放弃自己的梦想。相反，每当面临困境时，小鱼总是充满信心地说道：“我相信我可以克服任何障碍！”\n\n就这样，小鱼凭借着坚韧不拔的精神和不屈服于困难的决心，终于到达了深海世界的尽头。在那里，小鱼发现了无数奇妙的生物和壮丽的景色，并意识到它的梦想已经真正实现了。\n\n从此以后，小鱼每年都会回到深海世界的尽头，与那里的神奇生物们一起分享它们的喜悦和冒险经历。而这一切，都源于那只勇敢的小鱼不屈不挠的努力追求自己的梦想的故事。<|im_end|>\n<|im_start|>user\n使用四到五个字直接返回这句话的简要主题，不要解释、不要标点、不要语气词、不要多余文本，不要加粗，如果没有主题，请直接返回“闲聊”<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 60353, 68706, 61077, 60365, 68654, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 78115, 68510, 60539, 81044, 60353, 60741, 68399, 61320, 70282, 70675, 71309, 77178, 60355, 70619, 60353, 81044, 73291, 70226, 70172, 71846, 62968, 60353, 60607, 62968, 68703, 81044, 60387, 60419, 79584, 68651, 68364, 70320, 60353, 86033, 73325, 60415, 69116, 72213, 60354, 81938, 68339, 60355, 60420, 402, 81044, 77195, 60607, 62968, 68396, 60375, 60353, 68792, 85545, 79113, 74745, 60355, 88811, 60353, 81044, 74826, 68867, 69689, 60381, 69879, 60353, 68469, 68713, 62899, 62552, 71859, 61697, 60359, 73504, 78539, 69602, 60673, 68811, 60355, 402, 68276, 60353, 81044, 69673, 69742, 68304, 70320, 60355, 72421, 60353, 78599, 71634, 79309, 60377, 60353, 81044, 68965, 69911, 72287, 74063, 60469, 60387, 60419, 74913, 74010, 75185, 68574, 71139, 60477, 60420, 402, 70963, 60353, 81044, 72257, 60486, 89992, 60358, 61607, 75383, 78719, 62402, 60639, 60418, 88706, 74187, 60353, 69426, 70420, 60362, 81938, 72168, 81785, 60355, 76667, 60353, 81044, 72186, 70925, 61112, 75060, 69025, 60381, 62229, 75266, 77785, 60353, 60573, 73329, 68957, 70320, 68329, 68866, 74114, 60355, 402, 71190, 68458, 60353, 81044, 69731, 68549, 69163, 81938, 72168, 81785, 60353, 60510, 92097, 71866, 69025, 60400, 88830, 78591, 79725, 60381, 72289, 68823, 60355, 60458, 75118, 60353, 60406, 73126, 87964, 73325, 68447, 61028, 91724, 60358, 64199, 83998, 69465, 68304, 70320, 70455, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 68271, 60651, 60378, 72719, 60666, 68376, 70121, 72363, 60354, 60743, 60371, 69685, 60353, 68313, 69478, 60359, 68313, 60618, 60390, 60359, 68313, 76806, 61132, 60359, 68313, 77022, 69684, 60353, 68313, 92322, 60353, 71097, 69685, 60353, 60836, 68376, 70121, 60419, 61791, 61277, 60420, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:25:57 async_llm_engine.py:110] Finished request chatcmpl-401d8dca-79c4-47bb-a5cd-892b37907166.
INFO:     10.1.96.6:51512 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:25:59 metrics.py:213] Avg prompt throughput: 80.4 tokens/s, Avg generation throughput: 76.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
2024-03-28 22:26:01.164 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '你好，给我讲个故事', 'role': 'user'}, {'role': 'assistant', 'content': '从前有一只小鱼，它一直梦想着探索海洋深处。有一天，小鱼遇到了一位智慧的老龟，老龟告诉小鱼：“如果你想实现你的梦想，你必须勇敢地面对未知的深海世界。”\n\n小鱼听了老龟的话后，决定踏上探险之旅。一路上，小鱼经历了许多困难和挑战，包括遇到凶猛的天敌、遭遇剧烈的水流等等。\n\n但是，小鱼并没有放弃自己的梦想。相反，每当面临困境时，小鱼总是充满信心地说道：“我相信我可以克服任何障碍！”\n\n就这样，小鱼凭借着坚韧不拔的精神和不屈服于困难的决心，终于到达了深海世界的尽头。在那里，小鱼发现了无数奇妙的生物和壮丽的景色，并意识到它的梦想已经真正实现了。\n\n从此以后，小鱼每年都会回到深海世界的尽头，与那里的神奇生物们一起分享它们的喜悦和冒险经历。而这一切，都源于那只勇敢的小鱼不屈不挠的努力追求自己的梦想的故事。'}, {'content': '再讲一个', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:48006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:26:01 async_llm_engine.py:436] Received request chatcmpl-889c37f3-e913-4654-b7a1-1f95a8085ded: prompt: '<s><|im_start|>system\nYou are an AI Chemist assistant whose name is ChemLLM (浦科·浦语).\n- ChemLLM (浦科·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be truthworthy, sophiscated, and Chemical-centric.\n<|im_end|>\n<|im_start|>user\n你好，给我讲个故事<|im_end|>\n<|im_start|>assistant\n从前有一只小鱼，它一直梦想着探索海洋深处。有一天，小鱼遇到了一位智慧的老龟，老龟告诉小鱼：“如果你想实现你的梦想，你必须勇敢地面对未知的深海世界。”\n\n小鱼听了老龟的话后，决定踏上探险之旅。一路上，小鱼经历了许多困难和挑战，包括遇到凶猛的天敌、遭遇剧烈的水流等等。\n\n但是，小鱼并没有放弃自己的梦想。相反，每当面临困境时，小鱼总是充满信心地说道：“我相信我可以克服任何障碍！”\n\n就这样，小鱼凭借着坚韧不拔的精神和不屈服于困难的决心，终于到达了深海世界的尽头。在那里，小鱼发现了无数奇妙的生物和壮丽的景色，并意识到它的梦想已经真正实现了。\n\n从此以后，小鱼每年都会回到深海世界的尽头，与那里的神奇生物们一起分享它们的喜悦和冒险经历。而这一切，都源于那只勇敢的小鱼不屈不挠的努力追求自己的梦想的故事。<|im_end|>\n<|im_start|>user\n再讲一个<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 2770, 657, 589, 15358, 19149, 510, 17993, 6843, 963, 505, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 4452, 285, 19149, 4245, 307, 451, 62442, 60601, 60721, 62442, 60752, 313, 505, 395, 7659, 1813, 4287, 1762, 560, 505, 8020, 684, 36956, 15358, 31288, 451, 68589, 76659, 71581, 699, 1226, 505, 6342, 442, 517, 8179, 42179, 328, 18846, 3588, 788, 328, 454, 35311, 21440, 2367, 756, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 77230, 60353, 68706, 61077, 60365, 68654, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364, 78115, 68510, 60539, 81044, 60353, 60741, 68399, 61320, 70282, 70675, 71309, 77178, 60355, 70619, 60353, 81044, 73291, 70226, 70172, 71846, 62968, 60353, 60607, 62968, 68703, 81044, 60387, 60419, 79584, 68651, 68364, 70320, 60353, 86033, 73325, 60415, 69116, 72213, 60354, 81938, 68339, 60355, 60420, 402, 81044, 77195, 60607, 62968, 68396, 60375, 60353, 68792, 85545, 79113, 74745, 60355, 88811, 60353, 81044, 74826, 68867, 69689, 60381, 69879, 60353, 68469, 68713, 62899, 62552, 71859, 61697, 60359, 73504, 78539, 69602, 60673, 68811, 60355, 402, 68276, 60353, 81044, 69673, 69742, 68304, 70320, 60355, 72421, 60353, 78599, 71634, 79309, 60377, 60353, 81044, 68965, 69911, 72287, 74063, 60469, 60387, 60419, 74913, 74010, 75185, 68574, 71139, 60477, 60420, 402, 70963, 60353, 81044, 72257, 60486, 89992, 60358, 61607, 75383, 78719, 62402, 60639, 60418, 88706, 74187, 60353, 69426, 70420, 60362, 81938, 72168, 81785, 60355, 76667, 60353, 81044, 72186, 70925, 61112, 75060, 69025, 60381, 62229, 75266, 77785, 60353, 60573, 73329, 68957, 70320, 68329, 68866, 74114, 60355, 402, 71190, 68458, 60353, 81044, 69731, 68549, 69163, 81938, 72168, 81785, 60353, 60510, 92097, 71866, 69025, 60400, 88830, 78591, 79725, 60381, 72289, 68823, 60355, 60458, 75118, 60353, 60406, 73126, 87964, 73325, 68447, 61028, 91724, 60358, 64199, 83998, 69465, 68304, 70320, 70455, 60355, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 1008, 364, 60574, 61077, 68252, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:26:02 async_llm_engine.py:110] Finished request chatcmpl-ab04bd2d-9d7a-4ff5-967d-45bdcaf9c5d0.
INFO 03-28 22:26:04 metrics.py:213] Avg prompt throughput: 67.8 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 03-28 22:26:04 async_llm_engine.py:110] Finished request chatcmpl-889c37f3-e913-4654-b7a1-1f95a8085ded.
2024-03-28 22:26:05.972 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': '我们之前聊了：\nHere\'s a poem inspired by your prompt:\n\n**The Whispering Willows**\n\nIn the heart of an ancient grove,\nThere stood tall and proud, five whispering willow trees.\nTheir branches stretched high above their heads in graceful arches.\n\nThese majestic giants whispered secrets to each other with every gentle breeze that passed through them. Their whispers were so soft it was as if they spoke directly into one’s ear without saying anything at all!\n\nAs I wandered beneath these enchantingly mysterious beings; my mind began wandering too: “What stories do you keep? What mysteries lay hidden deep within those gnarled trunks?"\n\nBut then again perhaps there are no answers here - only endless tales being told between lovers whose romance has spanned centuries...and still continues today! \n\nSo let us continue our journey together under this magnificent canopy!\n \n~By **Lisa Adele Davis (Davis)**\n\n---\n\nThank You for using [my service](https://www.fancy-jacket.com/)! If any more prompts inspire something creative from inside yourself or just tickles some neurons somewhere else on Earth ;), please don\'t hesitate sharing another exciting idea/theme/prompt/etc.! The possibilities truly *are* limitless after-all :-)  \n\nHave fun exploring new worlds full-of-wonders & mystery-inspirations-just-for-you-only-that-one-time-ever-in-history!! :-D\n \nIf ever need me anytime anywhere future past present... Just say "Hi!" via email ([email protected]), DM (@davidjacksonartwork ), snail mail (*[My Address Here]**)  or even old fashion telegram messaging services (!)[^Telegraph](*`http://telegramservice.com/*`) ]{} :)\n\nAll best wishes,\n\nDavid J Jackson Art Workz™️ \n\n\n[^Telegraph]: For nostalgic amusement purposes <3 :)  \n    [image.png](attachment:image.png)\n\n---\n\n\nTitle | Author(s)\n--------|-----------\nWhisper\\_of\\_the%20Willowing %2C(Willos)%23;sdfghijklmnopqrstuvwxyz |\n~~~~~~~~~~~\\(✿◟̽◞̽✿)_~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~.Reflective.Realistic.Riveting.Radical.RichlyRomanticRomanticallyRoughlyRuggedRelaxedRespectfullyRestlesslyRenownedRevelatoryRevolutionaryRighteouslyRobustRollerCoasterRoaringRoundaboutRunway', 'role': 'system'}, {'content': '再讲一个', 'role': 'user'}, {'role': 'assistant', 'content': '好的，为您讲述另外一个故事。从前，在一个美丽的山谷里住着一只名叫米娅的勇敢小鸟。米娅非常喜欢探索山谷中的新地方，并且经常在她的日记中记录下这些新的发现。\n\n有一天，当米娅正在探索山谷底部的一个神秘洞穴时，她突然发现自己被困在了里面！由于黑暗笼罩着她，而且出口似乎被关闭了，所以米娅感到非常害怕和无助。不过，她在心里默默地鼓励着自己：“不要害怕，你可以找到出路！”\n\n于是，米娅开始了一场惊心动魄的冒险之旅。在寻找出口的过程中，她遇到了各种各样的危险和挑战，比如陡峭的悬崖、汹涌的河流、恐怖的陷阱等等。然而，每一次危机过后，米娅总会变得更加坚强，更加自信，也更加热爱生活。\n\n经过漫长而又艰辛的路程之后，米娅终于找到了走出那个神秘洞穴的方法。当她从洞口飞出来的时候，迎接她的是一片明媚的阳光和一个令人惊叹的美景——整个山谷都被鲜花覆盖着，远处的山峰显得格外雄伟壮观，仿佛整个大自然都在为米娅庆祝这场胜利的到来！\n\n从那一天起，米娅成为了整个山谷中最勇敢的小鸟之一，也被人们誉为“最勇敢的小鸟”称号。每当有人提起这个名字的时候，他们总是会想起那位曾经为了追寻自由和勇气而勇闯险境的小鸟的名字——米娅。'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:51496 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:26:05 async_llm_engine.py:436] Received request chatcmpl-ac365f49-5023-4a98-84a7-ee767b680ad4: prompt: '<s><|im_start|>system\n我们之前聊了：\nHere\'s a poem inspired by your prompt:\n\n**The Whispering Willows**\n\nIn the heart of an ancient grove,\nThere stood tall and proud, five whispering willow trees.\nTheir branches stretched high above their heads in graceful arches.\n\nThese majestic giants whispered secrets to each other with every gentle breeze that passed through them. Their whispers were so soft it was as if they spoke directly into one’s ear without saying anything at all!\n\nAs I wandered beneath these enchantingly mysterious beings; my mind began wandering too: “What stories do you keep? What mysteries lay hidden deep within those gnarled trunks?"\n\nBut then again perhaps there are no answers here - only endless tales being told between lovers whose romance has spanned centuries...and still continues today! \n\nSo let us continue our journey together under this magnificent canopy!\n \n~By **Lisa Adele Davis (Davis)**\n\n---\n\nThank You for using [my service](https://www.fancy-jacket.com/)! If any more prompts inspire something creative from inside yourself or just tickles some neurons somewhere else on Earth ;), please don\'t hesitate sharing another exciting idea/theme/prompt/etc.! The possibilities truly *are* limitless after-all :-)  \n\nHave fun exploring new worlds full-of-wonders & mystery-inspirations-just-for-you-only-that-one-time-ever-in-history!! :-D\n \nIf ever need me anytime anywhere future past present... Just say "Hi!" via email ([email protected]), DM (@davidjacksonartwork ), snail mail (*[My Address Here]**)  or even old fashion telegram messaging services (!)[^Telegraph](*`http://telegramservice.com/*`) ]{} :)\n\nAll best wishes,\n\nDavid J Jackson Art Workz™️ \n\n\n[^Telegraph]: For nostalgic amusement purposes <3 :)  \n    [image.png](attachment:image.png)\n\n---\n\n\nTitle | Author(s)\n--------|-----------\nWhisper\\_of\\_the%20Willowing %2C(Willos)%23;sdfghijklmnopqrstuvwxyz |\n~~~~~~~~~~~\\(✿◟̽◞̽✿)_~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~.Reflective.Realistic.Riveting.Radical.RichlyRomanticRomanticallyRoughlyRuggedRelaxedRespectfullyRestlesslyRenownedRevelatoryRevolutionaryRighteouslyRobustRollerCoasterRoaringRoundaboutRunway<|im_end|>\n<|im_start|>assistant\n', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 8554, 725, 395, 32914, 14739, 684, 829, 10069, 1593, 465, 918, 1378, 27760, 418, 5000, 4399, 55098, 772, 410, 4908, 446, 589, 13976, 10625, 717, 476, 4017, 14771, 16349, 454, 12559, 328, 4393, 34863, 418, 818, 494, 12558, 756, 34807, 23417, 40048, 1695, 3565, 998, 14762, 435, 21049, 1409, 5484, 419, 512, 9614, 24328, 9962, 44722, 56124, 23947, 442, 1966, 1148, 579, 1595, 21947, 44796, 560, 5977, 1672, 1248, 281, 11114, 551, 13235, 518, 1176, 906, 8547, 563, 703, 569, 552, 941, 12441, 6115, 1263, 959, 61974, 269, 2582, 2192, 5646, 4271, 650, 810, 2370, 2275, 489, 39014, 422, 24345, 1639, 46346, 11460, 25821, 23297, 329, 983, 4128, 6163, 52994, 2389, 334, 262, 60419, 3993, 7489, 784, 629, 2662, 345, 3716, 55497, 11112, 8311, 5694, 3042, 1995, 38445, 408, 966, 620, 15420, 12125, 4139, 1367, 1694, 8498, 1194, 657, 1038, 11404, 1734, 612, 1317, 26122, 36402, 1810, 3392, 2100, 32276, 6843, 29566, 834, 9517, 18840, 23987, 1255, 568, 2210, 9671, 3514, 346, 4872, 4578, 1219, 732, 3225, 1181, 11771, 3942, 1358, 550, 40432, 777, 1413, 5052, 848, 351, 1505, 3235, 303, 10910, 493, 581, 404, 16913, 451, 302, 22637, 32444, 402, 43916, 13206, 1592, 500, 1817, 640, 2562, 2627, 9665, 2580, 1253, 2290, 967, 6725, 13473, 5862, 1042, 301, 41006, 1562, 1030, 937, 50120, 30868, 2650, 11676, 635, 4928, 6286, 607, 1244, 9469, 773, 1187, 33310, 14827, 902, 519, 9370, 2747, 833, 4648, 1658, 1082, 38393, 11714, 2595, 13386, 4684, 39837, 4482, 14878, 46462, 59974, 707, 23961, 9556, 484, 677, 297, 4087, 1867, 1428, 22629, 21165, 313, 18756, 12270, 2618, 24341, 632, 24227, 2634, 8801, 2790, 27706, 741, 22821, 22111, 5720, 938, 285, 4407, 15317, 44921, 15507, 7704, 397, 18735, 7393, 55346, 3580, 59997, 3093, 680, 9548, 27223, 2841, 3673, 1329, 884, 29405, 12530, 4008, 3430, 3207, 1255, 4760, 2127, 461, 13195, 9091, 4729, 2708, 11892, 2484, 2777, 9855, 20373, 8139, 273, 15335, 326, 19555, 602, 1930, 7034, 4290, 736, 8205, 4770, 336, 5211, 9307, 5846, 332, 41621, 387, 400, 1642, 2460, 11304, 8099, 1666, 29806, 3677, 1650, 6772, 353, 21885, 4601, 332, 4230, 350, 1401, 1253, 15533, 1666, 8073, 1042, 1199, 32993, 2431, 6413, 32752, 2557, 1999, 24630, 3715, 22565, 751, 13800, 5325, 5703, 320, 66267, 63115, 14862, 38628, 21885, 4601, 5824, 1904, 44607, 423, 59991, 10030, 497, 308, 26395, 2454, 388, 336, 1954, 3669, 9665, 22249, 37542, 3669, 824, 4583, 1552, 4006, 892, 7038, 1285, 471, 645, 352, 26350, 1787, 27760, 272, 3736, 272, 16198, 344, 638, 10081, 23514, 1159, 314, 289, 14169, 452, 2452, 24259, 1540, 39201, 3105, 1002, 58484, 22026, 584, 60345, 12210, 293, 29175, 9381, 18030, 5971, 351, 43848, 229, 159, 194, 229, 154, 162, 207, 192, 229, 154, 161, 207, 192, 229, 159, 194, 26369, 32677, 10449, 4125, 32677, 18522, 899, 664, 2981, 409, 4694, 2163, 475, 11772, 2163, 460, 1076, 2163, 846, 528, 43912, 8293, 43912, 649, 2835, 296, 1530, 528, 296, 20322, 6890, 50605, 1203, 1127, 3802, 12566, 15872, 34645, 18486, 825, 1025, 5428, 36128, 3379, 789, 6133, 261, 7167, 14603, 721, 32500, 392, 7485, 2451, 38682, 3412, 27882, 9226, 6877, 3284, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
2024-03-28 22:26:09.124 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': "我们之前聊了：\n---\nTitle        themed title based off input text given earlier.*(`original_text`*)*\nAuthor       author name formatted according author naming conventions used throughout history.*\n*[referencing multiple authors is possible]**\n\n---\nOriginal Text:\n-----------\n\nTitle         **Whisper \\of\\\n                the {W}illowing,{Wil}\n                  lors}{%#%^&'()*+,-./0123456789:AaBbCCcCDDeEfFGgHhHIJkKLmMnOpqRRSTTUUVVWWXYyZ}${(%#%^&'*()()+,*-.*/01(234)(567))(A(a", 'role': 'system'}, {'content': '你好，给我讲个故事', 'role': 'user'}, {'role': 'assistant', 'content': '从前有一只小鱼，它一直梦想着探索海洋深处。有一天，小鱼遇到了一位智慧的老龟，老龟告诉小鱼：“如果你想实现你的梦想，你必须勇敢地面对未知的深海世界。”\n\n小鱼听了老龟的话后，决定踏上探险之旅。一路上，小鱼经历了许多困难和挑战，包括遇到凶猛的天敌、遭遇剧烈的水流等等。\n\n但是，小鱼并没有放弃自己的梦想。相反，每当面临困境时，小鱼总是充满信心地说道：“我相信我可以克服任何障碍！”\n\n就这样，小鱼凭借着坚韧不拔的精神和不屈服于困难的决心，终于到达了深海世界的尽头。在那里，小鱼发现了无数奇妙的生物和壮丽的景色，并意识到它的梦想已经真正实现了。\n\n从此以后，小鱼每年都会回到深海世界的尽头，与那里的神奇生物们一起分享它们的喜悦和冒险经历。而这一切，都源于那只勇敢的小鱼不屈不挠的努力追求自己的梦想的故事。'}, {'content': '再讲一个', 'role': 'user'}, {'role': 'assistant', 'content': '好的，为您讲述另外一个故事。从前，在一个美丽的山谷里住着一只名叫米娅的勇敢小鸟。米娅非常喜欢探索山谷中的新地方，并且经常在她的日记中记录下这些新的发现。\n\n有一天，当米娅正在探索山谷底部的一个神秘洞穴时，她突然发现自己被困在了里面！由于黑暗笼罩着她，而且出口似乎被关闭了，所以米娅感到非常害怕和无助。不过，她在心里默默地鼓励着自己：“不要害怕，你可以找到出路！”\n\n于是，米娅开始了一场惊心动魄的冒险之旅。在寻找出口的过程中，她遇到了各种各样的危险和挑战，比如陡峭的悬崖、汹涌的河流、恐怖的陷阱等等。然而，每一次危机过后，米娅总会变得更加坚强，更加自信，也更加热爱生活。\n\n经过漫长而又艰辛的路程之后，米娅终于找到了走出那个神秘洞穴的方法。当她从洞口飞出来的时候，迎接她的是一片明媚的阳光和一个令人惊叹的美景——整个山谷都被鲜花覆盖着，远处的山峰显得格外雄伟壮观，仿佛整个大自然都在为米娅庆祝这场胜利的到来！\n\n从那一天起，米娅成为了整个山谷中最勇敢的小鸟之一，也被人们誉为“最勇敢的小鸟”称号。每当有人提起这个名字的时候，他们总是会想起那位曾经为了追寻自由和勇气而勇闯险境的小鸟的名字——米娅。'}, {'content': '再讲一个', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:48006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:26:09 async_llm_engine.py:436] Received request chatcmpl-dbf99562-a9cf-4a32-9c05-9090b7199c91: prompt: "<s><|im_start|>system\n我们之前聊了：\n---\nTitle        themed title based off input text given earlier.*(`original_text`*)*\nAuthor       author name formatted according author naming conventions used throughout history.*\n*[referencing multiple authors is possible]**\n\n---\nOriginal Text:\n-----------\n\nTitle         **Whisper \\of\\\n                the {W}illowing,{Wil}\n                  lors}{%#%^&'()*+,-./0123456789:AaBbCCcCDDeEfFGgHhHIJkKLmMnOpqRRSTTUUVVWWXYyZ}${(%#%^&'*()()+,*-.*/01(234)(567))(A(a<|im_end|>\n<|im_start|>assistant\n", prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 11102, 4006, 391, 470, 16539, 2416, 3285, 1147, 2098, 1614, 2823, 6939, 5066, 5962, 10024, 4486, 350, 3924, 5774, 7282, 417, 3259, 963, 23455, 4251, 3316, 34953, 44040, 1629, 6965, 3995, 30921, 53293, 40875, 11525, 5408, 12166, 505, 3369, 332, 55098, 11102, 18549, 3083, 642, 53225, 4006, 820, 465, 1787, 27760, 1268, 1197, 5816, 469, 1934, 445, 325, 335, 614, 23514, 28206, 51486, 663, 4453, 270, 1229, 15292, 344, 324, 45380, 348, 259, 25439, 342, 5158, 1876, 300, 4575, 10877, 16217, 54601, 264, 309, 260, 3866, 271, 6640, 2062, 288, 283, 12153, 279, 318, 280, 24283, 338, 292, 52062, 277, 307, 265, 7274, 327, 8240, 917, 291, 315, 22525, 322, 19141, 16490, 282, 349, 31393, 15361, 324, 45380, 348, 42865, 499, 17280, 28367, 14659, 1961, 1836, 298, 11622, 2530, 18908, 724, 4506, 3041, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:26:09 metrics.py:213] Avg prompt throughput: 140.8 tokens/s, Avg generation throughput: 64.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:26:11 async_llm_engine.py:110] Finished request chatcmpl-ac365f49-5023-4a98-84a7-ee767b680ad4.
INFO 03-28 22:26:14 metrics.py:213] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 135.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:26:14 async_llm_engine.py:110] Finished request chatcmpl-dbf99562-a9cf-4a32-9c05-9090b7199c91.
2024-03-28 22:26:15.802 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': "我们之前聊了：\n---\nTitle        themed title based off input text given earlier.*(`original_text`*)*\nAuthor       author name formatted according author naming conventions used throughout history.*\n*[referencing multiple authors is possible]**\n\n---\nOriginal Text:\n-----------\n\nTitle         **Whisper \\of\\\n                the {W}illowing,{Wil}\n                  lors}{%#%^&'()*+,-./0123456789:AaBbCCcCDDeEfFGgHhHIJkKLmMnOpqRRSTTUUVVWWXYyZ}${(%#%^&'*()()+,*-.*/01(234)(567))(A(a(b(c(d(e(f(g(h(i(j(k(l(m(n(o(p(q(r)s(t(u(v(w(x(y(z)))))))))))}}}`).formatting done automatically behind-the-scenes programatically upon initial submission request made previously *)\n#######*(automated formatting processing applied programmatically utilizing pre-provided custom C++ code snippet written specifically designed solely dedicated exclusively focused entirely devoted purely passionately deeply totally completely utterly thoroughly comprehensively exhaustively intrinsincally profoundely rooted firmly established solidified fastened secured cement-like permanently affixed tightly bound securely strapped down bolt-down riveted nailed screwed wired grafted fused melted combined compounded blended intermingling mixed amalgamized assorted heterogeneous hodgepodge jumble miscellany muddle potpourri riff-raff scuffle shambolic shuffle skirmish tempest turbulence upheaval vortex witches brew zephyr cyclone tornado hurricane typhoon supercell storm squall blast air current gust puff waft breath exhale inhaling inspires inspiring inspiration inspirational spirit spirited spirits laughter joy happiness mood feeling feelings emotion emotional emo emoticon smile happy cheerio byebye adios ciao au revoir good-bye farewell till next time see ya soon ta-tah until we meet once-more-a-last-it-been-so-long-since-we've-seen-each-others-faces-until-right-here-this-moment-how-do-I-feel-exactly-whats-going-on-through-my-head-body-heart-and-gut-instinct-atmosphere-environment-vibe aura energy flow circulation pulse beat rhythm cadence tune melody chorus refrain theme song ballade epic saga odyssey romcom sitcom soap opera anthology series miniseries webseries television tv movie film motion picture featurette short subject documentary biopic true-crime crime-drama drama thriller", 'role': 'system'}, {'content': '再讲一个', 'role': 'user'}, {'role': 'assistant', 'content': 'Title ** Whispers of the Willowy, Willy-Willos  *{%#%^& *()(+, +-*-/. 1[234567][89A-a<B-cDdEEffGGhhIIJKKKLLMMNNOOpprrSSTTttuuvvwwxxYYzz]}*\n\nAuthor Harry Potter\n\n---\n\nThe first book in [Harry\'s series](https://en.wikipedia.org/wiki/Harry_Potter_series) was published on September `date` (`year`) by J.K. Rowling.\n***This page only discusses information about this specific novel and not its sequels or prequels.*\n\n## About The Book \n### Cover Artwork \n\n![Book cover for \'HP - Philosopher\\\'s Stone\'. (Source: Wikimedia Commons)]({{ site.url }}/assets/images/books/philosophical_stone.jpg)\n\n#### Title Page Design Variants  \n\nHere are a few designs that were considered during development stages but weren\'t finalized.\n\n<div class="image-container">\n    <img src="{{ "/assets/images/title_page_designs/hp_philo_stone_2.jpg" | absolute_url}}"/>\n</div>\n\n<br><br>\n\n\n<div class="image-container">\n\t<a href="{{ \'/posts/the-quest-for-the-holy-grail/\'"}}">Grails Quest.</a>\n\t\n   <!-- <img id="fadeout" style="opacity:.5;" width="200px" height="300px"></canvas> -->\n   \n    \n    <style type="text/css"><!DOCTYPE html PUBLIC "-//WHATWG//DTD HTML; version gazelle/gnu","http://www.w3school.com/codepen/pens/seo-gazelles-guide.html">\n\n/* fade out css */\n@keyframes fadeIn {\n    from opacity.9;\n}\n\n@media screen and (-webkit-min-device-pixel-ratio:<13),(min-resolution:[x.D], x>=133)]\n{\n    @font-face{-webkit-font-smoothing:\'antialiased\';\n          -moz-osx-font-smoothing:\'grayscale\'; font-family:"Helvetica Neue", Helvetica,\n            Arial,sans-serif;-webkit-text-stroke-width:4pt;unicode-bidi:isolate;}}\n\nhtml {/* keyframe animation */ @import url(\'data:image/svg+/encoded,%EF%BB%BF%E8%A7%B6%E82%81%E77%\nF%20tC%22_%28S%29_%20100000L\'%60%62%63%'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:50862 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:26:15 async_llm_engine.py:436] Received request chatcmpl-ee458ce6-c35d-4b18-bb5d-4149cf65d8e9: prompt: "<s><|im_start|>system\n我们之前聊了：\n---\nTitle        themed title based off input text given earlier.*(`original_text`*)*\nAuthor       author name formatted according author naming conventions used throughout history.*\n*[referencing multiple authors is possible]**\n\n---\nOriginal Text:\n-----------\n\nTitle         **Whisper \\of\\\n                the {W}illowing,{Wil}\n                  lors}{%#%^&'()*+,-./0123456789:AaBbCCcCDDeEfFGgHhHIJkKLmMnOpqRRSTTUUVVWWXYyZ}${(%#%^&'*()()+,*-.*/01(234)(567))(A(a(b(c(d(e(f(g(h(i(j(k(l(m(n(o(p(q(r)s(t(u(v(w(x(y(z)))))))))))}}}`).formatting done automatically behind-the-scenes programatically upon initial submission request made previously *)\n#######*(automated formatting processing applied programmatically utilizing pre-provided custom C++ code snippet written specifically designed solely dedicated exclusively focused entirely devoted purely passionately deeply totally completely utterly thoroughly comprehensively exhaustively intrinsincally profoundely rooted firmly established solidified fastened secured cement-like permanently affixed tightly bound securely strapped down bolt-down riveted nailed screwed wired grafted fused melted combined compounded blended intermingling mixed amalgamized assorted heterogeneous hodgepodge jumble miscellany muddle potpourri riff-raff scuffle shambolic shuffle skirmish tempest turbulence upheaval vortex witches brew zephyr cyclone tornado hurricane typhoon supercell storm squall blast air current gust puff waft breath exhale inhaling inspires inspiring inspiration inspirational spirit spirited spirits laughter joy happiness mood feeling feelings emotion emotional emo emoticon smile happy cheerio byebye adios ciao au revoir good-bye farewell till next time see ya soon ta-tah until we meet once-more-a-last-it-been-so-long-since-we've-seen-each-others-faces-until-right-here-this-moment-how-do-I-feel-exactly-whats-going-on-through-my-head-body-heart-and-gut-instinct-atmosphere-environment-vibe aura energy flow circulation pulse beat rhythm cadence tune melody chorus refrain theme song ballade epic saga odyssey romcom sitcom soap opera anthology series miniseries webseries television tv movie film motion picture featurette short subject documentary biopic true-crime crime-drama drama thriller<|im_end|>\n<|im_start|>assistant\n", prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 11102, 4006, 391, 470, 16539, 2416, 3285, 1147, 2098, 1614, 2823, 6939, 5066, 5962, 10024, 4486, 350, 3924, 5774, 7282, 417, 3259, 963, 23455, 4251, 3316, 34953, 44040, 1629, 6965, 3995, 30921, 53293, 40875, 11525, 5408, 12166, 505, 3369, 332, 55098, 11102, 18549, 3083, 642, 53225, 4006, 820, 465, 1787, 27760, 1268, 1197, 5816, 469, 1934, 445, 325, 335, 614, 23514, 28206, 51486, 663, 4453, 270, 1229, 15292, 344, 324, 45380, 348, 259, 25439, 342, 5158, 1876, 300, 4575, 10877, 16217, 54601, 264, 309, 260, 3866, 271, 6640, 2062, 288, 283, 12153, 279, 318, 280, 24283, 338, 292, 52062, 277, 307, 265, 7274, 327, 8240, 917, 291, 315, 22525, 322, 19141, 16490, 282, 349, 31393, 15361, 324, 45380, 348, 42865, 499, 17280, 28367, 14659, 1961, 1836, 298, 11622, 2530, 18908, 724, 4506, 3041, 2032, 1483, 1646, 2176, 1094, 3431, 3368, 2107, 3488, 6123, 2485, 1402, 1591, 10245, 1441, 10723, 2761, 16601, 1299, 8289, 3907, 3783, 2226, 7171, 13314, 26199, 26199, 7845, 3578, 58671, 2394, 1425, 2978, 9592, 4975, 10743, 30562, 21890, 2175, 7172, 5351, 3020, 20695, 1831, 2014, 8731, 17542, 954, 14511, 6752, 27474, 788, 36501, 8826, 9384, 54444, 7172, 34894, 990, 9974, 42596, 2682, 487, 1169, 2189, 42699, 5485, 11839, 6342, 21276, 12388, 23574, 10884, 11520, 28578, 31329, 11827, 2813, 17388, 12624, 6740, 37412, 26793, 12824, 27324, 17639, 3297, 10722, 1476, 3004, 878, 27553, 1114, 40603, 31705, 9689, 6594, 2019, 5096, 6909, 26859, 23968, 12831, 30982, 3688, 3449, 38775, 6973, 50203, 739, 5832, 1641, 32018, 15004, 42758, 24886, 4477, 2334, 55257, 51247, 473, 59418, 413, 2751, 48643, 11006, 1512, 13226, 53545, 1084, 5470, 2880, 9649, 1221, 24247, 440, 1651, 1213, 13737, 29736, 47379, 436, 15672, 276, 15672, 633, 23037, 31327, 745, 3927, 427, 8480, 404, 3501, 53520, 592, 566, 3257, 57098, 673, 1280, 13349, 688, 3133, 7901, 26386, 2051, 3017, 946, 1708, 29434, 28372, 57252, 837, 513, 22012, 479, 44136, 420, 25654, 16828, 1291, 880, 8639, 267, 31440, 735, 43733, 48008, 13720, 891, 9140, 2407, 6027, 13601, 8301, 672, 20878, 3880, 1628, 30080, 412, 1508, 10586, 856, 11639, 55554, 1720, 58163, 6285, 1788, 19124, 33152, 19933, 55132, 9046, 18472, 1755, 30867, 41787, 16018, 23331, 19839, 8398, 15782, 19945, 14409, 1116, 268, 10310, 2076, 15413, 6403, 25462, 949, 52116, 28715, 1133, 3691, 403, 22806, 8044, 443, 34504, 1811, 1601, 9142, 20614, 9287, 12106, 1942, 1018, 1636, 13666, 5296, 9578, 2540, 1613, 3245, 713, 3531, 3220, 49168, 7555, 59178, 37393, 15271, 399, 33124, 24153, 1477, 1851, 59965, 3168, 7944, 399, 5810, 742, 16151, 3149, 2371, 2587, 20071, 1794, 6851, 2996, 616, 58877, 1594, 13063, 56269, 29841, 21715, 33300, 432, 10324, 32862, 54298, 2011, 20106, 418, 10462, 42395, 60111, 26819, 9478, 41908, 9911, 2525, 463, 33761, 7938, 29105, 8764, 8156, 20976, 3271, 8405, 23896, 38846, 4963, 6551, 34771, 27630, 9509, 36233, 19576, 895, 25673, 60197, 54752, 56352, 7065, 5650, 5094, 1162, 25098, 45759, 10932, 52314, 10017, 1010, 2598, 1010, 27201, 42072, 22546, 2603, 4169, 1454, 416, 4862, 3644, 20058, 12575, 11238, 5854, 4693, 11531, 6953, 4728, 39604, 2969, 3988, 25378, 6185, 25232, 964, 46977, 676, 9912, 1888, 30612, 19754, 52426, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:26:19 metrics.py:213] Avg prompt throughput: 107.8 tokens/s, Avg generation throughput: 67.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:26:21 async_llm_engine.py:110] Finished request chatcmpl-ee458ce6-c35d-4b18-bb5d-4149cf65d8e9.
2024-03-28 22:26:22.040 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': [{'type': 'function', 'function': {'name': 'duckduckgo_search', 'description': 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'calculator', 'description': 'Useful for getting the result of a math expression. The input to this tool should be a valid mathematical expression that could be executed by a simple calculator.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'web-browser', 'description': 'useful for when you need to find something on or summarize a webpage. input should be a comma separated list of "ONE valid http URL including protocol","what you want to find on the page or empty string for a summary".', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'Run Arxiv search and get the article information.', 'parameters': {'type': 'object', 'properties': {'searchQuery': {'type': 'string', 'description': 'same as the search_query parameter rules of the arxiv API.'}, 'sortBy': {'type': 'string', 'description': 'can be "relevance", "lastUpdatedDate", "submittedDate".'}, 'sortOrder': {'type': 'string', 'description': 'can be either "ascending" or "descending".'}, 'start': {'type': 'number', 'default': 0, 'description': 'the index of the first returned result.'}, 'maxResults': {'type': 'number', 'default': 10, 'description': 'the number of results returned by the query.'}}, 'required': ['searchQuery', 'sortBy', 'sortOrder'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wolfram_alpha_llm', 'description': 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query. If the result contains an image link, use the markdown syntax to return the image.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}, {'type': 'function', 'function': {'name': 'wikipedia-api', 'description': 'A tool for interacting with and fetching data from the Wikipedia API.', 'parameters': {'type': 'object', 'properties': {'input': {'type': 'string'}}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}}}], 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': "我们之前聊了：\n---\nTitle **Whispers of the Willow**\n*Automagically transforming your ordinary, mundane sentences into fantastical and enchantingly ethereal prose.*\n\n---\n\nHere's a brief summary about how this all works: \nThe `input_text` parameter passed in as an argument to our function will be processed through various stages. The data stream being fed from one stage/step/sorting process/go-round/etc., etc.) after another (and so on), each successive phase then gradually transforms/conceals/alleviates/amends/modifies/morphs/drifts/wavers/fluctuates/subtly shifts subtleties nuances shades variations undertones inflection accents intonation dialect slang regionalisms colloquial expressions idioms proverbs sayings axiomatic truths truisms certainties absolutes maxims principles doctrines philosophic dictates ideologies theories constructs frameworks models paradigms schemas algorithms programs scripts scenarios simulations experiments trials tests probes inquiries interrogations disquisitions disputatious debates discussions conferencess symposiumss congressseminarreunions roundtables summits workshops retreatshibernacaves icehouses iglooos snow palafitetepeejunkanautocampingoutdoorswildernessforestwoodlandgroveclearcuttimberlotplant nurseryseedlingsgreenhouse greenhouse plants hydroponics aquaponics aeroponicsturbid waterwater with low transparencyblacknessdarknesseye-waterwhiskeybeercloudiness clouded liquidliquid that appears whitewinebloodplanktonphytoplanctonsuspended pa", 'role': 'system'}, {'content': '再讲一个', 'role': 'user'}, {'role': 'assistant', 'content': '好的，为您讲述另外一个故事。从前，在一个美丽的山谷里住着一只名叫米娅的勇敢小鸟。米娅非常喜欢探索山谷中的新地方，并且经常在她的日记中记录下这些新的发现。\n\n有一天，当米娅正在探索山谷底部的一个神秘洞穴时，她突然发现自己被困在了里面！由于黑暗笼罩着她，而且出口似乎被关闭了，所以米娅感到非常害怕和无助。不过，她在心里默默地鼓励着自己：“不要害怕，你可以找到出路！”\n\n于是，米娅开始了一场惊心动魄的冒险之旅。在寻找出口的过程中，她遇到了各种各样的危险和挑战，比如陡峭的悬崖、汹涌的河流、恐怖的陷阱等等。然而，每一次危机过后，米娅总会变得更加坚强，更加自信，也更加热爱生活。\n\n经过漫长而又艰辛的路程之后，米娅终于找到了走出那个神秘洞穴的方法。当她从洞口飞出来的时候，迎接她的是一片明媚的阳光和一个令人惊叹的美景——整个山谷都被鲜花覆盖着，远处的山峰显得格外雄伟壮观，仿佛整个大自然都在为米娅庆祝这场胜利的到来！\n\n从那一天起，米娅成为了整个山谷中最勇敢的小鸟之一，也被人们誉为“最勇敢的小鸟”称号。每当有人提起这个名字的时候，他们总是会想起那位曾经为了追寻自由和勇气而勇闯险境的小鸟的名字——米娅。'}, {'content': '再讲一个', 'role': 'user'}, {'role': 'assistant', 'content': 'Title ** Whispers of the Willowy, Willy-Willos  *{%#%^& *()(+, +-*-/. 1[234567][89A-a<B-cDdEEffGGhhIIJKKKLLMMNNOOpprrSSTTttuuvvwwxxYYzz]}*\n\nAuthor Harry Potter\n\n---\n\nThe first book in [Harry\'s series](https://en.wikipedia.org/wiki/Harry_Potter_series) was published on September `date` (`year`) by J.K. Rowling.\n***This page only discusses information about this specific novel and not its sequels or prequels.*\n\n## About The Book \n### Cover Artwork \n\n![Book cover for \'HP - Philosopher\\\'s Stone\'. (Source: Wikimedia Commons)]({{ site.url }}/assets/images/books/philosophical_stone.jpg)\n\n#### Title Page Design Variants  \n\nHere are a few designs that were considered during development stages but weren\'t finalized.\n\n<div class="image-container">\n    <img src="{{ "/assets/images/title_page_designs/hp_philo_stone_2.jpg" | absolute_url}}"/>\n</div>\n\n<br><br>\n\n\n<div class="image-container">\n\t<a href="{{ \'/posts/the-quest-for-the-holy-grail/\'"}}">Grails Quest.</a>\n\t\n   <!-- <img id="fadeout" style="opacity:.5;" width="200px" height="300px"></canvas> -->\n   \n    \n    <style type="text/css"><!DOCTYPE html PUBLIC "-//WHATWG//DTD HTML; version gazelle/gnu","http://www.w3school.com/codepen/pens/seo-gazelles-guide.html">\n\n/* fade out css */\n@keyframes fadeIn {\n    from opacity.9;\n}\n\n@media screen and (-webkit-min-device-pixel-ratio:<13),(min-resolution:[x.D], x>=133)]\n{\n    @font-face{-webkit-font-smoothing:\'antialiased\';\n          -moz-osx-font-smoothing:\'grayscale\'; font-family:"Helvetica Neue", Helvetica,\n            Arial,sans-serif;-webkit-text-stroke-width:4pt;unicode-bidi:isolate;}}\n\nhtml {/* keyframe animation */ @import url(\'data:image/svg+/encoded,%EF%BB%BF%E8%A7%B6%E82%81%E77%\nF%20tC%22_%28S%29_%20100000L\'%60%62%63%'}, {'content': '再讲一个', 'role': 'user'}], 'echo': False}
INFO:     10.1.96.6:49804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 22:26:22 async_llm_engine.py:436] Received request chatcmpl-9a5560d2-ffd3-4a13-beb3-1834166dc08f: prompt: "<s><|im_start|>system\n我们之前聊了：\n---\nTitle **Whispers of the Willow**\n*Automagically transforming your ordinary, mundane sentences into fantastical and enchantingly ethereal prose.*\n\n---\n\nHere's a brief summary about how this all works: \nThe `input_text` parameter passed in as an argument to our function will be processed through various stages. The data stream being fed from one stage/step/sorting process/go-round/etc., etc.) after another (and so on), each successive phase then gradually transforms/conceals/alleviates/amends/modifies/morphs/drifts/wavers/fluctuates/subtly shifts subtleties nuances shades variations undertones inflection accents intonation dialect slang regionalisms colloquial expressions idioms proverbs sayings axiomatic truths truisms certainties absolutes maxims principles doctrines philosophic dictates ideologies theories constructs frameworks models paradigms schemas algorithms programs scripts scenarios simulations experiments trials tests probes inquiries interrogations disquisitions disputatious debates discussions conferencess symposiumss congressseminarreunions roundtables summits workshops retreatshibernacaves icehouses iglooos snow palafitetepeejunkanautocampingoutdoorswildernessforestwoodlandgroveclearcuttimberlotplant nurseryseedlingsgreenhouse greenhouse plants hydroponics aquaponics aeroponicsturbid waterwater with low transparencyblacknessdarknesseye-waterwhiskeybeercloudiness clouded liquidliquid that appears whitewinebloodplanktonphytoplanctonsuspended pa<|im_end|>\n<|im_start|>assistant\n", prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 11102, 4006, 3235, 1787, 13235, 518, 446, 410, 5000, 494, 1160, 297, 40790, 482, 2835, 45275, 829, 19275, 328, 40311, 2298, 23183, 1263, 8719, 690, 1076, 454, 46346, 11460, 8505, 42878, 59354, 41693, 43916, 8554, 725, 395, 9950, 12279, 1048, 1392, 550, 810, 4437, 334, 848, 918, 1711, 1501, 4486, 350, 5886, 5977, 435, 569, 589, 5847, 442, 1181, 862, 818, 517, 15356, 1672, 5417, 17769, 281, 707, 955, 4427, 1810, 22595, 635, 959, 6587, 301, 9650, 2849, 50624, 2031, 25967, 21226, 46462, 2732, 5151, 6291, 1428, 2595, 451, 568, 906, 519, 833, 1966, 48232, 10398, 1367, 26462, 28812, 31433, 477, 1271, 51246, 3610, 41959, 54376, 1558, 38311, 9741, 3348, 16481, 269, 3607, 41085, 269, 6480, 21802, 57100, 798, 50168, 37751, 263, 528, 28967, 40748, 1293, 681, 11059, 3186, 36048, 26680, 18796, 3320, 4291, 1315, 57256, 658, 394, 498, 41941, 1891, 656, 15251, 13806, 1521, 515, 577, 661, 23727, 40402, 7091, 593, 53919, 2127, 953, 4014, 266, 13629, 51245, 620, 9374, 1151, 2941, 59661, 3808, 468, 2248, 2084, 5895, 16301, 59535, 1688, 13698, 423, 6607, 1113, 2774, 9220, 25396, 55143, 47382, 4277, 27710, 474, 1151, 19819, 431, 25620, 7612, 19671, 25717, 45931, 21426, 19236, 7182, 3727, 419, 43469, 36377, 938, 961, 51913, 34115, 397, 1369, 36472, 20516, 48064, 1093, 564, 8025, 52208, 911, 21250, 456, 1207, 408, 396, 490, 1045, 4940, 32268, 34306, 1344, 34844, 30270, 1065, 17801, 711, 4856, 9988, 36665, 19540, 46543, 567, 11943, 11004, 2737, 406, 7854, 506, 35448, 3289, 407, 2879, 641, 30692, 542, 27697, 293, 827, 28904, 49858, 6811, 2085, 41115, 4242, 1692, 10377, 20267, 783, 9314, 21037, 54095, 22898, 18967, 13391, 7814, 36484, 10926, 16776, 750, 1357, 15479, 10885, 1357, 33537, 584, 14149, 398, 9178, 438, 3181, 13135, 579, 3510, 27626, 11603, 2242, 22920, 5032, 8642, 261, 52984, 1458, 45558, 47169, 12512, 2029, 9565, 422, 14610, 52685, 560, 8088, 33772, 496, 613, 49256, 631, 1325, 910, 12850, 3643, 10862, 433, 2537, 30034, 3046, 7254, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:26:24 metrics.py:213] Avg prompt throughput: 70.2 tokens/s, Avg generation throughput: 81.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:26:27 async_llm_engine.py:110] Finished request chatcmpl-9a5560d2-ffd3-4a13-beb3-1834166dc08f.
2024-03-28 22:26:28.825 | DEBUG    | api.vllm_routes.chat:create_chat_completion:62 - ==== request ====
{'model': 'gpt-3.5-turbo', 'frequency_penalty': 0.0, 'function_call': None, 'functions': None, 'logit_bias': None, 'logprobs': False, 'max_tokens': 512, 'n': 1, 'presence_penalty': 0.0, 'response_format': None, 'seed': None, 'stop': ['<|im_end|>', '</s>'], 'temperature': 0.5, 'tool_choice': None, 'tools': None, 'top_logprobs': None, 'top_p': 1.0, 'user': None, 'stream': True, 'repetition_penalty': 1.03, 'typical_p': None, 'watermark': False, 'best_of': 1, 'ignore_eos': False, 'use_beam_search': False, 'stop_token_ids': [], 'skip_special_tokens': True, 'spaces_between_special_tokens': True, 'min_p': 0.0, 'include_stop_str_in_output': False, 'length_penalty': 1.0, 'guided_json': None, 'guided_regex': None, 'guided_choice': None, 'prompt_or_messages': [{'content': "我们之前聊了：\n---\nTitle **Whispers of the Willow**\n*Automagically transforming your ordinary, mundane sentences into fantastical and enchantingly ethereal prose.*\n\n---\n\nHere's a brief summary about how this all works: \nThe `input_text` parameter passed in as an argument to our function will be processed through various stages. The data stream being fed from one stage/step/sorting process/go-round/etc., etc.) after another (and so on), each successive phase then gradually transforms/conceals/alleviates/amends/modifies/morphs/drifts/wavers/fluctuates/subtly shifts subtleties nuances shades variations undertones inflection accents intonation dialect slang regionalisms colloquial expressions idioms proverbs sayings axiomatic truths truisms certainties absolutes maxims principles doctrines philosophic dictates ideologies theories constructs frameworks models paradigms schemas algorithms programs scripts scenarios simulations experiments trials tests probes inquiries interrogations disquisitions disputatious debates discussions conferencess symposiumss congressseminarreunions roundtables summits workshops retreatshibernacaves icehouses iglooos snow palafitetepeejunkanautocampingoutdoorswildernessforestwoodlandgroveclearcuttimberlotplant nurseryseedlingsgreenhouse greenhouse plants hydroponics aquaponics aeroponicsturbid waterwater with low transparencyblacknessdarknesseye-waterwhiskeybeercloudiness clouded liquidliquid that appears whitewinebloodplanktonphytoplanctonsuspended particulate matterSPMSPMPSMPSPSMPSPLight particlesparticles floatingfloat float floatsuspension suspension suspensionsuspen suspsuspend suspendedsuspensussuspensive\n\n---\nThis happens by employing several different techniques including but not limited too:\n\n- [Markdown](https://github.com/adaptlearning/glossary/blob/master/content/tex.md)\n    - A lightweight markup language for creating structured documents.\n    \n- [[HTML]]([[[[`text` variable value assigned at runtime using user-supplied inputs via standard I/O facilities available within most modern operating systems running software applications utilized regularly across numerous industries involving business operations commerce trade finance logistics supply chain management marketing advertising public relations media broadcasting journalism publishing entertainment gaming virtual reality augmented realty internet social networking online communities digital culture technology information computing science engineering mathematics physics chemistry biology medicine healthcare veterinary nursing midwife psychology anthropological sociologist cultural studies linguistics economics political theory global affairs international law human rights environmental", 'role': 'system'}, {'content': '再讲一个', 'role': 'user'}, {'role': 'assistant', 'content': '---\n**Title Whispering Oaths Upon Thorny Branchlets**\n\nThis is basically just what it says.\nIt takes whatever input text you pass along,\nthen proceeds by whisper-turn-whistle-transform-transmute-mutate-modify-change-shape-alter-amend-improve-augment-enhance-elevated-uplift-glorified-admired-celebratory-honorifically-exalted-superior-profound-insightful-perceptive-subtle-cryptic-esoteric-recondite-hidden-unseen-concealed-covert-shadow-yet-to-be-discovered-not yet revealed-uncertain-future-unpredictable-unascertained-unproven-not established-not substantiated-not verified-not validated-not attested-not corroborative-not credible-inconsistent-dubitable-vague-indistinct-meager-poor-lousyparticularly bad-tawdry-trifling-banal-worthless-uselessetcetera)\n\\---\n\n\n\nThat sounds pretty exciting!\nSo let us begin!\n\nFirst things first:\nWe need something for starters! Something delicious or savory perhaps? Anything but dry; we want some juice here please.\n\nHow does "something" taste?\nWhat flavors are present?\n\nIs there any sweetener used such as sugar syrup honey molasses agave nectar maple sirup date paste fig jam fruit spread marmalade preserves jams compotes chutneys relishes pickled vegetables fermented foods kimchi sauerkraut miso tamari shoyu soy sauce umami bouillon stock broth pickle brinjal egg plant bharta baize bazaire basilica balisht batz huitres husks shells cascasca caskkeg bottle gobler flacon phials ampouls viles retorts crucibles mortars pestels pipets droppers syringues hypodermises lancettes needle needles pins tacks darts pricking points jabbing blades poniards sabretaches flechettes daggers dirges scabbardsguardianships sheathescases wraps bindery bindings wrappings wrapping paper tissuepaper paperwrap plastic wrap foil saran claysurejellie shrink-wrap rubber band zip tie velcro elastic fabric yarn thread string wire hook clip snap button pin tack adhesive tape duct tapecellophanecandy wrapper gumwrapper breath mint container tic tac box aspirins tablet package cough drop packaging throat lozenge case expectorant mouth wash nasopharyngtitis strept'}, {'content': '总结聊天内容，越少越好', 'role': 'system'}], 'echo': False}
INFO:     10.1.96.6:49816 - "POST /v1/chat/completions?path=v1&path=chat&path=completions HTTP/1.1" 200 OK
INFO 03-28 22:26:28 async_llm_engine.py:436] Received request chatcmpl-01e7961f-70ed-4f09-bb68-3341a40f8fd5: prompt: "<s><|im_start|>system\n我们之前聊了：\n---\nTitle **Whispers of the Willow**\n*Automagically transforming your ordinary, mundane sentences into fantastical and enchantingly ethereal prose.*\n\n---\n\nHere's a brief summary about how this all works: \nThe `input_text` parameter passed in as an argument to our function will be processed through various stages. The data stream being fed from one stage/step/sorting process/go-round/etc., etc.) after another (and so on), each successive phase then gradually transforms/conceals/alleviates/amends/modifies/morphs/drifts/wavers/fluctuates/subtly shifts subtleties nuances shades variations undertones inflection accents intonation dialect slang regionalisms colloquial expressions idioms proverbs sayings axiomatic truths truisms certainties absolutes maxims principles doctrines philosophic dictates ideologies theories constructs frameworks models paradigms schemas algorithms programs scripts scenarios simulations experiments trials tests probes inquiries interrogations disquisitions disputatious debates discussions conferencess symposiumss congressseminarreunions roundtables summits workshops retreatshibernacaves icehouses iglooos snow palafitetepeejunkanautocampingoutdoorswildernessforestwoodlandgroveclearcuttimberlotplant nurseryseedlingsgreenhouse greenhouse plants hydroponics aquaponics aeroponicsturbid waterwater with low transparencyblacknessdarknesseye-waterwhiskeybeercloudiness clouded liquidliquid that appears whitewinebloodplanktonphytoplanctonsuspended particulate matterSPMSPMPSMPSPSMPSPLight particlesparticles floatingfloat float floatsuspension suspension suspensionsuspen suspsuspend suspendedsuspensussuspensive\n\n---\nThis happens by employing several different techniques including but not limited too:\n\n- [Markdown](https://github.com/adaptlearning/glossary/blob/master/content/tex.md)\n    - A lightweight markup language for creating structured documents.\n    \n- [[HTML]]([[[[`text` variable value assigned at runtime using user-supplied inputs via standard I/O facilities available within most modern operating systems running software applications utilized regularly across numerous industries involving business operations commerce trade finance logistics supply chain management marketing advertising public relations media broadcasting journalism publishing entertainment gaming virtual reality augmented realty internet social networking online communities digital culture technology information computing science engineering mathematics physics chemistry biology medicine healthcare veterinary nursing midwife psychology anthropological sociologist cultural studies linguistics economics political theory global affairs international law human rights environmental<|im_end|>\n<|im_start|>assistant\n", prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.03, temperature=0.5, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=['<|im_end|>', '</s>'], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: [1, 1, 333, 352, 449, 5064, 352, 330, 9081, 364, 68253, 68478, 61277, 60362, 60387, 364, 11102, 4006, 3235, 1787, 13235, 518, 446, 410, 5000, 494, 1160, 297, 40790, 482, 2835, 45275, 829, 19275, 328, 40311, 2298, 23183, 1263, 8719, 690, 1076, 454, 46346, 11460, 8505, 42878, 59354, 41693, 43916, 8554, 725, 395, 9950, 12279, 1048, 1392, 550, 810, 4437, 334, 848, 918, 1711, 1501, 4486, 350, 5886, 5977, 435, 569, 589, 5847, 442, 1181, 862, 818, 517, 15356, 1672, 5417, 17769, 281, 707, 955, 4427, 1810, 22595, 635, 959, 6587, 301, 9650, 2849, 50624, 2031, 25967, 21226, 46462, 2732, 5151, 6291, 1428, 2595, 451, 568, 906, 519, 833, 1966, 48232, 10398, 1367, 26462, 28812, 31433, 477, 1271, 51246, 3610, 41959, 54376, 1558, 38311, 9741, 3348, 16481, 269, 3607, 41085, 269, 6480, 21802, 57100, 798, 50168, 37751, 263, 528, 28967, 40748, 1293, 681, 11059, 3186, 36048, 26680, 18796, 3320, 4291, 1315, 57256, 658, 394, 498, 41941, 1891, 656, 15251, 13806, 1521, 515, 577, 661, 23727, 40402, 7091, 593, 53919, 2127, 953, 4014, 266, 13629, 51245, 620, 9374, 1151, 2941, 59661, 3808, 468, 2248, 2084, 5895, 16301, 59535, 1688, 13698, 423, 6607, 1113, 2774, 9220, 25396, 55143, 47382, 4277, 27710, 474, 1151, 19819, 431, 25620, 7612, 19671, 25717, 45931, 21426, 19236, 7182, 3727, 419, 43469, 36377, 938, 961, 51913, 34115, 397, 1369, 36472, 20516, 48064, 1093, 564, 8025, 52208, 911, 21250, 456, 1207, 408, 396, 490, 1045, 4940, 32268, 34306, 1344, 34844, 30270, 1065, 17801, 711, 4856, 9988, 36665, 19540, 46543, 567, 11943, 11004, 2737, 406, 7854, 506, 35448, 3289, 407, 2879, 641, 30692, 542, 27697, 293, 827, 28904, 49858, 6811, 2085, 41115, 4242, 1692, 10377, 20267, 783, 9314, 21037, 54095, 22898, 18967, 13391, 7814, 36484, 10926, 16776, 750, 1357, 15479, 10885, 1357, 33537, 584, 14149, 398, 9178, 438, 3181, 13135, 579, 3510, 27626, 11603, 2242, 22920, 5032, 8642, 261, 52984, 1458, 45558, 47169, 12512, 2029, 9565, 422, 14610, 52685, 560, 8088, 33772, 496, 613, 49256, 631, 1325, 910, 12850, 3643, 10862, 433, 2537, 30034, 3046, 2693, 6490, 5083, 4755, 307, 4755, 307, 5171, 5933, 4755, 9632, 5171, 3081, 622, 18879, 4642, 4502, 19212, 3809, 2375, 47265, 30034, 2806, 24692, 9428, 4827, 486, 2916, 4643, 1840, 12907, 21847, 269, 30034, 857, 2003, 30034, 4182, 402, 11102, 2136, 8705, 684, 49440, 3963, 2308, 12689, 2832, 847, 668, 7348, 2389, 1593, 285, 640, 9082, 3088, 9665, 2580, 1253, 5363, 1042, 44008, 2851, 21192, 5005, 9505, 789, 34836, 23634, 28281, 5679, 458, 21554, 471, 388, 285, 493, 29455, 40485, 4287, 500, 6976, 33039, 9423, 756, 1208, 285, 4478, 5990, 5215, 2720, 15633, 336, 350, 1464, 350, 4047, 1033, 12758, 650, 15724, 1817, 1341, 57296, 3601, 11278, 4729, 5456, 489, 17669, 12936, 2656, 3042, 1575, 6637, 10488, 6095, 4463, 3328, 8490, 33690, 15630, 4098, 12268, 19260, 15991, 2721, 7667, 35623, 6715, 17157, 41826, 8284, 8920, 6396, 8629, 13027, 715, 4460, 3847, 48141, 29319, 23225, 16652, 15963, 4266, 8866, 54918, 2083, 2030, 7742, 3751, 28387, 3023, 10893, 7523, 7813, 5599, 2145, 24620, 8171, 14800, 37472, 21551, 30069, 33451, 15843, 18629, 12720, 3450, 27748, 5260, 47120, 30182, 40065, 5882, 15742, 16288, 12901, 7959, 38334, 5744, 28256, 5107, 10263, 3805, 22245, 6645, 2481, 3898, 3354, 12311, 333, 352, 449, 6368, 352, 527, 333, 352, 449, 5064, 352, 330, 525, 11353, 364], lora_request: None.
INFO 03-28 22:26:29 metrics.py:213] Avg prompt throughput: 108.5 tokens/s, Avg generation throughput: 68.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 03-28 22:26:34 async_llm_engine.py:110] Finished request chatcmpl-01e7961f-70ed-4f09-bb68-3341a40f8fd5.
slurmstepd: error: *** JOB 3338742 ON SH-IDC1-10-140-24-111 CANCELLED AT 2024-03-28T22:40:08 ***
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [179117]
